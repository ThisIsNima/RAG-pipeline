

----- Page 1 (native) -----
SOME
PHILOSOPHICAL
PR
OBLEMS
FR
OM
THE
ST
ANDPOINT
OF
AR
TIFICIAL
INTELLIGENCE
John
McCarth
y
and
P
atric
k
J.
Ha
y
es
Computer
Science
Departmen
t
Stanford
Univ
ersit
y
Stanford,
CA
	0
jmc@cs.stanford.
edu
http://www-form
al.s
tanfo
rd.e
du/j
mc/
		

In
tro
duction
A
computer
program
capable
of
acting
in
telligen
tly
in
the
w
orld
m
ust
ha
v
e
a
general
represen
tation
of
the
w
orld
in
terms
of
whic
h
its
inputs
are
in
ter-
preted.
Designing
suc
h
a
program
requires
commitm
en
ts
ab
out
what
kno
wl-
edge
is
and
ho
w
it
is
obtained.
Th
us,
some
of
the
ma
jor
traditional
problems
of
philosoph
y
arise
in
articial
in
telligence.
More
sp
ecically
,
w
e
w
an
t
a
computer
program
that
decides
what
to
do
b
y
inferring
in
a
formal
language
that
a
certain
strategy
will
ac
hiev
e
its
assigned
goal.
This
requires
formalizing
concepts
of
causalit
y
,
abilit
y
,
and
kno
wledge.
Suc
h
formalisms
are
also
considered
in
philosophical
logic.
The
rst
part
of
the
pap
er
b
egins
with
a
philosophical
p
oin
t
of
view
that
seems
to
arise
naturally
once
w
e
tak
e
seriously
the
idea
of
actually
mak-
ing
an
in
telligen
t
mac
hine.
W
e
go
on
to
the
notions
of
metaph
ysically
and
epistemologically
adequate
represen
tations
of
the
w
orld
and
then
to
an
ex-
planation
of
c
an,
c
auses,
and
knows
in
terms
of
a
represen
tation
of
the
w
orld


----- Page 2 (native) -----
b
y
a
system
of
in
teracting
automata.
A
prop
osed
resolution
of
the
prob-
lem
of
freewill
in
a
deterministic
univ
erse
and
of
coun
terfactual
conditional
sen
tences
is
presen
ted.
The
second
part
is
mainly
concerned
with
formalisms
within
whic
h
it
can
b
e
pro
v
ed
that
a
strategy
will
ac
hiev
e
a
goal.
Concepts
of
situation,
uen
t,
future
op
erator,
action,
strategy
,
result
of
a
strategy
and
kno
wledge
are
formalized.
A
metho
d
is
giv
en
of
constructing
a
sen
tence
of
rst
order
logic
whic
h
will
b
e
true
in
all
mo
dels
of
certain
axioms
if
and
only
if
a
certain
strategy
will
ac
hiev
e
a
certain
goal.
The
formalism
of
this
pap
er
represen
ts
an
adv
ance
o
v
er
McCarth
y
(	)
and
Green
(		)
in
that
it
p
ermits
pro
of
of
the
correctness
of
strategies
that
con
tain
lo
ops
and
strategies
that
in
v
olv
e
the
acquisition
of
kno
wledge,
and
it
is
also
somewhat
more
concise.
The
third
part
discusses
op
en
problems
in
extending
the
formalism
of
P
art
t
w
o
(section
).
The
fourth
part
is
a
review
of
w
ork
in
philosophical
logic
in
relation
to
problems
of
articial
in
telligence
and
a
discussion
of
previous
eorts
to
program
`general
in
telligence'
from
the
p
oin
t
of
view
of
this
pap
er.

PHILOSOPHICAL
QUESTIONS
.
Wh
y
Articial
In
telligence
Needs
Philosoph
y
The
idea
of
an
in
telligen
t
mac
hine
is
old,
but
serious
w
ork
on
the
articial
in
telligence
problem
or
ev
en
serious
understanding
of
what
the
problem
is
a
w
aited
the
stored
program
computer.
W
e
ma
y
regard
the
sub
ject
of
articial
in
telligence
as
b
eginning
with
T
uring's
article
Computing
Machinery
and
Intel
ligenc
e
(T
uring
	0)
and
with
Shannon's
(	0)
discussion
of
ho
w
a
mac
hine
migh
t
b
e
programmed
to
pla
y
c
hess.
Since
that
time,
progress
in
articial
in
telligence
has
b
een
mainly
along
the
follo
wing
lines.
Programs
ha
v
e
b
een
written
to
solv
e
a
class
of
prob-
lems
that
giv
e
h
umans
in
tellectual
dicult
y:
examples
are
pla
ying
c
hess


----- Page 3 (native) -----
or
c
hec
k
ers,
pro
ving
mathematical
theorems,
transforming
one
sym
b
olic
ex-
pression
in
to
another
b
y
giv
en
rules,
in
tegrating
expressions
comp
osed
of
el-
emen
tary
functions,
determining
c
hemical
comp
ounds
consisten
t
with
mass-
sp
ectrographic
and
other
data.
In
the
course
of
designing
these
programs
in
tellectual
mec
hanism
s
of
greater
or
lesser
generalit
y
are
iden
tied
some-
times
b
y
in
trosp
ection,
sometime
s
b
y
mathematical
analysis,
and
sometimes
b
y
exp
erimen
ts
with
h
uman
sub
jects.
T
esting
the
programs
sometimes
leads
to
b
etter
understanding
of
the
in
tellectual
mec
hanism
s
and
the
iden
tication
of
new
ones.
An
alternativ
e
approac
h
is
to
start
with
the
in
tellectual
mec
hanisms
(for
example,
memory
,
decision-making
b
y
comparisons
of
scores
made
up
of
w
eigh
ted
sums
of
sub-criteria,
learning,
tree-searc
h,
extrap
olation)
and
mak
e
up
problems
that
exercise
these
mec
hanisms.
In
our
opinion
the
b
est
of
this
w
ork
has
led
to
increased
understanding
of
in
tellectual
mec
hanism
s
and
this
is
essen
tial
for
the
dev
elopmen
t
of
articial
in
telligence
ev
en
though
few
in
v
estigators
ha
v
e
tried
to
place
their
particular
mec
hanism
in
the
general
con
text
of
articial
in
telligence.
Sometimes
this
is
b
ecause
the
in
v
estigator
iden
ties
his
particular
problem
with
the
eld
as
a
whole;
he
thinks
he
sees
the
w
o
o
ds
when
in
fact
he
is
lo
oking
at
a
tree.
An
old
but
not
y
et
sup
erseded
discussion
on
in
tellectual
mec
hanisms
is
in
Minsky
(	);
see
also
New
ell's
(	)
review
of
the
state
of
articial
in
telligence.
There
ha
v
e
b
een
sev
eral
attempts
to
design
in
telligence
with
the
same
kind
of
exibilit
y
as
that
of
a
h
uman.
This
has
mean
t
dieren
t
things
to
dieren
t
in
v
estigators,
but
none
has
met
with
m
uc
h
success
ev
en
in
the
sense
of
general
in
telligence
used
b
y
the
in
v
estigator
in
question.
Since
our
crit-
icism
of
this
w
ork
will
b
e
that
it
do
es
not
face
the
philosophical
problems
discussed
in
this
pap
er,
w
e
shall
p
ostp
one
discussing
it
un
til
a
concluding
sec-
tion.
Ho
w
ev
er,
w
e
are
obliged
at
this
p
oin
t
to
presen
t
our
notion
of
general
in
telligence.
It
is
not
dicult
to
giv
e
sucien
t
conditions
for
general
in
telligence.
T
ur-
ing's
idea
that
the
mac
hine
should
successfully
pretend
to
a
sophisticated
observ
er
to
b
e
a
h
uman
b
eing
for
half
an
hour
will
do.
Ho
w
ev
er,
if
w
e
direct
our
eorts
to
w
ards
suc
h
a
goal
our
atten
tion
is
distracted
b
y
certain
sup
er-
cial
asp
ects
of
h
uman
b
eha
viour
that
ha
v
e
to
b
e
imitated.
T
uring
excluded
some
of
these
b
y
sp
ecifying
that
the
h
uman
to
b
e
imitated
is
at
the
end
of
a
telet
yp
e
line,
so
that
v
oice,
app
earance,
smell,
etc.,
do
not
ha
v
e
to
b
e
consid-
ered.
T
uring
did
allo
w
himself
to
b
e
distracted
in
to
discussing
the
imitation
of
h
uman
fallibilit
y
in
arithmetic,
laziness,
and
the
abilit
y
to
use
the
English


----- Page 4 (native) -----
language.
Ho
w
ev
er,
w
ork
on
articial
in
telligence,
esp
ecially
general
in
telligence,
will
b
e
impro
v
ed
b
y
a
clearer
idea
of
what
in
telligence
is.
One
w
a
y
is
to
giv
e
a
purely
b
eha
vioural
or
blac
k-b
o
x
denition.
In
this
case
w
e
ha
v
e
to
sa
y
that
a
mac
hine
is
in
telligen
t
if
it
solv
es
certain
classes
of
problems
requiring
in
tel-
ligence
in
h
umans,
or
surviv
es
in
an
in
tellectually
demanding
en
vironmen
t.
This
denition
seems
v
ague;
p
erhaps
it
can
b
e
made
somewhat
more
precise
without
departing
from
b
eha
vioural
terms,
but
w
e
shall
not
try
to
do
so.
Instead,
w
e
shall
use
in
our
denition
certain
structures
apparen
t
to
in-
trosp
ection,
suc
h
as
kno
wledge
of
facts.
The
risk
is
t
w
ofold:
in
the
rst
place
w
e
migh
t
b
e
mistak
en
in
our
in
trosp
ectiv
e
views
of
our
o
wn
men
tal
structure;
w
e
ma
y
only
think
w
e
use
facts.
In
the
second
place
there
migh
t
b
e
en
tities
whic
h
satisfy
b
eha
viourist
criteria
of
in
telligence
but
are
not
organized
in
this
w
a
y
.
Ho
w
ev
er,
w
e
regard
the
construction
of
in
telligen
t
mac
hines
as
fact
manipulators
as
b
eing
the
b
est
b
et
b
oth
for
constructing
articial
in
telligence
and
understanding
natural
in
telligence.
W
e
shall,
therefore,
b
e
in
terested
in
an
in
telligen
t
en
tit
y
that
is
equipp
ed
with
a
represen
tation
or
mo
del
of
the
w
orld.
On
the
basis
of
this
represen
ta-
tion
a
certain
class
of
in
ternally
p
osed
questions
can
b
e
answ
ered,
not
alw
a
ys
correctly
.
Suc
h
questions
are
.
What
will
happ
en
next
in
a
certain
asp
ect
of
the
situation?
.
What
will
happ
en
if
I
do
a
certain
action?
.
What
is

+
?
.
What
do
es
he
w
an
t?
.
Can
I
gure
out
ho
w
to
do
this
or
m
ust
I
get
information
from
someone
else
or
something
else?
The
ab
o
v
e
are
not
a
fully
represen
tativ
e
set
of
questions
and
w
e
do
not
ha
v
e
suc
h
a
set
y
et.
On
this
basis
w
e
shall
sa
y
that
an
en
tit
y
is
in
telligen
t
if
it
has
an
adequate
mo
del
of
the
w
orld
(including
the
in
tellectual
w
orld
of
mathematics,
under-
standing
of
its
o
wn
goals
and
other
men
tal
pro
cesses),
if
it
is
clev
er
enough
to
answ
er
a
wide
v
ariet
y
of
questions
on
the
basis
of
this
mo
del,
if
it
can
get
additional
information
from
the
external
w
orld
when
required,
and
can
p
erform
suc
h
tasks
in
the
external
w
orld
as
its
goals
demand
and
its
ph
ysical
abilities
p
ermit.


----- Page 5 (native) -----
According
to
this
denition
in
telligence
has
t
w
o
parts,
whic
h
w
e
shall
call
the
epistemological
and
the
heuristic.
The
epistemological
part
is
the
represen
tation
of
the
w
orld
in
suc
h
a
form
that
the
solution
of
problems
follo
ws
from
the
facts
expressed
in
the
represen
tation.
The
heuristic
part
is
the
mec
hanism
that
on
the
basis
of
the
information
solv
es
the
problem
and
decides
what
to
do.
Most
of
the
w
ork
in
articial
in
telligence
so
far
can
b
e
regarded
as
dev
oted
to
the
heuristic
part
of
the
problem.
This
pap
er,
ho
w
ev
er,
is
en
tirely
dev
oted
to
the
epistemological
part.
Giv
en
this
notion
of
in
telligence
the
follo
wing
kinds
of
problems
arise
in
constructing
the
epistemological
part
of
an
articial
in
telligence:
.
What
kind
of
general
represen
tation
of
the
w
orld
will
allo
w
the
incorp
o-
ration
of
sp
ecic
observ
ations
and
new
scien
tic
la
ws
as
they
are
disco
v
ered?
.
Besides
the
represen
tation
of
the
ph
ysical
w
orld
what
other
kinds
of
en
tities
ha
v
e
to
b
e
pro
vided
for?
F
or
example,
mathematical
systems,
goals,
states
of
kno
wledge.
.
Ho
w
are
observ
ations
to
b
e
used
to
get
kno
wledge
ab
out
the
w
orld,
and
ho
w
are
the
other
kinds
of
kno
wledge
to
b
e
obtained?
In
particular
what
kinds
of
kno
wledge
ab
out
the
system's
o
wn
state
of
mind
are
to
b
e
pro
vided
for?
.
In
what
kind
of
in
ternal
notation
is
the
system's
kno
wledge
to
b
e
expressed?
These
questions
are
iden
tical
with
or
at
least
corresp
ond
to
some
tradi-
tional
questions
of
philosoph
y
,
esp
ecially
in
metaph
ysics,
epistemology
and
philosophic
logic.
Therefore,
it
is
imp
ortan
t
for
the
researc
h
w
ork
er
in
arti-
cial
in
telligence
to
consider
what
the
philosophers
ha
v
e
had
to
sa
y
.
Since
the
philosophers
ha
v
e
not
really
come
to
an
agreemen
t
in
00
y
ears
it
migh
t
seem
that
articial
in
telligence
is
in
a
rather
hop
eless
state
if
it
is
to
dep
end
on
getting
concrete
enough
information
out
of
philosoph
y
to
write
computer
programs.
F
ortunately
,
merely
undertaking
to
em
b
o
dy
the
philosoph
y
in
a
computer
program
in
v
olv
es
making
enough
philosophical
presupp
ositions
to
exclude
most
philosoph
y
as
irrelev
an
t.
Undertaking
to
construct
a
general
in
telligen
t
computer
program
seems
to
en
tail
the
follo
wing
presupp
ositions:
.
The
ph
ysical
w
orld
exists
and
already
con
tains
some
in
telligen
t
ma-
c
hines
called
p
eople.


----- Page 6 (native) -----
.
Information
ab
out
this
w
orld
is
obtainable
through
the
senses
and
is
expressible
in
ternally
.
.
Our
common-sense
view
of
the
w
orld
is
appro
ximately
correct
and
so
is
our
scien
tic
view.
.
The
righ
t
w
a
y
to
think
ab
out
the
general
problems
of
metaph
ysics
and
epistemology
is
not
to
attempt
to
clear
one's
o
wn
mind
of
all
kno
wledge
and
start
with
`Cogito
ergo
sum'
and
build
up
from
there.
Instead,
w
e
prop
ose
to
use
all
of
our
kno
wledge
to
construct
a
computer
program
that
kno
ws.
The
correctness
of
our
philosophical
system
will
b
e
tested
b
y
n
umerous
com-
parisons
b
et
w
een
the
b
eliefs
of
the
program
and
our
o
wn
observ
ations
and
kno
wledge.
(This
p
oin
t
of
view
corresp
onds
to
the
presen
tly
dominan
t
at-
titude
to
w
ards
the
foundations
of
mathematics.
W
e
study
the
structure
of
mathematical
systems|from
the
outside
as
it
w
ere|using
whatev
er
meta-
mathematical
to
ols
seem
useful
instead
of
assuming
as
little
as
p
ossible
and
building
up
axiom
b
y
axiom
and
rule
b
y
rule
within
a
system.)
.
W
e
m
ust
undertak
e
to
construct
a
rather
comprehensiv
e
philosophical
system,
con
trary
to
the
presen
t
tendency
to
study
problems
separately
and
not
try
to
put
the
results
together.
.
The
criterion
for
deniteness
of
the
system
b
ecomes
m
uc
h
stronger.
Unless,
for
example,
a
system
of
epistemology
allo
ws
us,
at
least
in
principle,
to
construct
a
computer
program
to
seek
kno
wledge
in
accordance
with
it,
it
m
ust
b
e
rejected
as
to
o
v
ague.
.
The
problem
of
`free
will'
assumes
an
acute
but
concrete
form.
Namely
,
in
common-sense
reasoning,
a
p
erson
often
decides
what
to
do
b
y
ev
aluating
the
results
of
the
dieren
t
actions
he
can
do.
An
in
telligen
t
program
m
ust
use
this
same
pro
cess,
but
using
an
exact
formal
sense
of
c
an,
m
ust
b
e
able
to
sho
w
that
it
has
these
alternativ
es
without
den
ying
that
it
is
a
deterministic
mac
hine.
.
The
rst
task
is
to
dene
ev
en
a
naiv
e,
common-sense
view
of
the
w
orld
precisely
enough
to
program
a
computer
to
act
accordingly
.
This
is
a
v
ery
dicult
task
in
itself.
W
e
m
ust
men
tion
that
there
is
one
p
ossible
w
a
y
of
getting
an
articial
in
telligence
without
ha
ving
to
understand
it
or
solv
e
the
related
philosophical
problems.
This
is
to
mak
e
a
computer
sim
ulation
of
natural
selection
in
whic
h
in
telligence
ev
olv
es
b
y
m
utating
computer
programs
in
a
suitably
demanding
en
vironmen
t.
This
metho
d
has
had
no
substan
tial
success
so
far,
p
erhaps
due
to
inadequate
mo
dels
of
the
w
orld
and
of
the
ev
olutionary
pro
cess,
but


----- Page 7 (native) -----
it
migh
t
succeed.
It
w
ould
seem
to
b
e
a
dangerous
pro
cedure,
for
a
program
that
w
as
in
telligen
t
in
a
w
a
y
its
designer
did
not
understand
migh
t
get
out
of
con
trol.
In
an
y
case,
the
approac
h
of
trying
to
mak
e
an
articial
in
telligence
through
understanding
what
in
telligence
is,
is
more
congenial
to
the
presen
t
authors
and
seems
lik
ely
to
succeed
so
oner.
.
Reasoning
programs
and
the
Missouri
program
The
philosophical
problems
that
ha
v
e
to
b
e
solv
ed
will
b
e
clearer
in
connec-
tion
with
a
particular
kind
of
prop
osed
in
telligen
t
program,
called
a
reasoning
program
or
RP
for
short.
RP
in
teracts
with
the
w
orld
through
input
and
output
devices
some
of
whic
h
ma
y
b
e
general
sensory
and
motor
organs
(for
example,
television
cameras,
microphones,
articial
arms)
and
others
of
whic
h
are
comm
uni
cation
devices
(for
example,
telet
yp
es
or
k
eyb
oard-displa
y
consoles).
In
ternally
,
RP
ma
y
represen
t
information
in
a
v
ariet
y
of
w
a
ys.
F
or
example,
pictures
ma
y
b
e
represen
ted
as
dot
arra
ys
or
a
list
of
regions
and
edges
with
classications
and
adjacency
relations.
Scenes
ma
y
b
e
represen
ted
as
lists
of
b
o
dies
with
p
ositions,
shap
es,
and
rates
of
motion.
Situations
ma
y
b
e
represen
ted
b
y
sym
b
olic
expressions
with
allo
w
ed
rules
of
transformation.
Utterances
ma
y
b
e
represen
ted
b
y
digitized
functions
of
time,
b
y
sequences
of
phonemes,
and
parsings
of
sen
tences.
Ho
w
ev
er,
one
represen
tation
pla
ys
a
dominan
t
role
and
in
simpler
systems
ma
y
b
e
the
only
represen
tation
presen
t.
This
is
a
represen
tation
b
y
sets
of
sen
tences
in
a
suitable
formal
logical
language,
for
example
!
-order
logic
with
function
sym
b
ols,
description
op
erator,
conditional
expressions,
sets,
etc.
Whether
w
e
m
ust
include
mo
dal
op
erators
with
their
referen
tial
opacit
y
is
undecided.
This
represen
tation
dominates
in
the
follo
wing
sense:
.
All
other
data
structures
ha
v
e
linguistic
descriptions
that
giv
e
the
relations
b
et
w
een
the
structures
and
what
they
tell
ab
out
the
w
orld.
.
The
subroutines
ha
v
e
linguistic
descriptions
that
tell
what
they
do,
either
in
ternally
manipulating
data,
or
externally
manipulating
the
w
orld.
.
The
rules
that
express
RP's
b
eliefs
ab
out
ho
w
the
w
orld
b
eha
v
es
and
that
giv
e
the
consequences
of
strategies
are
expressed
linguistically
.
.
RP's
goals,
as
giv
en
b
y
the
exp
erimen
ter,
its
devised
subgoals,
its
opinion
on
its
state
of
progress
are
all
linguistically
expressed.
.
W
e
shall
sa
y
that
RP's
information
is
adequate
to
solv
e
a
problem
if
it
is
a
logical
consequence
of
all
these
sen
tences
that
a
certain
strategy
of


----- Page 8 (native) -----
action
will
solv
e
it.
.
RP
is
a
deduction
program
that
tries
to
nd
strategies
of
action
that
it
can
pro
v
e
will
solv
e
a
problem;
on
nding
one,
it
executes
it.
.
Strategies
ma
y
in
v
olv
e
subgoals
whic
h
are
to
b
e
solv
ed
b
y
RP
,
and
part
or
all
of
a
strategy
ma
y
b
e
purely
in
tellectual,
that
is,
ma
y
in
v
olv
e
the
searc
h
for
a
strategy
,
a
pro
of,
or
some
other
in
tellectual
ob
ject
that
satises
some
criteria.
Suc
h
a
program
w
as
rst
discussed
in
McCarth
y
(		)
and
w
as
called
the
Advice
T
ak
er.
In
McCarth
y
(	)
a
preliminary
approac
h
to
the
required
formalism,
no
w
sup
erseded
b
y
this
pap
er,
w
as
presen
ted.
This
pap
er
is
in
part
an
answ
er
to
Y.
Bar-Hillel's
commen
t,
when
the
original
pap
er
w
as
presen
ted
at
the
	
Symp
osium
on
the
Mec
hanization
of
Though
t
Pro
cesses,
that
the
pap
er
in
v
olv
ed
some
philosophical
presupp
ositions.
Constructing
RP
in
v
olv
es
b
oth
the
epistemological
and
the
heuristic
parts
of
the
articial
in
telligence
problem:
that
is,
the
information
in
memory
m
ust
b
e
adequate
to
determine
a
strategy
for
ac
hieving
the
goal
(this
strategy
ma
y
in
v
olv
e
the
acquisition
of
further
information)
and
RP
m
ust
b
e
clev
er
enough
to
nd
the
strategy
and
the
pro
of
of
its
correctness.
Of
course,
these
problems
in
teract,
but
since
this
pap
er
is
fo
cused
on
the
epistemological
part,
w
e
men
tion
the
Missouri
program
(MP)
that
in
v
olv
es
only
this
part.
The
Missouri
program
(its
motto
is,
`Sho
w
me')
do
es
not
try
to
nd
strategies
or
pro
ofs
that
the
strategies
ac
hiev
e
a
goal.
Instead,
it
allo
ws
the
exp
erimen
ter
to
presen
t
it
pro
of
steps
and
c
hec
ks
their
correctness.
More-
o
v
er,
when
it
is
`con
vinced'
that
it
ough
t
to
p
erform
an
action
or
execute
a
strategy
it
do
es
so.
W
e
ma
y
regard
this
pap
er
as
b
eing
concerned
with
the
construction
of
a
Missouri
program
that
can
b
e
p
ersuaded
to
ac
hiev
e
goals.
.
Represen
tations
of
the
w
orld
The
rst
step
in
the
design
of
RP
or
MP
is
to
decide
what
structure
the
w
orld
is
to
b
e
regarded
as
ha
ving,
and
ho
w
information
ab
out
the
w
orld
and
its
la
ws
of
c
hange
are
to
b
e
represen
ted
in
the
mac
hine.
This
decision
turns
out
to
dep
end
on
whether
one
is
talking
ab
out
the
expression
of
general
la
ws
or
sp
ecic
facts.
Th
us,
our
understanding
of
gas
dynamics
dep
ends
on
the
represen
tation
of
a
gas
as
a
v
ery
large
n
um
b
er
of
particles
mo
ving
in
space;
this
represen
tation
pla
ys
an
essen
tial
role
in
deriving
the
mec
hanical,
thermal
electrical
and
optical
prop
erties
of
gases.
The
state
of
the
gas
at
a
giv
en


----- Page 9 (native) -----
instan
t
is
regarded
as
determined
b
y
the
p
osition,
v
elo
cit
y
and
excitation
states
of
eac
h
particle.
Ho
w
ev
er,
w
e
nev
er
actually
determine
the
p
osition,
v
elo
cit
y
or
excitation
of
ev
en
a
single
molecule.
Our
practical
kno
wledge
of
a
particular
sample
of
gas
is
expressed
b
y
parameters
lik
e
the
pressure,
temp
erature
and
v
elo
cit
y
elds
or
ev
en
more
grossly
b
y
a
v
erage
pressures
and
temp
eratures.
F
rom
our
philosophical
p
oin
t
of
view
this
is
en
tirely
normal,
and
w
e
are
not
inclined
to
den
y
existence
to
en
tities
w
e
cannot
see,
or
to
b
e
so
an
throp
o
cen
tric
as
to
imagine
that
the
w
orld
m
ust
b
e
so
constructed
that
w
e
ha
v
e
direct
or
ev
en
indirect
access
to
all
of
it.
F
rom
the
articial
in
telligence
p
oin
t
of
view
w
e
can
then
dene
three
kinds
of
adequacy
for
represen
tations
of
the
w
orld.
A
represen
tation
is
called
metaph
ysically
adequate
if
the
w
orld
could
ha
v
e
that
form
without
con
tradicting
the
facts
of
the
asp
ect
of
realit
y
that
in
terests
us.
Examples
of
metaph
ysically
adequate
represen
tations
for
dieren
t
asp
ects
of
realit
y
are:
.
The
represen
tation
of
the
w
orld
as
a
collection
of
particles
in
teracting
through
forces
b
et
w
een
eac
h
pair
of
particles.
.
Represen
tation
of
the
w
orld
as
a
gian
t
quan
tum-mec
hanical
w
a
v
e
func-
tion.
.
Represen
tation
as
a
system
of
in
teracting
discrete
automata.
W
e
shall
mak
e
use
of
this
represen
tation.
Metaph
ysically
adequate
represen
tations
are
mainly
useful
for
construct-
ing
general
theories.
Deriving
observ
able
consequences
from
the
theory
is
a
further
step.
A
represen
tation
is
called
epistemologically
adequate
for
a
p
erson
or
ma-
c
hine
if
it
can
b
e
used
practically
to
express
the
facts
that
one
actually
has
ab
out
the
asp
ect
of
the
w
orld.
Th
us
none
of
the
ab
o
v
e-men
tioned
represen-
tations
are
adequate
to
express
facts
lik
e
`John
is
at
home'
or
`dogs
c
hase
cats'
or
`John's
telephone
n
um
b
er
is
-0'.
Ordinary
language
is
ob
vi-
ously
adequate
to
express
the
facts
that
p
eople
comm
unic
ate
to
eac
h
other
in
ordinary
language.
It
is
not,
for
instance,
adequate
to
express
what
p
eo-
ple
kno
w
ab
out
ho
w
to
recognize
a
particular
face.
The
second
part
of
this
pap
er
is
concerned
with
an
epistemologically
adequate
formal
represen
tation
of
common-sense
facts
of
causalit
y
,
abilit
y
and
kno
wledge.
A
represen
tation
is
called
heuristically
adequate
if
the
reasoning
pro
cesses
actually
gone
through
in
solving
a
problem
are
expressible
in
the
language.

----- Page 10 (native) -----
W
e
shall
not
treat
this
somewhat
ten
tativ
ely
prop
osed
concept
further
in
this
pap
er
except
to
p
oin
t
out
later
that
one
particular
represen
tation
seems
epistemologically
but
not
heuristically
adequate.
In
the
remaining
sections
of
the
rst
part
of
the
pap
er
w
e
shall
use
the
represen
tations
of
the
w
orld
as
a
system
of
in
teracting
automata
to
explicate
notions
of
causalit
y
,
abilit
y
and
kno
wledge
(including
self-kno
wledge).
.
The
automaton
represen
tation
and
the
notion
of
`can'
Let
S
b
e
a
system
of
in
teracting
discrete
nite
automata
suc
h
as
that
sho
wn
in
Figure
.
10
1
1
9
4
3
2
5
8
7
6
3
2
Figure 1
Eac
h
b
o
x
represen
ts
a
subautomaton
and
eac
h
line
represen
ts
a
signal.
Time
tak
es
on
in
teger
v
alues
and
the
dynamic
b
eha
viour
of
the
whole
au-
tomaton
is
giv
en
b
y
the
equations:
0

----- Page 11 (native) -----
()
a

(t
+
)
=
A

(a

(t);
s

(t))
a

(t
+
)
=
A

(a

(t);
s

(t);
s

(t);
s
0
(t))
a

(t
+
)
=
A

(a

(t);
s

(t);
s

(t);
s

(t);
s

(t))
a

(t
+
)
=
A

(a

(t);
s

(t))
()
s

(t)
=
S

(a

(t))
s

(t)
=
S

(a

(t))
s

(t)
=
S

(a

(t))
s

(t)
=
S

(a

(t))
s

(t)
=
S

(a

(t))
s

(t)
=
S

(a

(t))
s
	
(t)
=
S
	
(a

(t))
s
0
(t)
=
S
0
(a

(t))
()
The
in
terpretation
of
these
equations
is
that
the
state
of
an
y
automaton
at
time
t
+

is
determined
b
y
its
state
at
time
t
and
b
y
the
signals
receiv
ed
at
time
t.
The
v
alue
of
a
particular
signal
at
time
t
is
determined
b
y
the
state
at
time
t
of
the
automaton
from
whic
h
it
comes.
Signals
without
a
source
automaton
represen
t
inputs
from
the
outside
and
signals
without
a
destination
represen
t
outputs.
Finite
automata
are
the
simplest
examples
of
systems
that
in
teract
o
v
er
time.
They
are
completely
deterministic
;
if
w
e
kno
w
the
initial
states
of
all
the
automata
and
if
w
e
kno
w
the
inputs
as
a
function
of
time,
the
b
eha
viour
of
the
system
is
completely
determined
b
y
equations
()
and
()
for
all
future
time.
The
automaton
represen
tation
consists
in
regarding
the
w
orld
as
a
system
of
in
teracting
subautomata.
F
or
example,
w
e
migh
t
regard
eac
h
p
erson
in
the
ro
om
as
a
subautomaton
and
the
en
vironmen
t
as
consisting
of
one
or
more
additional
subautomata.
As
w
e
shall
see,
this
represen
tation
has
man
y
of
the
qualitativ
e
prop
erties
of
in
teractions
among
things
and
p
ersons.
Ho
w
ev
er,
if
w
e
tak
e
the
represen
tation
to
o
seriously
and
attempt
to
represen
t
particular
situations
b
y
systems
of
in
teracting
automata,
w
e
encoun
ter
the
follo
wing
diculties:
.
The
n
um
b
er
of
states
required
in
the
subautomata
is
v
ery
large,
for
example

0
0
,
if
w
e
try
to
represen
t
someone's
kno
wledge.
Automata
this
large
ha
v
e
to
b
e
represen
ted
b
y
computer
programs,
or
in
some
other
w
a
y
that
do
es
not
in
v
olv
e
men
tioning
states
individually
.


----- Page 12 (native) -----
.
Geometric
information
is
hard
to
represen
t.
Consider,
for
example,
the
lo
cation
of
a
m
ulti-join
ted
ob
ject
suc
h
as
a
p
erson
or
a
matter
of
ev
en
more
dicult
y|the
shap
e
of
a
lump
of
cla
y
.
.
The
system
of
xed
in
terconnections
is
inadequate.
Since
a
p
erson
ma
y
handle
an
y
ob
ject
in
the
ro
om,
an
adequate
automaton
represen
tation
w
ould
require
signal
lines
connecting
him
with
ev
ery
ob
ject.
.
The
most
serious
ob
jection,
ho
w
ev
er,
is
that
(in
our
terminology)
the
automaton
represen
tation
is
epistemologically
inadequate.
Namely
,
w
e
do
not
ev
er
kno
w
a
p
erson
w
ell
enough
to
list
his
in
ternal
states.
The
kind
of
information
w
e
do
ha
v
e
ab
out
him
needs
to
b
e
expressed
in
some
other
w
a
y
.
Nev
ertheless,
w
e
ma
y
use
the
automaton
represen
tation
for
concepts
of
c
an,
c
auses,
some
kinds
of
coun
terfactual
statemen
ts
(`If
I
had
struc
k
this
matc
h
y
esterda
y
it
w
ould
ha
v
e
lit')
and,
with
some
elab
oration
of
the
repre-
sen
tation,
for
a
concept
of
b
elieves.
1
2
3
1
2
3
Figure 2.  System S.
1
2
3
2
3
1
Figure 3.  System S.
Let
us
consider
the
notion
of
c
an.
Let
S
b
e
a
system
of
subautomata
without
external
inputs
suc
h
as
that
of
Figure
.
Let
p
b
e
one
of
the
subau-
tomata,
and
supp
ose
that
there
are
m
signal
lines
coming
out
of
p.
What
p


----- Page 13 (native) -----
can
do
is
dened
in
terms
of
a
new
system
S
p
,
whic
h
is
obtained
from
the
system
S
b
y
disconnecting
the
m
signal
lines
coming
from
p
and
replacing
them
b
y
m
external
input
lines
to
the
system.
In
Figure
,
subautomaton

has
one
output,
and
in
the
system
S

(Figure
)
this
is
replaced
b
y
an
external
input.
The
new
system
S
p
alw
a
ys
has
the
same
set
of
states
as
the
system
S
.
No
w
let

b
e
a
condition
on
the
state
suc
h
as,
`a

is
ev
en'
or
`a

=
a

'.
(In
the
applications

ma
y
b
e
a
condition
lik
e
`The
b
o
x
is
under
the
bananas'.)
W
e
shall
write
can(p;

;
s)
whic
h
is
read,
`The
subautomaton
p
c
an
bring
ab
out
the
condition

in
the
situation
s'
if
there
is
a
sequence
of
outputs
from
the
automaton
S
p
that
will
ev
en
tually
put
S
in
to
a
state
a
0
that
satises

(a
0
).
In
other
w
ords,
in
determining
what
p
can
ac
hiev
e,
w
e
consider
the
eects
of
sequences
of
its
actions,
quite
apart
from
the
conditions
that
determine
what
it
actually
will
do.
In
Figure
,
let
us
consider
the
initial
state
a
to
b
e
one
in
whic
h
all
subautomata
are
initially
in
state
0.
Then
the
reader
will
easily
v
erify
the
follo
wing
prop
ositions:
.
Subautomaton

wil
l
nev
er
b
e
in
state
.
.
Subautomaton

c
an
put
subautomaton

in
state
.
.
Subautomaton

c
annot
put
subautomaton

in
state
.
Figure
.
System
S
a

(t
+
)
=
a

(t)
+
s

(t)
a

(t
+
)
=
a

(t)
+
s

(t)
+
s

(t)
a

(t
+
)
=
if
a

(t)
=
0
then
0
else
a

(t)
+

s

(t)
=
if
a

(t)
=
0
then

else

s

(t)
=

s

(t)
=
if
a

(t)
=
0
then
0
else

W
e
claim
that
this
notion
of
can
is,
to
a
rst
appro
ximation,
the
ap-
propriate
one
for
an
automaton
to
use
in
ternally
in
deciding
what
to
do
b
y
reasoning.
W
e
also
claim
that
it
corresp
onds
in
man
y
cases
to
the
common
sense
notion
of
can
used
in
ev
eryda
y
sp
eec
h.
In
the
rst
place,
supp
ose
w
e
ha
v
e
an
automaton
that
decides
what
to
do
b
y
reasoning;
for
example,
supp
ose
it
is
a
computer
using
an
RP
.
Then
its
output
is
determined
b
y
the
decisions
it
mak
es
in
the
reasoning
pro
cess.
It


----- Page 14 (native) -----
do
es
not
kno
w
(has
not
computed)
in
adv
ance
what
it
will
do,
and,
therefore,
it
is
appropriate
that
it
considers
that
it
can
do
an
ything
that
can
b
e
ac
hiev
ed
b
y
some
sequence
of
its
outputs.
Common-sense
reasoning
seems
to
op
erate
in
the
same
w
a
y
.
The
ab
o
v
e
rather
simple
notion
of
can
requires
some
elab
oration,
b
oth
to
represen
t
adequately
the
commonsense
notion
and
for
practical
purp
oses
in
the
reasoning
program.
First,
supp
ose
that
the
system
of
automata
admits
external
inputs.
There
are
t
w
o
w
a
ys
of
dening
can
in
this
case.
One
w
a
y
is
to
assert
can(p;

;
s)
if
p
can
ac
hiev
e

regardless
of
what
signals
app
ear
on
the
external
inputs.
Th
us,
w
e
require
the
existence
of
a
sequence
of
outputs
of
p
that
ac
hiev
es
the
goal
regardless
of
the
sequence
of
external
inputs
to
the
system.
Note
that,
in
this
denition
of
can,
w
e
are
not
requiring
that
p
ha
v
e
an
y
w
a
y
of
kno
wing
what
the
external
inputs
w
ere.
An
alternativ
e
denition
requires
the
outputs
to
dep
end
on
the
inputs
of
p.
This
is
equiv
alen
t
to
sa
ying
that
p
can
ac
hiev
e
a
goal,
pro
vided
the
goal
w
ould
b
e
ac
hiev
ed
for
arbitrary
inputs
b
y
some
automaton
put
in
place
of
p.
With
either
of
these
denitions
can
b
ecomes
a
function
of
the
place
of
the
subautomaton
in
the
system
rather
than
of
the
subautomaton
itself.
W
e
do
not
kno
w
whic
h
of
these
treatmen
ts
is
preferable,
and
so
w
e
shall
call
the
rst
concept
cana
and
the
second
canb.
The
idea
that
what
a
p
erson
can
do
dep
ends
on
his
p
osition
rather
than
on
his
c
haracteristics
is
somewhat
coun
ter-in
tuitiv
e.
This
impression
can
b
e
mitigated
as
follo
ws:
Imagine
the
p
erson
to
b
e
made
up
of
sev
eral
subau-
tomata;
the
output
of
the
outer
subautomaton
is
the
motion
of
the
join
ts.
If
w
e
break
the
connection
to
the
w
orld
at
that
p
oin
t
w
e
can
answ
er
questions
lik
e,
`Can
he
t
through
a
giv
en
hole?'
W
e
shall
get
some
coun
ter-in
tuitiv
e
answ
ers,
ho
w
ev
er,
suc
h
as
that
he
can
run
at
top
sp
eed
for
an
hour
or
can
jump
o
v
er
a
building,
since
these
are
sequences
of
motions
of
his
join
ts
that
w
ould
ac
hiev
e
these
results.
The
next
step,
ho
w
ev
er,
is
to
consider
a
subautomaton
that
receiv
es
the
nerv
e
impulses
from
the
spinal
cord
and
transmits
them
to
the
m
uscles.
If
w
e
break
at
the
input
to
this
automaton,
w
e
shall
no
longer
sa
y
that
he
can
jump
o
v
er
a
building
or
run
long
at
top
sp
eed
since
the
limitations
of
the
m
uscles
will
b
e
tak
en
in
to
accoun
t.
W
e
shall,
ho
w
ev
er,
sa
y
that
he
can
ride
a
unicycle
since
appropriate
nerv
e
signals
w
ould
ac
hiev
e
this
result.
The
notion
of
can
corresp
onding
to
the
in
tuitiv
e
notion
in
the
largest
n
um
b
er
of
cases
migh
t
b
e
obtained
b
y
h
yp
othesizing
an
or
gan
of
wil
l,
whic
h
mak
es
decisions
to
do
things
and
transmits
these
decisions
to
the
main
part


----- Page 15 (native) -----
of
the
brain
that
tries
to
carry
them
out
and
con
tains
all
the
kno
wledge
of
particular
facts.
If
w
e
mak
e
the
break
at
this
p
oin
t
w
e
shall
b
e
able
to
sa
y
that
so-and-so
cannot
dial
the
Presiden
t's
secret
and
priv
ate
telephone
n
um
b
er
b
ecause
he
do
es
not
kno
w
it,
ev
en
though
if
the
question
w
ere
ask
ed
could
he
dial
that
particular
n
um
b
er,
the
answ
er
w
ould
b
e
y
es.
Ho
w
ev
er,
ev
en
this
break
w
ould
not
giv
e
the
statemen
t,
`I
cannot
go
without
sa
ying
go
o
db
y
e,
b
ecause
this
w
ould
h
urt
the
c
hild's
feelings'.
On
the
basis
of
these
examples,
one
migh
t
try
to
p
ostulate
a
sequence
of
narro
w
er
and
narro
w
er
notions
of
can
terminating
in
a
notion
according
to
whic
h
a
p
erson
can
do
only
what
he
actually
do
es.
This
notion
w
ould
then
b
e
sup
eruous.
Actually
,
one
should
not
lo
ok
for
a
single
b
est
notion
of
can;
eac
h
of
the
ab
o
v
e-men
tioned
notions
is
useful
and
is
actually
used
in
some
circumstances.
Sometimes,
more
than
one
notion
is
used
in
a
single
sen
tence,
when
t
w
o
dieren
t
lev
els
of
constrain
t
are
men
tioned.
Besides
its
use
in
explicating
the
notion
of
can,
the
automaton
represen-
tation
of
the
w
orld
is
v
ery
suited
for
dening
notions
of
causalit
y
.
F
or,
w
e
ma
y
sa
y
that
subautomaton
p
caused
the
condition

in
state
s,
if
c
hang-
ing
the
output
of
p
w
ould
prev
en
t

.
In
fact
the
whole
idea
of
a
system
of
in
teracting
automata
is
just
a
formalization
of
the
commonsense
notion
of
causalit
y
.
Moreo
v
er,
the
automaton
represen
tation
can
b
e
used
to
explicate
certain
coun
terfactual
conditional
sen
tences.
F
or
example,
w
e
ha
v
e
the
sen
tence,
`If
I
had
struc
k
this
matc
h
y
esterda
y
at
this
time
it
w
ould
ha
v
e
lit.'
In
a
suitable
automaton
represen
tation,
w
e
ha
v
e
a
certain
state
of
the
system
y
esterda
y
at
that
time,
and
w
e
imagine
a
break
made
where
the
nerv
es
lead
from
m
y
head
or
p
erhaps
at
the
output
of
m
y
`decision
b
o
x',
and
the
appropriate
signals
to
strik
e
the
matc
h
ha
ving
b
een
made.
Then
it
is
a
denite
and
decidable
question
ab
out
the
system
S
p
,
whether
the
matc
h
ligh
ts
or
not,
dep
ending
on
whether
it
is
w
et,
etc.
This
in
terpretation
of
this
kind
of
coun
terfactual
sen
tence
seems
to
b
e
what
is
needed
for
RP
to
learn
from
its
mistak
es,
b
y
accepting
or
generating
sen
tences
of
the
form,
`had
I
done
th
us-and-so
I
w
ould
ha
v
e
b
een
successful,
so
I
should
alter
m
y
pro
cedures
in
some
w
a
y
that
w
ould
ha
v
e
pro
duced
the
correct
action
in
that
case'.
In
the
foregoing
w
e
ha
v
e
tak
en
the
represen
tation
of
the
situation
as
a
system
of
in
teracting
subautomata
for
gran
ted.
Ho
w
ev
er,
a
giv
en
o
v
erall
situation
migh
t
b
e
represen
ted
as
a
system
of
in
teracting
subautomata
in
a
n
um
b
er
of
w
a
ys,
and
dieren
t
represen
tations
migh
t
yield
dieren
t
results
ab
out
what
a
giv
en
subautomaton
can
ac
hiev
e,
what
w
ould
ha
v
e
happ
ened


----- Page 16 (native) -----
if
some
subautomaton
had
acted
dieren
tly
,
or
what
caused
what.
Indeed,
in
a
dieren
t
represen
tation,
the
same
or
corresp
onding
subautomata
migh
t
not
b
e
iden
tiable.
Therefore,
these
notions
dep
end
on
the
represen
tation
c
hosen.
F
or
example,
supp
ose
a
pair
of
Martians
observ
e
the
situation
in
a
ro
om.
One
Martian
analyzes
it
as
a
collection
of
in
teracting
p
eople
as
w
e
do,
but
the
second
Martian
groups
all
the
heads
together
in
to
one
subautomaton
and
all
the
b
o
dies
in
to
another.
(A
creature
from
momen
tum
space
w
ould
regard
the
F
ourier
comp
onen
ts
of
the
distribution
of
matter
as
the
separate
in
teracting
subautomata.)
Ho
w
is
the
rst
Martian
to
con
vince
the
second
that
his
represen
tation
is
to
b
e
preferred?
Roughly
sp
eaking,
he
w
ould
argue
that
the
in
teraction
b
et
w
een
the
heads
and
b
o
dies
of
the
same
p
erson
is
closer
than
the
in
teraction
b
et
w
een
the
dieren
t
heads,
and
so
more
of
an
analysis
has
b
een
ac
hiev
ed
from
`the
primordial
m
uddle'
with
the
con
v
en
tional
represen
tation.
He
will
b
e
esp
ecially
con
vincing
when
he
p
oin
ts
out
that
when
the
meeting
is
o
v
er
the
heads
will
stop
in
teracting
with
eac
h
other,
but
will
con
tin
ue
to
in
teract
with
their
resp
ectiv
e
b
o
dies.
W
e
can
express
this
kind
of
argumen
t
formally
in
terms
of
automata
as
follo
ws:
Supp
ose
w
e
ha
v
e
an
autonomous
automaton
A,
that
is
an
automaton
without
inputs,
and
let
it
ha
v
e
k
states.
F
urther,
let
m
and
n
b
e
t
w
o
in
tegers
suc
h
that
m;
n

k
.
No
w
lab
el
k
p
oin
ts
of
an
m-b
y-n
arra
y
with
the
states
of
A.
This
can
b
e
done
in

mn
k

!
w
a
ys.
F
or
eac
h
of
these
w
a
ys
w
e
ha
v
e
a
represen
tation
of
the
automaton
A
as
a
system
of
an
m-state
automaton
B
in
teracting
with
an
n-state
automaton
C
.
Namely
,
corresp
onding
to
eac
h
ro
w
of
the
arra
y
w
e
ha
v
e
a
state
of
B
and
to
eac
h
column
a
state
of
C
.
The
signals
are
in
{
corresp
ondence
with
the
states
themselv
es;
th
us
eac
h
subautomaton
has
just
as
man
y
v
alues
of
its
output
as
it
has
states.
No
w
it
ma
y
happ
en
that
t
w
o
of
these
signals
are
equiv
alen
t
in
their
eect
on
the
other
subautomaton,
and
w
e
use
this
equiv
alence
relation
to
form
equiv
alence
classes
of
signals.
W
e
ma
y
then
regard
the
equiv
alence
classes
as
the
signals
themselv
es.
Supp
ose
then
that
there
are
no
w
r
signals
from
B
to
C
and
s
signals
from
C
to
B
.
W
e
ask
ho
w
small
r
and
s
can
b
e
tak
en
in
general
compared
to
m
and
n.
The
answ
er
ma
y
b
e
obtained
b
y
coun
ting
the
n
um
b
er
of
inequiv
alen
t
automata
with
k
states
and
comparing
it
with
the
n
um
b
er
of
systems
of
t
w
o
automata
with
m
and
n
states
resp
ectiv
ely
and
r
and
s
signals
going
in
the
resp
ectiv
e
directions.
The
result
is
not
w
orth
w
orking
out
in
detail,
but
tells
us
that
only
a
few
of
the
k
state
automata
admit
suc
h
a
decomp
osition
with
r
and
s
small
compared
to
m
and
n.
Therefore,
if


----- Page 17 (native) -----
an
automaton
happ
ens
to
admit
suc
h
a
decomp
osition
it
is
v
ery
un
usual
for
it
to
admit
a
second
suc
h
decomp
osition
that
is
not
equiv
alen
t
to
the
rst
with
resp
ect
to
some
renaming
of
states.
Applying
this
argumen
t
to
the
real
w
orld,
w
e
ma
y
sa
y
that
it
is
o
v
erwhelmingly
probable
that
our
customary
decomp
osition
of
the
w
orld
automaton
in
to
separate
p
eople
and
things
has
a
unique,
ob
jectiv
e
and
usually
preferred
status.
Therefore,
the
notions
of
can,
of
causalit
y
,
and
of
coun
terfactual
asso
ciated
with
this
decomp
osition
also
ha
v
e
a
preferred
status.
In
our
opinion,
this
explains
some
of
the
dicult
y
philosophers
ha
v
e
had
in
analyzing
coun
terfactuals
and
causalit
y
.
F
or
example,
the
sen
tence,
`If
I
had
struc
k
this
matc
h
y
esterda
y
,
it
w
ould
ha
v
e
lit'
is
meaningful
only
in
terms
of
a
rather
complicated
mo
del
of
the
w
orld,
whic
h,
ho
w
ev
er,
has
an
ob
jectiv
e
preferred
status.
Ho
w
ev
er,
the
preferred
status
of
this
mo
del
de-
p
ends
on
its
corresp
ondence
with
a
large
n
um
b
er
of
facts.
F
or
this
reason,
it
is
probably
not
fruitful
to
treat
an
individual
coun
terfactual
conditional
sen
tence
in
isolation.
It
is
also
p
ossible
to
treat
notions
of
b
elief
and
kno
wledge
in
terms
of
the
automaton
represen
tation.
W
e
ha
v
e
not
w
ork
ed
this
out
v
ery
far,
and
the
ideas
presen
ted
here
should
b
e
regarded
as
ten
tativ
e.
W
e
w
ould
lik
e
to
b
e
able
to
giv
e
conditions
under
whic
h
w
e
ma
y
sa
y
that
a
subautomaton
p
b
eliev
es
a
certain
prop
osition.
W
e
shall
not
try
to
do
this
directly
but
only
relativ
e
to
a
predicate
B
p
(s;
w
).
Here
s
is
the
state
of
the
automaton
p
and
w
is
a
prop
osition;
B
p
(s;
w
)
is
true
if
p
is
to
b
e
regarded
as
b
elieving
w
when
in
state
s
and
is
false
otherwise.
With
resp
ect
to
suc
h
a
predicate
B
w
e
ma
y
ask
the
follo
wing
questions:
.
Are
p's
b
eliefs
consisten
t?
Are
they
correct?
.
Do
es
p
reason?
That
is,
do
new
b
eliefs
arise
that
are
logical
conse-
quences
of
previous
b
eliefs?
.
Do
es
p
observ
e?
That
is,
do
true
prop
ositions
ab
out
automata
con-
nected
to
p
cause
p
to
b
eliev
e
them?
.
Do
es
p
b
eha
v
e
rationally?
That
is,
when
p
b
eliev
es
a
sen
tence
asserting
that
it
should
do
something
do
es
p
do
it?
.
Do
es
p
comm
unic
ate
in
language
L?
That
is,
regarding
the
con
ten
t
of
a
certain
input
or
output
signal
line
as
in
a
text
in
language
L,
do
es
this
line
transmit
b
eliefs
to
or
from
p?
.
Is
p
self-conscious?
That
is,
do
es
it
ha
v
e
a
fair
v
ariet
y
of
correct
b
eliefs
ab
out
its
o
wn
b
eliefs
and
the
pro
cesses
that
c
hange
them?


----- Page 18 (native) -----
It
is
only
with
resp
ect
to
the
predicate
B
p
that
all
these
questions
can
b
e
ask
ed.
Ho
w
ev
er,
if
questions

thru

are
answ
ered
armativ
ely
for
some
predicate
B
p
,
this
is
certainly
remark
able,
and
w
e
w
ould
feel
fully
en
titled
to
consider
B
p
a
reasonable
notion
of
b
elief.
In
one
imp
ortan
t
resp
ect
the
situation
with
regard
to
b
elief
or
kno
wledge
is
the
same
as
it
w
as
for
coun
terfactual
conditional
statemen
ts:
no
w
a
y
is
pro
vided
to
assign
a
meaning
to
a
single
statemen
t
of
b
elief
or
kno
wledge,
since
for
an
y
single
statemen
t
a
suitable
B
p
can
easily
b
e
constructed.
Indi-
vidual
statemen
ts
ab
out
b
elief
or
kno
wledge
are
made
on
the
basis
of
a
larger
system
whic
h
m
ust
b
e
v
alidated
as
a
whole.

F
ORMALISM
In
part

w
e
sho
w
ed
ho
w
the
concepts
of
abilit
y
and
b
elief
could
b
e
giv
en
formal
denition
in
the
metaph
ysically
adequate
automaton
mo
del
and
indi-
cated
the
corresp
ondence
b
et
w
een
these
formal
concepts
and
the
corresp
ond-
ing
commonsense
concepts.
W
e
emphasized,
ho
w
ev
er,
that
practical
systems
require
epistemologically
adequate
systems
in
whic
h
those
facts
whic
h
are
actually
ascertainable
can
b
e
expressed.
In
this
part
w
e
b
egin
the
construction
of
an
epistemologically
adequate
system.
Instead
of
giving
formal
denitions,
ho
w
ev
er,
w
e
shall
in
tro
duce
the
formal
notions
b
y
informal
natural-language
descriptions
and
giv
e
examples
of
their
use
to
describ
e
situations
and
the
p
ossibilities
for
action
they
presen
t.
The
formalism
presen
ted
is
in
tended
to
sup
ersede
that
of
McCarth
y
(	).
.
Situations
A
situation
s
is
the
complete
state
of
the
univ
erse
at
an
instan
t
of
time.
W
e
denote
b
y
S
it
the
set
of
all
situations.
Since
the
univ
erse
is
to
o
large
for
complete
description,
w
e
shall
nev
er
completely
describ
e
a
situation;
w
e
shall
only
giv
e
facts
ab
out
situations.
These
facts
will
b
e
used
to
deduce
further
facts
ab
out
that
situation,
ab
out
future
situations
and
ab
out
situations
that
p
ersons
can
bring
ab
out
from
that
situation.
This
requires
that
w
e
consider
not
only
situations
that
actually
o
ccur,
but
also
h
yp
othetical
situations
suc
h
as
the
situation
that
w
ould
arise
if
Mr.
Smith
sold
his
car
to
a
certain
p
erson
who
has
oered
$0
for
it.
Since
he
is
not
going
to
sell
the
car
for
that
price,
the
h
yp
othetical
situation
is
not


----- Page 19 (native) -----
completely
dened;
for
example,
it
is
not
determined
what
Smith's
men
tal
state
w
ould
b
e
and
therefore
it
is
also
undetermined
ho
w
quic
kly
he
w
ould
return
to
his
oce,
etc.
Nev
ertheless,
the
represen
tation
of
realit
y
is
adequate
to
determine
some
facts
ab
out
this
situation,
enough
at
least
to
mak
e
him
decide
not
to
sell
the
car.
W
e
shall
further
assume
that
the
la
ws
of
motion
determine,
giv
en
a
situ-
ation,
all
future
situations.

In
order
to
giv
e
partial
information
ab
out
situations
w
e
in
tro
duce
the
notion
of
uen
t.
.
Fluen
ts
A
uent
is
a
function
whose
domain
is
the
space
S
it
of
situations.
If
the
range
of
the
function
is
(tr
ue;
f
al
se),
then
it
is
called
a
prop
ositional
uen
t.
If
its
range
is
S
it,
then
it
is
called
a
situational
uent.
Fluen
ts
are
often
the
v
alues
of
functions.
Th
us
r
aining
(x)
is
a
uen
t
suc
h
that
r
aining
(x)(s)
is
true
if
and
only
if
it
is
raining
at
the
place
x
in
the
situation
s.
W
e
can
also
write
this
assertion
as
r
aining
(x;
s)
making
use
of
the
w
ell-kno
wn
equiv
alence
b
et
w
een
a
function
of
t
w
o
v
ariables
and
a
function
of
the
rst
v
ariable
whose
v
alue
is
a
function
of
the
second
v
ariable.
Supp
ose
w
e
wish
to
assert
ab
out
a
situation
s
that
p
erson
p
is
in
place
x
and
that
it
is
raining
in
place
x.
W
e
ma
y
write
this
in
sev
eral
w
a
ys
eac
h
of
whic
h
has
its
uses:
.
at(p;
x)(s)
^
r
aining
(x)(s).
This
corresp
onds
to
the
denition
giv
en.
.
at(p;
x;
s)
^
r
aining
(x;
s).
This
is
more
con
v
en
tional
mathematicall
y
and
a
bit
shorter.
.
[at(p;
x)
^
r
aining
(x)](s).
Here
w
e
are
in
tro
ducing
a
con
v
en
tion
that
op
erators
applied
to
uen
ts
giv
e
uen
ts
whose
v
alues
are
computed
b
y
ap-
plying
the
logical
op
erators
to
the
v
alues
of
the
op
erand
uen
ts,
that
is,
if
f
and
g
are
uen
ts
then
(f
op
g
)(s)
=
f
(s)
op
g
(s):
.
[s
0
:at(p;
x;
s
0
)
^
r
aining
(x;
s
0
)](s).
Here
w
e
ha
v
e
formed
the
comp
osite
uen
t
b
y
-abstraction.

This
assumption
is
dicult
to
reconcile
with
quan
tum
mec
hanics,
and
relativit
y
tells
us
that
an
y
assignmen
t
of
sim
ultaneit
y
to
ev
en
ts
in
dieren
t
places
is
arbitrary
.
Ho
w
ev
er,
w
e
are
pro
ceeding
on
the
basis
that
mo
dern
ph
ysics
is
irrelev
an
t
to
common
sense
in
deciding
what
to
do,
and
in
particular
is
irrelev
an
t
to
solving
the
`free
will
problem'.


----- Page 20 (native) -----
Here
are
some
examples
of
uen
ts
and
expressions
in
v
olving
them:
.
time(s).
This
is
the
time
asso
ciated
with
the
situation
s.
It
is
essen
tial
to
consider
time
as
dep
enden
t
on
the
situation
as
w
e
shall
sometimes
wish
to
consider
sev
eral
dieren
t
situations
ha
ving
the
same
time
v
alue,
for
example,
the
results
of
alternativ
e
courses
of
actions.
.
in(x;
y
;
s).
This
asserts
that
x
is
in
the
lo
cation
y
in
situation
s.
The
uen
t
in
ma
y
b
e
tak
en
as
satisfying
a
kind
of
transitiv
e
la
w,
namely:
x:y
:

z
:

s:
in(x;
y
;
s)
^
in(y
;
z
;
s)
!
in(x;
z
;
s):
W
e
can
also
write
this
la
w
x:y
:
z
:
:in(x
;
y
)
^
in(y
;
z
)
!
in(x;
z
)
where
w
e
ha
v
e
adopted
the
con
v
en
tion
that
a
quan
tier
without
a
v
ariable
is
applied
to
an
implici
t
situation
v
ariable
whic
h
is
the
(suppressed)
argumen
t
of
a
prop
ositional
uen
t
that
follo
ws.
Suppressing
situation
argumen
ts
in
this
w
a
y
corresp
onds
to
the
natural
language
con
v
en
tion
of
writing
sen
tences
lik
e,
`John
w
as
at
home'
or
`John
is
at
home'
lea
ving
understo
o
d
the
situations
to
whic
h
these
assertions
apply
.
.
has(M
onk
ey
;
B
ananas;
s).
Here
w
e
in
tro
duce
the
con
v
en
tion
that
capitalized
w
ords
denote
prop
er
names,
for
example,
`Monk
ey'
is
the
name
of
a
particular
individual.
That
the
individual
is
a
monk
ey
is
not
asserted,
so
that
the
expression
monk
ey
(M
onk
ey
)
ma
y
ha
v
e
to
app
ear
among
the
premisses
of
an
argumen
t.
Needless
to
sa
y
,
the
reader
has
a
righ
t
to
feel
that
he
has
b
een
giv
en
a
hin
t
that
the
individual
Monk
ey
will
turn
out
to
b
e
a
monk
ey
.
The
ab
o
v
e
expression
is
to
b
e
tak
en
as
asserting
that
in
the
situation
s
the
individual
M
onk
ey
has
the
ob
ject
B
ananas.
W
e
shall,
in
the
examples
b
elo
w,
sometimes
omit
premisses
suc
h
as
monk
ey
(M
onk
ey
),
but
in
a
complete
system
they
w
ould
ha
v
e
to
app
ear.
.
Causalit
y
W
e
shall
mak
e
assertions
of
causalit
y
b
y
means
of
a
uen
t
F
(
)
where

is
itself
a
prop
ositional
uen
t.
F
(
;
s)
asserts
that
the
situation
s
will
b
e
follo
w
ed
(after
an
unsp
ecied
time)
b
y
a
situation
that
satises
the
uen
t

.
W
e
ma
y
use
F
to
assert
that
if
a
p
erson
is
out
in
the
rain
he
will
get
w
et,
b
y
writing:
x:
p:
s:r
a
ining
(x;
s)
^
at(p;
x;
s)
^
outside(p;
s)
!
F
(s
0
:w
et(p;
s
0
);
s):
0

----- Page 21 (native) -----
Suppressing
explicit
men
tion
of
situations
giv
es:
x:p:
r
aining
(x)
^
at(p;
x)
^
outside(p)
!
F
(w
et(p)):
In
this
case
suppressing
situations
simplies
the
statemen
t.
F
can
also
b
e
used
to
express
ph
ysical
la
ws.
Consider
the
la
w
of
falling
b
o
dies
whic
h
is
often
written
h
=
h
0
+
v
0

(t
 t
0
)
 

g

(t
 t
0
)

together
with
some
prose
iden
tifying
the
v
ariables.
Since
w
e
need
a
formal
system
for
mac
hine
reasoning
w
e
cannot
ha
v
e
an
y
prose.
Therefore,
w
e
write:
b:
t:
s:f
all
ing
(b;
s)
^
t

0
^
heig
ht(b;
s)
+
v
el
ocity
(b;
s)

t
 

g
t

>
0
!
F
(s
0
:time(s
0
)
=
time(s)
+
t
^
f
al
l
ing
(b;
s
0
)
^
heig
ht(b;
s
0
)
=
heig
ht(b;
s)
+
v
el
ocity
(b;
s)

t
 

g
t

;
s):
()
Suppressing
explicit
men
tion
of
situations
in
this
case
requires
the
in
tro-
duction
of
real
auxiliary
quan
tities
v
,
h
and

so
that
the
sen
tence
tak
es
the
follo
wing
form:
b:
t:


:
v
:

h:

[
f
al
l
ing
(b)
^
t

0
^
h
=
heig
ht(b)
^
v
=
v
el
ocity
(b)
^
h
+
v
t
 

g
t

>
0
^time
=

!
F
(time
=
t
+

^
f
al
l
ing
(b)
^
heig
ht(b)
=
h
+
v
t
 

g
t

)]:
()
There
has
to
b
e
a
con
v
en
tion
(or
declarations)
so
that
it
is
determined
that
heig
ht(b),
v
el
ocity
(b)
and
time
are
uen
ts,
whereas
t,
v
,

and
h
denote
ordinary
real
n
um
b
ers.
F
(
;
s)
as
in
tro
duced
here
corresp
onds
to
A.
N.
Prior's
(	,
	)
ex-
pression
F

.
The
use
of
situation
v
ariables
is
analogous
to
the
use
of
time-instan
ts
in
the
calculi
of
w
orld-states
whic
h
Prior
(	)
calls
U
-T
calculi.
Prior
pro-
vides
man
y
in
teresting
corresp
ondences
b
et
w
een
his
U
-T
calculi
and
v
arious
axiomatizations
of
the
mo
dal
tense-logics
(that
is,
using
this
F
-op
erator:
see
part
).
Ho
w
ev
er,
the
situation
calculus
is
ric
her
than
an
y
of
the
tense-logics
Prior
considers.


----- Page 22 (native) -----
Besides
F
he
in
tro
duces
three
other
op
erators
whic
h
w
e
also
nd
useful;
w
e
th
us
ha
v
e:
.
F
(
;
s).
F
or
some
situation
s
0
in
the
future
of
s;

(s
0
)
holds.
.
G(
;
s):
F
or
all
situations
s
0
in
the
future
of
s;

(s
0
)
holds.
.
P
(
;
s):
F
or
some
situations
s
0
in
the
past
of
s;

(s
0
)
holds.
.
H
(
;
s):
F
or
all
situations
s
0
in
the
past
of
s;

(s
0
)
holds.
It
seems
also
useful
to
dene
a
situational
uen
t
next(
)
as
the
next
situation
s
0
in
the
future
of
s
for
whic
h

(s
0
)
holds.
If
there
is
no
suc
h
situation,
that
is,
if
:F
(
;
s),
then
next(
;
s)
is
considered
undened.
F
or
example,
w
e
ma
y
translate
the
sen
tence
`By
the
time
John
gets
home,
Henry
will
b
e
home
to
o'
as
at(H
enr
y
;
home(H
enr
y
);
next(at(J
ohn;
home(J
ohn));
s)):
Also
the
phrase
`when
John
gets
home'
translates
in
to
time(next(at(J
ohn;
home(J
ohn));
s)):
Though
next(
;
s)
will
nev
er
actually
b
e
computed
since
situations
are
to
o
ric
h
to
b
e
sp
ecied
completely
,
the
v
alues
of
uen
ts
applied
to
next(
;
s)
will
b
e
computed.
.
Actions
A
fundamen
tal
role
in
our
study
of
actions
is
pla
y
ed
b
y
the
situational
uen
t
r
esul
t(p;

;
s)
Here,
p
is
a
p
erson,

is
an
action
or
more
generally
a
strategy
,
and
s
is
a
situation.
The
v
alue
of
r
esul
t(p;

;
s)
is
the
situation
that
results
when
p
carries
out

,
starting
in
the
situation
s.
If
the
action
or
strategy
do
es
not
terminate,
r
esul
t(p;

;
s)
is
considered
undened.
With
the
aid
of
r
esul
t
w
e
can
express
certain
la
ws
of
abilit
y
.
F
or
example:
has(p;
k
;
s)
^
f
its(k
;
sf
)
^
at(p;
sf
;
s)
!
open(sf
;
r
esul
t(p;
opens(sf
;
k
);
s)):
This
form
ula
is
to
b
e
regarded
as
an
axiom
sc
hema
asserting
that
if
in
a
situation
s
a
p
erson
p
has
a
k
ey
k
that
ts
the
safe
sf
,
then
in
the
situation
resulting
from
his
p
erforming
the
action
opens(sf
;
k
),
that
is,
op
ening
the
safe
sf
with
the
k
ey
k
,
the
safe
is
op
en.
The
assertion
f
its(k
;
sf
)
carries
the
information
that
k
is
a
k
ey
and
sf
a
safe.
Later
w
e
shall
b
e
concerned
with
com
bination
safes
that
require
p
to
k
now
the
com
bination.


----- Page 23 (native) -----
.
Strategies
Actions
can
b
e
com
bined
in
to
strategies.
The
simplest
com
bination
is
a
nite
sequence
of
actions.
W
e
shall
com
bine
actions
as
though
they
w
ere
ALGOL
statemen
ts,
that
is,
pro
cedure
calls.
Th
us,
the
sequence
of
actions,
(`mo
v
e
the
b
o
x
under
the
bananas',
`clim
b
on
to
the
b
o
x',
and
`reac
h
for
the
bananas')
ma
y
b
e
written:
b
egin
mov
e(B
ox;
U
nder
-B
ananas);
cl
imb(B
ox);
r
each-
f
or
(B
ananas)
end;
A
strategy
in
general
will
b
e
an
ALGOL-lik
e
comp
ound
statemen
t
con
tain-
ing
actions
written
in
the
form
of
pro
cedure
calling
assignmen
t
statemen
ts,
and
conditional
go
to's.
W
e
shall
not
include
an
y
declarations
in
the
pro-
gram
since
they
can
b
e
included
in
the
m
uc
h
larger
collection
of
declarativ
e
sen
tences
that
determine
the
eect
of
the
strategy
.
Consider
for
example
the
strategy
that
consists
of
w
alking

blo
c
ks
south,
turning
righ
t
and
then
w
alking
till
y
ou
come
to
Chestn
ut
Street.
This
strat-
egy
ma
y
b
e
written
as
follo
ws:
b
egin
f
ace(S
outh);
n
:=
0;
b
:
if
n
=

then
go
to
a;
w
al
k
-a-
bl
ock
;
n
:=
n
+
;
go
to
b;
a
:
tur
n-r
ig
ht;
c
:
w
al
k
-a-
bl
ock
;
if
name-
on-
str
eet-
sig
n
=
0
C
hestnut
S
tr
eet
0
then
go
to
c
end;
()
In
the
ab
o
v
e
program
the
external
actions
are
represen
ted
b
y
pro
cedure
calls.
V
ariables
to
whic
h
v
alues
are
assigned
ha
v
e
a
purely
in
ternal
signi-
cance
(w
e
ma
y
ev
en
call
it
men
tal
signicance)
and
so
do
the
statemen
t
lab
els
and
the
go
to
statemen
ts.
F
or
the
purp
ose
of
applying
the
mathematical
theory
of
computation
w
e
shall
write
the
program
dieren
tly:
namely
,
eac
h
o
ccurrence
of
an
action

is
to
b
e
replaced
b
y
an
assignmen
t
statemen
t
s
:=
r
esul
t(p;
;
s):
Th
us
the
ab
o
v
e
program
b
ecomes


----- Page 24 (native) -----
b
egin
s
:=
r
esul
t(p;
f
ace(S
outh);
s);
n
:=
0;
b
:
if
n
=

then
go
to
a;
s
:=
r
esul
t(p;
w
al
k
-
a-bl
ock
;
s);
n
:=
n
+
;
go
to
b;
a
:
s
:=
r
esul
t(p;
tur
n-
r
ig
ht;
s);
c
:
s
:=
r
esul
t(p;
w
al
k
-
a-bl
ock
;
s);
if
name-
on-
str
eet-
sig
n
=
0
C
hestnut
S
tr
eet
0
then
go
to
c
end;
()
Supp
ose
w
e
wish
to
sho
w
that
b
y
carrying
out
this
strategy
John
can
go
home
pro
vided
he
is
initially
at
his
oce.
Then
according
to
the
metho
ds
of
Zohar
Manna
(	a,
	b),
w
e
ma
y
deriv
e
from
this
program
together
with
the
initial
condition
at(J
ohn;
of
f
ice(J
ohn);
s
0
)
and
the
nal
condition
at(J
ohn;
home(J
ohn);
s),
a
sen
tence
W
of
rst-order
logic.
Pro
ving
W
will
sho
w
that
the
pro
cedure
terminates
in
a
nite
n
um
b
er
of
steps
and
that
when
it
terminates
s
will
satisfy
at(J
ohn;
home(J
ohn);
s).
According
to
Manna's
theory
w
e
m
ust
pro
v
e
the
follo
wing
collection
of
sen
tences
inconsisten
t
for
arbitrary
in
terpretations
of
the
predicates
q

and
q

and
the
particular
in
terpretations
of
the
other
functions
and
predicates
in
the
program:
at(J
ohn;
of
f
ice(J
ohn);
s
0
);
q
(O
;
r
esul
t(J
ohn;
f
ace(S
outh);
s
0
));
n:s:
q
(n;
s)
!
if
n
=

then
q
(r
esul
t(J
ohn;
w
al
k
-
a-bl
ock
;
r
esul
t(J
ohn;
tur
n-
r
ig
ht;
s)))
else
q
(n
+
;
r
esul
t(J
ohn;
w
al
k
-
a-bl
ock
;
s));
s:q
(s)
!
if
name-on-str
eet-
sig
n(s)
=
0
C
hestnut
S
tr
eet
0
then
q
(r
esul
t(J
ohn;
w
al
k
-
a-bl
ock
;
s))
else
:at(J
ohn;
home(J
ohn);
s):
()
Therefore
the
form
ula
that
has
to
b
e
pro
v
ed
ma
y
b
e
written


----- Page 25 (native) -----
s
0
fat(J
ohn;
of
f
ice(J
ohn);
s
0
)
^
q
(O
;
r
esul
t(J
ohn;
f
ace(S
outh);
s
0
))g
!
	n:	s:fq
(n;
s)
^
if
n
=

then
q
(r
esul
t(J
ohn;
w
al
k
-
a-
bl
ock
;
r
esul
t(J
ohn;
tur
n-
r
ig
ht;
s)))
else
:q
(n
+
;
r
esul
t(J
ohn;
w
al
k
-
a-bl
ock
;
s))g
_
	s:fq
(s)
^
if
name-
on-
str
eet-
sig
n(s)
=
0
C
hestnut
S
tr
eet
0
then
:q
(r
esul
t(J
ohn;
w
al
k
-
a-bl
ock
;
s))
else
at(J
ohn;
home(J
ohn);
s)g:
()
In
order
to
pro
v
e
this
sen
tence
w
e
w
ould
ha
v
e
to
use
the
follo
wing
kinds
of
facts
expressed
as
sen
tences
or
sen
tence
sc
hemas
of
rst-order
logic:
.
F
acts
of
geograph
y
.
The
initial
street
stretc
hes
at
least

blo
c
ks
to
the
south,
and
in
tersects
a
street
whic
h
in
turn
in
tersects
Chestn
ut
Street
a
n
um
b
er
of
blo
c
ks
to
the
righ
t;
the
lo
cation
of
John's
home
and
oce.
.
The
fact
that
the
uen
t
name-
on-
str
eet-
sig
n
will
ha
v
e
the
v
alue
`Chestn
ut
Street'
at
that
p
oin
t.
.
F
acts
giving
the
eects
of
action

expressed
as
predicates
ab
out
r
esul
t(p;
;
s)
deducible
from
sen
tences
ab
out
s.
.
An
axiom
sc
hema
of
induction
that
allo
ws
us
to
deduce
that
the
lo
op
of
w
alking

blo
c
ks
will
terminate.
.
A
fact
that
sa
ys
that
Chestn
ut
Street
is
a
nite
n
um
b
er
of
blo
c
ks
to
the
righ
t
after
going

blo
c
ks
south.
This
fact
has
nothing
to
do
with
the
p
ossibilit
y
of
w
alking.
It
ma
y
also
ha
v
e
to
b
e
expressed
as
a
sen
tence
sc
hema
or
ev
en
as
a
sen
tence
of
second-order
logic.
When
w
e
consider
making
a
computer
carry
out
the
strategy
,
w
e
m
ust
distinguish
the
v
ariable
s
from
the
other
v
ariables
in
the
second
form
of
the
program.
The
other
v
ariables
are
stored
in
the
memory
of
the
computer
and
the
assignmen
ts
ma
y
b
e
executed
in
the
normal
w
a
y
.
The
v
ariable
s
represen
ts
the
state
of
the
w
orld
and
the
computer
mak
es
an
assignmen
t
to
it
b
y
p
erforming
an
action.
Lik
ewise
the
uen
t
name-on-str
eet-
sig
n
requires
an
action,
of
observ
ation.


----- Page 26 (native) -----
.
Kno
wledge
and
Abilit
y
In
order
to
discuss
the
role
of
kno
wledge
in
one's
abilit
y
to
ac
hiev
e
goals
let
us
return
to
the
example
of
the
safe.
There
w
e
had
:
has(p;
k
;
s)^f
its(k
;
sf
)^at(p;
sf
;
s)
!
open(sf
;
r
esul
t(p;
opens(sf
;
k
);
s));
whic
h
expressed
sucien
t
conditions
for
the
abilit
y
of
a
p
erson
to
op
en
a
safe
with
a
k
ey
.
No
w
supp
ose
w
e
ha
v
e
a
com
bination
safe
with
a
com
bination
c.
Then
w
e
ma
y
write:
:
f
its(c;
sf
)
^
at(p;
sf
;
s)
!
open(sf
;
r
esul
t(p;
opens(sf
;
c);
s));
where
w
e
ha
v
e
used
the
predicate
f
its
and
the
action
opens
to
express
the
distinction
b
et
w
een
a
k
ey
tting
a
safe
and
a
com
bination
tting
it,
and
also
the
distinction
b
et
w
een
the
acts
of
op
ening
a
safe
with
a
k
ey
and
a
com
bination.
In
particular,
opens(sf
;
c)
is
the
act
of
manipulating
the
safe
in
accordance
with
the
com
bination
c.
W
e
ha
v
e
left
out
a
sen
tence
of
the
form
has(p;
c;
s)
for
t
w
o
reasons.
In
the
rst
place,
it
is
unnecessary:
if
y
ou
manipulate
a
safe
in
accordance
with
its
com
bination
it
will
op
en;
there
is
no
need
to
ha
v
e
an
ything.
In
the
second
place
it
is
not
clear
what
has(p;
c;
s)
means.
Supp
ose,
for
example,
that
the
com
bination
of
a
particular
safe
sf
is
the
n
um
b
er
,
then
f
its(;
sf
)
mak
es
sense
and
so
do
es
the
act
opens(sf
;
).
(W
e
assume
that
open(sf
;
r
esul
t(p;
opens(sf
;
);
s))
w
ould
not
b
e
true.)
But
what
could
has(p;
;
s)
mean?
Th
us,
a
direct
parallel
b
et
w
een
the
rules
for
op
ening
a
safe
with
a
k
ey
and
op
ening
it
with
a
com
bination
seems
imp
ossible.
Nev
ertheless,
w
e
need
some
w
a
y
of
expressing
the
fact
that
one
has
to
kno
w
the
com
bination
of
a
safe
in
order
to
op
en
it.
First
w
e
in
tro
duce
the
function
combination(sf
)
and
rewrite

as
:
at(p;
sf
;
s)
^
csaf
e(sf
)
!
open(sf
;
r
esul
t(p;
opens(sf
;
combination(sf
));
s));
where
csaf
e(sf
)
asserts
that
sf
is
a
com
bination
safe
and
combination(sf
)
denotes
the
com
bination
of
sf
.
(W
e
could
not
write
k
ey
(sf
)
in
the
other
case
unless
w
e
wished
to
restrict
ourselv
es
to
the
case
of
safes
with
only
one
k
ey
.)
Next
w
e
in
tro
duce
the
notion
of
a
feasible
strategy
for
a
p
erson.
The
idea
is
that
a
strategy
that
w
ould
ac
hiev
e
a
certain
goal
migh
t
not
b
e
feasible
for
a
p
erson
b
ecause
he
lac
ks
certain
kno
wledge
or
abilities.


----- Page 27 (native) -----
Our
rst
approac
h
is
to
regard
the
action
opens(sf
;
combination(sf
))
as
infeasible
b
ecause
p
migh
t
not
kno
w
the
com
bination.
Therefore,
w
e
in
tro-
duce
a
new
function
idea-
of
-
combination(p;
sf
;
s)
whic
h
stands
for
p
erson
p's
idea
of
the
com
bination
of
sf
in
situation
s.
The
action
opens(sf
;
idea-of
-
combination(p;
sf
;
s))
is
regarded
as
fea-
sible
for
p,
since
p
is
assumed
to
kno
w
his
idea
of
the
com
bination
if
this
is
dened.
Ho
w
ev
er,
w
e
lea
v
e
sen
tence

as
it
is
so
w
e
cannot
y
et
pro
v
e
open(sf
;
r
esul
t(p;
opens(sf
;
idea-
of
-
combination(p;
sf
;
s));
s)).
The
asser-
tion
that
p
kno
ws
the
com
bination
of
sf
can
no
w
b
e
expressed
as

:
idea-
of
-
combination(p;
sf
;
s)
=
combination(sf
)
and
with
this,
the
p
ossibilit
y
of
op
ening
the
safe
can
b
e
pro
v
ed.
Another
example
of
this
approac
h
is
giv
en
b
y
the
follo
wing
formalization
of
getting
in
to
con
v
ersation
with
someone
b
y
lo
oking
up
his
n
um
b
er
in
the
telephone
b
o
ok
and
then
dialing
it.
The
strategy
for
p
in
the
rst
form
is
b
egin
l
ook
up(q
;
P
hone-
book
);
dial
(idea-
of
-
phone-
number
(sq
;
p))
end
;
()
or
in
the
second
form
b
egin
s
:=
r
esul
t(p;
l
ook
up(q
;
P
hone-book
);
s
0
);
s
:=
r
esul
t(p;
dial
(idea-
of
-
phone-
number
(q
;
p;
s));
s)
end;
(	)
The
premisses
to
write
do
wn
app
ear
to
b
e
.
has(p;
P
hone-book
;
s
0
)
.
l
isted(q
;
P
hone-
book
;
s
0
)
.
s:p:
q
:
has(p;
P
hone-
book
;
s)
^
l
isted(q
;
P
hone-
book
;
s)
!
phone-
number
(q
)
=
idea-of
-
phone-
number
(p;
q
;
r
esul
t(p;
l
ook
up(q
;
P
hone-book
);
s))
.
s:p:
q
:

x:
at
(q
;
home(q
);
s)
^
has(p;
x;
s)
^
tel
ephone(x)

		:
Apparen
tly
there
w
as
nev
er
an
equation
.


----- Page 28 (native) -----
!
in-conv
er
sation(p;
q
;
r
esul
t(p;
dial
(phone-
number
(q
));
s))
.
at(q
;
home(q
);
s
0
)
.
tel
ephone(T
el
ephone)
.
has(p;
T
el
ephone;
s
0
)
Unfortunately
,
these
premisses
are
not
sucien
t
to
allo
w
one
to
conclude
that
in-conv
er
sation(p;
q
;
r
esul
t(p;
b
egin
l
ook
up(q
;
P
hone-
book
);
dial
(idea-
of
-
phone-
number
(q
;
p))
end
;
s
0
)):
(0)
The
trouble
is
that
one
cannot
sho
w
that
the
uen
ts
at(q
;
home(q
))
and
has(p;
T
el
ephone)
still
apply
to
the
situation
r
esul
t(p;
l
ook
up(q
;
P
hone-book
);
s
0
).
T
o
mak
e
it
come
out
righ
t
w
e
shall
revise
the
third
h
yp
othesis
to
read:
s:
p:
q
:

x
:
y
:
at(q
;
y
;
s)
^
has(p;
x;
s)
^
has(p;
P
hone-
book
;
s)
^
l
isted(q
;
P
hone-
book
)
!
[r
:at(q
;
y
;
r
)
^
has(p;
x;
r
)
^
phone-
number
(q
)
=
idea-
of
-
phone-
number
(p;
q
;
r
)]
(r
esul
t(p;
l
ook
up(q
;
P
hone-book
);
s)):
()
This
w
orks,
but
the
additional
h
yp
otheses
ab
out
what
remains
unc
hanged
when
p
lo
oks
up
a
telephone
n
um
b
er
are
quite
ad
ho
c.
W
e
shall
treat
this
problem
in
a
later
section.
The
presen
t
approac
h
has
a
ma
jor
tec
hnical
adv
an
tage
for
whic
h,
ho
w
ev
er,
w
e
pa
y
a
high
price.
The
adv
an
tage
is
that
w
e
preserv
e
the
abilit
y
to
replace
an
y
expression
b
y
an
equal
one
in
an
y
expression
of
our
language.
Th
us
if
phone-
number
(J
ohn)
=
0,
an
y
true
statemen
t
of
our
language
that
con
tains
0
or
phonenumber
(J
ohn)
will
remain
true
if
w
e
replace
one
b
y
the
other.
This
desirable
prop
ert
y
is
termed
referen
tial
transparency
.
The
price
w
e
pa
y
for
referen
tial
transparency
is
that
w
e
ha
v
e
to
in
tro
duce
idea-
of
-
phone-
number
(p;
q
;
s)
as
a
separate
ad
ho
c
en
tit
y
and
cannot
use
the
more
natural
idea-
of
(p;
phone-
number
(q
);
s)
where
idea-
of
(p;
con;
s)
is
some
kind
of
op
erator
applicable
to
the
concept
con.
Namely
,
the
sen
tence
idea-
of
(p;
phone-
number
(q
);
s)
=
phone-
number
(q
)
w
ould
b
e
supp
osed
to
express
that
p
kno
ws
q
's
phone-n
um
b
er,
but
idea-
of
(p;
-
0;
s)
=
0
expresses
only
that
p
understands
that
n
um
b
er.
Y
et
with


----- Page 29 (native) -----
transparency
and
the
fact
that
phone-
number
(q
)
=
0
w
e
could
deriv
e
the
former
statemen
t
from
the
latter.
A
further
consequence
of
our
approac
h
is
that
feasibilit
y
of
a
strategy
is
a
referen
tially
opaque
concept
since
a
strategy
con
taining
idea-
of
-
phone-
number
(p;
q
;
s)
is
regarded
as
feasible
while
one
con
taining
phone-
number
(q
)
is
not,
ev
en
though
these
quan
tities
ma
y
b
e
equal
in
a
particular
case.
Ev
en
so,
our
language
is
still
referen
tially
transparen
t
since
feasibilit
y
is
a
concept
of
the
metalanguage.
A
classical
p
oser
for
the
reader
who
w
an
ts
to
solv
e
these
diculties
to
p
onder
is,
`George
IV
w
ondered
whether
the
author
of
the
W
a
v
erly
no
v
els
w
as
W
alter
Scott'
and
`W
alter
Scott
is
the
author
of
the
W
a
v
erly
no
v
els',
from
whic
h
w
e
do
not
wish
to
deduce,
`George
IV
w
ondered
whether
W
alter
Scott
w
as
W
alter
Scott'.
This
example
and
others
are
discussed
in
the
rst
c
hapter
of
Ch
urc
h's
Intr
o
duction
to
Mathematic
al
L
o
gic
(	).
In
the
long
run
it
seems
that
w
e
shall
ha
v
e
to
use
a
formalism
with
referen-
tial
opacit
y
and
form
ulate
precisely
the
necessary
restrictions
on
replacemen
t
of
equals
b
y
equals;
the
program
m
ust
b
e
able
to
reason
ab
out
the
feasibil-
it
y
of
its
strategies,
and
users
of
natural
language
handle
referen
tial
opacit
y
without
disaster.
In
part

w
e
giv
e
a
brief
accoun
t
of
the
partly
successful
approac
h
to
problems
of
referen
tial
opacit
y
in
mo
dal
logic.

REMARKS
AND
OPEN
PR
OBLEMS
The
formalism
presen
ted
in
part

is,
w
e
think,
an
adv
ance
on
previous
at-
tempts,
but
it
is
far
from
epistemological
adequacy
.
In
the
follo
wing
sections
w
e
discuss
a
n
um
b
er
of
problems
that
it
raises.
F
or
some
of
them
w
e
ha
v
e
prop
osals
that
migh
t
lead
to
solutions.
.
The
appro
ximate
c
haracter
of
r
esul
t(p;

;
s)
Using
the
situational
uen
t
r
esul
t(p;

;
s)
in
form
ulating
the
conditions
under
whic
h
strategies
ha
v
e
giv
en
eects
has
t
w
o
adv
an
tages
o
v
er
the
can(p;

;
s)
of
part
.
It
p
ermits
more
compact
and
transparen
t
sen
tences,
and
it
lends
itself
to
the
application
of
the
mathematical
theory
of
computation
to
pro
v
e
that
certain
strategies
ac
hiev
e
certain
goals.
Ho
w
ev
er,
w
e
m
ust
recognize
that
it
is
only
an
appro
ximation
to
sa
y
that
an
action,
other
than
that
whic
h
will
actually
o
ccur,
leads
to
a
denite
situa-


----- Page 30 (native) -----
tion.
Th
us
if
someone
is
ask
ed,
`Ho
w
w
ould
y
ou
feel
tonigh
t
if
y
ou
c
hallenged
him
to
a
duel
tomorro
w
morning
and
he
accepted?'
he
migh
t
w
ell
reply
,
`I
can't
imagine
the
men
tal
state
in
whic
h
I
w
ould
do
it;
if
the
w
ords
inexplica-
bly
p
opp
ed
out
of
m
y
mouth
as
though
m
y
v
oice
w
ere
under
someone
else's
con
trol
that
w
ould
b
e
one
thing;
if
y
ou
ga
v
e
me
a
long-lasting
b
elligerence
drug
that
w
ould
b
e
another.'
F
rom
this
w
e
see
that
r
esul
t(p;

;
s)
should
not
b
e
regarded
as
b
eing
dened
in
the
w
orld
itself,
but
only
in
certain
represen
tations
of
the
w
orld;
alb
eit
in
represen
tations
that
ma
y
ha
v
e
a
preferred
c
haracter
as
discussed
in
part
.
W
e
regard
this
as
a
blemish
on
the
smo
othness
of
in
terpretation
of
the
formalism,
whic
h
ma
y
also
lead
to
diculties
in
the
formal
dev
elopmen
t.
P
erhaps
another
device
can
b
e
found
whic
h
has
the
adv
an
tages
of
r
esul
t
without
the
disadv
an
tages.
.
P
ossible
Meanings
of
`can'
for
a
Computer
Pro-
gram
A
computer
program
can
readily
b
e
giv
en
m
uc
h
more
p
o
w
erful
means
of
in-
trosp
ection
than
a
p
erson
has,
for
w
e
ma
y
mak
e
it
insp
ect
the
whole
of
its
memory
including
program
and
data
to
answ
er
certain
in
trosp
ectiv
e
ques-
tions,
and
it
can
ev
en
sim
ulate
(slo
wly)
what
it
w
ould
do
with
giv
en
initial
data.
It
is
in
teresting
to
list
v
arious
notions
of
can(P
r
og
r
am;

)
for
a
pro-
gram.
.
There
is
a
sub-program

and
ro
om
for
it
in
memory
whic
h
w
ould
ac
hiev
e

if
it
w
ere
in
memory
,
and
con
trol
w
ere
transferred
to

.
No
assertion
is
made
that
P
r
og
r
am
kno
ws

or
ev
en
kno
ws
that

exists.
.

exists
as
ab
o
v
e
and
that

will
ac
hiev
e

follo
ws
from
information
in
memory
according
to
a
pro
of
that
P
r
og
r
am
is
capable
of
c
hec
king.
.
P
r
og
r
am's
standard
problem-solving
pro
cedure
will
nd

if
ac
hieving

is
ev
er
accepted
as
a
subgoal.
.
The
F
rame
Problem
In
the
last
section
of
part
,
in
pro
ving
that
one
p
erson
could
get
in
to
con
v
er-
sation
with
another,
w
e
w
ere
obliged
to
add
the
h
yp
othesis
that
if
a
p
erson
has
a
telephone
he
still
has
it
after
lo
oking
up
a
n
um
b
er
in
the
telephone
0

----- Page 31 (native) -----
b
o
ok.
If
w
e
had
a
n
um
b
er
of
actions
to
b
e
p
erformed
in
sequence
w
e
w
ould
ha
v
e
quite
a
n
um
b
er
of
conditions
to
write
do
wn
that
certain
actions
do
not
c
hange
the
v
alues
of
certain
uen
ts.
In
fact
with
n
actions
and
m
uen
ts
w
e
migh
t
ha
v
e
to
write
do
wn
mn
suc
h
conditions.
W
e
see
t
w
o
w
a
ys
out
of
this
dicult
y
.
The
rst
is
to
in
tro
duce
the
notion
of
frame,
lik
e
the
state
v
ector
in
McCarth
y
(	).
A
n
um
b
er
of
uen
ts
are
declared
as
attac
hed
to
the
frame
and
the
eect
of
an
action
is
describ
ed
b
y
telling
whic
h
uen
ts
are
c
hanged,
all
others
b
eing
presumed
unc
hanged.
This
can
b
e
formalized
b
y
making
use
of
y
et
more
ALGOL
notation,
p
erhaps
in
a
somewhat
generalized
form.
Consider
a
strategy
in
whic
h
p
p
erforms
the
action
of
going
from
x
to
y
.
In
the
rst
form
of
writing
strategies
w
e
ha
v
e
g
o(x;
y
)
as
a
program
step.
In
the
second
form
w
e
ha
v
e
s
:=
r
esul
t(p;
g
o(x;
y
);
s).
No
w
w
e
ma
y
write
l
ocation(p)
:=
tr
y
f
or
(y
;
x)
and
the
fact
that
other
v
ariables
are
unc
hanged
b
y
this
action
follo
ws
from
the
general
prop
erties
of
assignmen
t
statemen
ts.
Among
the
conditions
for
successful
execution
of
the
program
will
b
e
sen
tences
that
enable
us
to
sho
w
that
when
this
statemen
t
is
executed,
tr
y
f
or
(y
;
x)
=
y
.
If
w
e
w
ere
willing
to
consider
that
p
could
go
an
ywhere
w
e
could
write
the
assignmen
t
statemen
t
simply
as
l
ocation(p)
:=
y
The
p
oin
t
of
using
tr
y
f
or
here
is
that
a
program
using
this
simpler
assign-
men
t
is,
on
the
face
of
it,
not
p
ossible
to
execute,
since
p
ma
y
b
e
unable
to
go
to
y
.
W
e
ma
y
co
v
er
this
case
in
the
more
complex
assignmen
t
b
y
agreeing
that
when
p
is
barred
from
y
,
tr
y
f
or
(y
;
x)
=
x.
In
general,
restrictions
on
what
could
app
ear
on
the
righ
t
side
of
an
assignmen
t
to
a
comp
onen
t
of
the
situation
w
ould
b
e
included
in
the
con-
ditions
for
the
feasibilit
y
of
the
strategy
.
Since
comp
onen
ts
of
the
situation
that
c
hange
indep
enden
tly
in
some
circumstances
are
dep
enden
t
in
others,
it
ma
y
b
e
w
orth
while
to
mak
e
use
of
the
blo
c
k
structure
of
ALGOL.
W
e
shall
not
explore
this
approac
h
further
in
this
pap
er.
Another
approac
h
to
the
frame
problem
ma
y
follo
w
from
the
metho
ds
of
the
next
section;
and
in
part

w
e
men
tion
a
third
approac
h
whic
h
ma
y
b
e
useful,
although
w
e
ha
v
e
not
in
v
estigated
it
at
all
fully
.


----- Page 32 (native) -----
.
F
ormal
Literatures
In
this
section
w
e
in
tro
duce
the
notion
of
formal
literature
whic
h
is
to
b
e
con
trasted
with
the
w
ell-kno
wn
notion
of
formal
language.
W
e
shall
men
tion
some
p
ossible
applications
of
this
concept
in
constructing
an
epistemologi-
cally
adequate
system.
A
formal
literature
is
lik
e
a
formal
language
with
a
history:
w
e
imagine
that
up
to
a
certain
time
a
certain
sequence
of
sen
tences
ha
v
e
b
een
said.
The
literature
then
determines
what
sen
tences
ma
y
b
e
said
next.
The
formal
denition
is
as
follo
ws.
Let
A
b
e
a
set
of
p
oten
tial
sen
tences,
for
example,
the
set
of
all
nite
strings
in
some
alphab
et.
Let
S
eq
(A)
b
e
the
set
of
nite
sequences
of
elemen
ts
of
A
and
let
L
:
S
eq
(A)
!
ftrue;
false
g
b
e
suc
h
that
if
s

S
eq
(A)
and
L(s),
that
is
L(s)
=
tr
ue,
and


is
an
initial
segmen
t
of

then
L(

).
The
pair
(A;
L)
is
termed
a
liter
atur
e.
The
in
terpretation
is
that
a
n
ma
y
b
e
said
after
a

;
:
:
:
;
a
n 
);
pro
vided
L((a

;
:
:
:
;
a
n
)).
W
e
shall
also
write


L
and
refer
to

as
a
string
of
the
literature
L.
F
rom
a
literature
L
and
a
string


L
w
e
in
tro
duce
the
deriv
ed
literature
L

.
Namely
,


L

if
and
only
if




L,
where



denotes
the
concatenation
of

and

.
W
e
shall
sa
y
that
the
language
L
is
univ
ersal
for
the
class

of
literatures
if
for
ev
ery
literature
M


there
is
a
string

(M
)

L
suc
h
that
M
=
L

(M
)
;
that
is,


M
if
and
only
if

(M
)



L.
W
e
shall
call
a
literature
computable
if
its
strings
form
a
recursiv
ely
en
umerable
set.
It
is
easy
to
see
that
there
is
a
computable
literature
U
(C
)
that
is
univ
ersal
with
resp
ect
to
the
set
C
of
computable
literatures.
Namely
,
let
e
b
e
a
computable
literature
and
let
c
b
e
the
represen
tation
of
the
G
odel
n
um
b
er
of
the
recursiv
ely
en
umerable
set
of
e
as
a
string
of
elemen
ts
of
A.
Then,
w
e
sa
y
c



U
C
if
and
only
if


e.
It
ma
y
b
e
more
con
v
enien
t
to
describ
e
natural
languages
as
formal
liter-
atures
than
as
formal
languages:
if
w
e
allo
w
the
denition
of
new
terms
and
require
that
new
terms
b
e
used
in
accordance
with
their
denitions,
then
w
e
ha
v
e
restrictions
on
sen
tences
that
dep
end
on
what
sen
tences
ha
v
e
previously
b
een
uttered.
In
a
programming
language,
the
restriction
that
an
iden
tier
not
b
e
used
un
til
it
has
b
een
declared,
and
then
only
consisten
tly
with
the
declaration,
is
of
this
form.
An
y
natural
language
ma
y
b
e
regarded
as
univ
ersal
with
resp
ect
to
the
set
of
natural
languages
in
the
appro
ximate
sense
that
w
e
migh
t
dene
F
renc
h


----- Page 33 (native) -----
in
terms
of
English
and
then
sa
y
`F
rom
no
w
on
w
e
shall
sp
eak
only
F
renc
h'.
All
the
ab
o
v
e
is
purely
syn
tactic.
The
applications
w
e
en
visage
to
articial
in
telligence
come
from
a
certain
kind
of
in
terpreted
literature.
W
e
are
not
able
to
describ
e
precisely
the
class
of
literatures
that
ma
y
pro
v
e
useful,
only
to
sk
etc
h
a
class
of
examples.
Supp
ose
w
e
ha
v
e
an
in
terpreted
language
suc
h
as
rst-order
logic
p
erhaps
including
some
mo
dal
op
erators.
W
e
in
tro
duce
three
additional
op
erators:
consistent(),
nor
mal
l
y
(),
and
pr
obabl
y
().
W
e
start
with
a
list
of
sen-
tences
as
h
yp
otheses.
A
new
sen
tence
ma
y
b
e
added
to
a
string

of
sen
tences
according
to
the
follo
wing
rules:
.
An
y
consequence
of
sen
tences
of

ma
y
b
e
added.
.
If
a
sen
tence

is
consisten
t
with

,
then
consistent()
ma
y
b
e
added.
Of
course,
this
is
a
non-computable
rule.
It
ma
y
b
e
w
eak
ened
to
sa
y
that
consistent()
ma
y
b
e
added
pro
vided

can
b
e
sho
wn
to
b
e
consisten
t
with

b
y
some
particular
pro
of
pro
cedure.
.
nor
mal
l
y
();
consistent()
`
pr
obabl
y
().
.

`
pr
obabl
y
()
is
a
p
ossible
deduction.
.
If


;


;
:
:
:
;

n
`

is
a
p
ossible
deduction
then
pr
obabl
y
(

);
:
:
:
;
pr
obabl
y
(
n
)
`
pr
obabl
y
()
is
also
a
p
ossible
deduction.
The
in
tended
application
to
our
formalism
is
as
follo
ws:
In
part

w
e
considered
the
example
of
one
p
erson
telephoning
another,
and
in
this
example
w
e
assumed
that
if
p
lo
oks
up
q
's
phone-n
um
b
er
in
the
b
o
ok,
he
will
kno
w
it,
and
if
he
dials
the
n
um
b
er
he
will
come
in
to
con
v
ersation
with
q
.
It
is
not
hard
to
think
of
p
ossible
exceptions
to
these
statemen
ts
suc
h
as:
.
The
page
with
q
's
n
um
b
er
ma
y
b
e
torn
out.
.
p
ma
y
b
e
blind.
.
Someone
ma
y
ha
v
e
delib
erately
ink
ed
out
q
's
n
um
b
er.
.
The
telephone
compan
y
ma
y
ha
v
e
made
the
en
try
incorrectly
.
.
q
ma
y
ha
v
e
got
the
telephone
only
recen
tly
.
.
The
phone
system
ma
y
b
e
out
of
order.
.
q
ma
y
b
e
incapacitated
suddenly
.


----- Page 34 (native) -----
F
or
eac
h
of
these
p
ossibilities
it
is
p
ossible
to
add
a
term
excluding
the
dicult
y
in
question
to
the
condition
on
the
result
of
p
erforming
the
ac-
tion.
But
w
e
can
think
of
as
man
y
additional
diculties
as
w
e
wish,
so
it
is
impractical
to
exclude
eac
h
dicult
y
separately
.
W
e
hop
e
to
get
out
of
this
dicult
y
b
y
writing
suc
h
sen
tences
as
p:q
:

s:a
t(q
;
home(q
);
s)
!
nor
mal
l
y
(in-
conv
er
sation(p;
q
;
r
esul
t(p;
dial
s(phone-
number
(q
));
s))):
()
W
e
w
ould
then
b
e
able
to
deduce
pr
obabl
y
(in-
conv
er
sation(p;
q
;
r
esul
t(p;
dial
s(phone-
number
(q
));
s
0
)))
pro
vided
there
w
ere
no
statemen
ts
lik
e
k
aput(P
hone-sy
stem;
s
0
)
and
s:k
aput(P
hone-
sy
stem;
s)
!
:in-conv
er
sation(p;
q
;
r
esul
t(p;
dial
s(phone-
number
(q
));
s))
()
presen
t
in
the
system.
Man
y
of
the
problems
that
giv
e
rise
to
the
in
tro
duction
of
frames
migh
t
b
e
handled
in
a
similar
w
a
y
.
The
op
erators
nor
mal
l
y
,
consistent
and
pr
obabl
y
are
all
mo
dal
and
refer-
en
tially
opaque.
W
e
en
visage
systems
in
whic
h
pr
obabl
y
(
)
and
pr
obabl
y
(:
)
and
therefore
pr
obabl
y
(false
)
will
arise.
Suc
h
an
ev
en
t
should
giv
e
rise
to
a
searc
h
for
a
con
tradiction.
W
e
hereb
y
w
arn
the
reader,
if
it
is
not
already
clear
to
him,
that
these
ideas
are
v
ery
ten
tativ
e
and
ma
y
pro
v
e
useless,
esp
ecially
in
their
presen
t
form.
Ho
w
ev
er,
the
problem
they
are
in
tended
to
deal
with,
namely
the
imp
ossibilit
y
of
naming
ev
ery
conceiv
able
thing
that
ma
y
go
wrong,
is
an
imp
ortan
t
one
for
articial
in
telligence,
and
some
formalism
has
to
b
e
dev
el-
op
ed
to
deal
with
it.


----- Page 35 (native) -----
.
Probabilities
On
n
umerous
o
ccasions
it
has
b
een
suggested
that
the
formalism
tak
e
uncer-
tain
t
y
in
to
accoun
t
b
y
attac
hing
probabilities
to
its
sen
tences.
W
e
agree
that
the
formalism
will
ev
en
tually
ha
v
e
to
allo
w
statemen
ts
ab
out
the
probabili-
ties
of
ev
en
ts,
but
attac
hing
probabilities
to
all
statemen
ts
has
the
follo
wing
ob
jections:
.
It
is
not
clear
ho
w
to
attac
h
probabilities
to
statemen
ts
con
taining
quan
tiers
in
a
w
a
y
that
corresp
onds
to
the
amoun
t
of
con
viction
p
eople
ha
v
e.
.
The
information
necessary
to
assign
n
umerical
probabilities
is
not
ordi-
narily
a
v
ailable.
Therefore,
a
formalism
that
required
n
umerical
probabilities
w
ould
b
e
epistemologically
inadequate.
.
P
arallel
Pro
cessing
Besides
describing
strategies
b
y
ALGOL-lik
e
programs
w
e
ma
y
also
w
an
t
to
describ
e
the
la
ws
of
c
hange
of
the
situation
b
y
suc
h
programs.
In
doing
so
w
e
m
ust
tak
e
in
to
accoun
t
the
fact
that
man
y
pro
cesses
are
going
on
sim
ul-
taneously
and
that
the
single-activit
y-at-a-time
ALGOL-lik
e
programs
will
ha
v
e
to
b
e
replaced
b
y
programs
in
whic
h
pro
cesses
tak
e
place
in
parallel,
in
order
to
get
an
epistemologically
adequate
description.
This
suggests
exam-
ining
the
so-called
sim
ulation
languages;
but
a
quic
k
surv
ey
indicates
that
they
are
rather
restricted
in
the
kinds
of
pro
cesses
they
allo
w
to
tak
e
place
in
parallel
and
in
the
t
yp
es
of
in
teraction
allo
w
ed.
Moreo
v
er,
at
presen
t
there
is
no
dev
elop
ed
formalism
that
allo
ws
pro
ofs
of
the
correctness
of
parallel
programs.

DISCUSSION
OF
LITERA
TURE
The
plan
for
ac
hieving
a
generally
in
telligen
t
program
outlined
in
this
pap
er
will
clearly
b
e
dicult
to
carry
out.
Therefore,
it
is
natural
to
ask
if
some
simpler
sc
heme
will
w
ork,
and
w
e
shall
dev
ote
this
section
to
criticising
some
simpler
sc
hemes
that
ha
v
e
b
een
prop
osed.
.
L.
F
ogel
(	)
prop
oses
to
ev
olv
e
in
telligen
t
automata
b
y
altering
their
state
transition
diagrams
so
that
they
p
erform
b
etter
on
tasks
of
greater
and
greater
complexit
y
.
The
exp
erimen
ts
describ
ed
b
y
F
ogel
in
v
olv
e
mac
hines


----- Page 36 (native) -----
with
less
than
0
states
b
eing
ev
olv
ed
to
predict
the
next
sym
b
ol
of
a
quite
simple
sequence.
W
e
do
not
think
this
approac
h
has
m
uc
h
c
hance
of
ac
hieving
in
teresting
results
b
ecause
it
seems
limited
to
automata
with
small
n
um
b
ers
of
states,
sa
y
less
than
00,
whereas
computer
programs
regarded
as
au-
tomata
ha
v
e

0

to

0

states.
This
is
a
reection
of
the
fact
that,
while
the
represen
tation
of
b
eha
viours
b
y
nite
automata
is
metaph
ysically
adequate|
in
principle
ev
ery
b
eha
viour
of
whic
h
a
h
uman
or
mac
hine
is
capable
can
b
e
so
represen
ted|this
represen
tation
is
not
epistemologically
adequate;
that
is,
conditions
w
e
migh
t
wish
to
imp
ose
on
a
b
eha
viour,
or
what
is
learned
from
an
exp
erience,
are
not
readily
expresible
as
c
hanges
in
the
state
diagram
of
an
automaton.
.
A
n
um
b
er
of
in
v
estigators
(Galan
ter
	,
Piv
ar
and
Fink
elstein
	)
ha
v
e
tak
en
the
view
that
in
telligence
ma
y
b
e
regarded
as
the
abilit
y
to
pre-
dict
the
future
of
a
sequence
from
observ
ation
of
its
past.
Presumably
,
the
idea
is
that
the
exp
erience
of
a
p
erson
can
b
e
regarded
as
a
sequence
of
discrete
ev
en
ts
and
that
in
telligen
t
p
eople
can
predict
the
future.
Articial
in
telligence
is
then
studied
b
y
writing
programs
to
predict
sequences
formed
according
to
some
simple
class
of
la
ws
(sometimes
probabilistic
la
ws).
Again
the
mo
del
is
metaph
ysically
adequate
but
epistemologically
inadequate.
In
other
w
ords,
what
w
e
kno
w
ab
out
the
w
orld
is
divided
in
to
kno
wledge
ab
out
man
y
asp
ects
of
it,
tak
en
separately
and
with
rather
w
eak
in
teraction.
A
mac
hine
that
w
ork
ed
with
the
undieren
tiated
enco
ding
of
exp
erience
in
to
a
sequence
w
ould
rst
ha
v
e
to
solv
e
the
enco
ding,
a
task
more
dicult
than
an
y
the
sequence
extrap
olators
are
prepared
to
undertak
e.
Moreo
v
er,
our
kno
wledge
is
not
usable
to
predict
exact
sequences
of
exp
erience.
Imagine
a
p
erson
who
is
correctly
predicting
the
course
of
a
fo
otball
game
he
is
w
atc
hing;
he
is
not
predicting
eac
h
visual
sensation
(the
pla
y
of
ligh
t
and
shado
w,
the
exact
mo
v
eme
n
ts
of
the
pla
y
ers
and
the
cro
wd).
Instead
his
prediction
is
on
the
lev
el
of:
team
A
is
getting
tired;
they
should
start
to
fum
ble
or
ha
v
e
their
passes
in
tercepted.
.
F
riedb
erg
(	,		)
has
exp
erimen
ted
with
represen
ting
b
eha
viour
b
y
a
computer
program
and
ev
olving
a
program
b
y
random
m
utations
to
p
erform
a
task.
The
epistemological
inadequacy
of
the
represen
tation
is
expressed
b
y
the
fact
that
desired
c
hanges
in
b
eha
viour
are
often
not
repre-
sen
table
b
y
small
c
hanges
in
the
mac
hine
language
form
of
the
program.
In
particular,
the
eect
on
a
reasoning
program
of
learning
a
new
fact
is
not
so
represen
table.
.
New
ell
and
Simon
w
ork
ed
for
a
n
um
b
er
of
y
ears
with
a
program
called


----- Page 37 (native) -----
the
General
Problem
Solv
er
(New
ell
et.
al.
		,
New
ell
and
Simon
	).
This
program
represen
ts
problems
as
the
task
of
transforming
one
sym
b
olic
expression
in
to
another
using
a
xed
set
of
transformation
rules.
They
suc-
ceeded
in
putting
a
fair
v
ariet
y
of
problems
in
to
this
form,
but
for
a
n
um
b
er
of
problems
the
represen
tation
w
as
a
wkw
ard
enough
so
that
GPS
could
only
do
small
examples.
The
task
of
impro
ving
GPS
w
as
studied
as
a
GPS
task,
but
w
e
b
eliev
e
it
w
as
nally
abandoned.
The
name,
General
Problem
Solv
er,
suggests
that
its
authors
at
one
time
b
eliev
ed
that
most
problems
could
b
e
put
in
its
terms,
but
their
more
recen
t
publications
ha
v
e
indicated
other
p
oin
ts
of
view.
It
is
in
teresting
to
compare
the
p
oin
t
of
view
of
the
presen
t
pap
er
with
that
expressed
in
New
ell
and
Ernst
(	)
from
whic
h
w
e
quote
the
second
paragraph:
W
e
ma
y
consider
a
problem
solv
er
to
b
e
a
pro
cess
that
tak
es
a
problem
as
input
and
pro
vides
(when
successful)
the
solution
as
output.
The
problem
consists
of
the
problem
statemen
t,
or
what
is
immedi
ately
giv
en,
and
auxil-
iary
information,
whic
h
is
p
oten
tially
relev
an
t
to
the
problem
but
a
v
ailable
only
as
the
result
of
pro
cessing.
The
problem
solv
er
has
a
v
ailable
certain
metho
ds
for
attempting
to
solv
e
the
problem.
F
or
the
problem
solv
er
to
b
e
able
to
w
ork
on
a
problem
it
m
ust
rst
transform
the
problem
statemen
t
from
its
external
form
in
to
the
in
ternal
represen
tation.
Th
us
(roughly),
the
class
of
problems
the
problem
solv
er
can
con
v
ert
in
to
its
in
ternal
represen-
tation
determines
ho
w
broad
or
general
it
is,
and
its
success
in
obtaining
solutions
to
problems
in
in
ternal
form
determines
its
p
o
w
er.
Whether
or
not
univ
ersal,
suc
h
a
decomp
osition
ts
w
ell
the
structure
of
presen
t
problem
solving
programs.
In
a
v
ery
appro
ximate
w
a
y
their
division
of
the
problem
solv
er
in
to
the
input
program
that
con
v
erts
problems
in
to
in
ternal
represen-
tation
and
the
problem
solv
er
prop
er
corresp
onds
to
our
division
in
to
the
epistemological
and
heuristic
pats
of
the
articial
in
telligence
problem.
The
dierence
is
that
w
e
are
more
concerned
with
the
suitabilit
y
of
the
in
ternal
represen
tation
itself.
New
ell
(	)
p
oses
the
problem
of
ho
w
to
get
what
w
e
call
heuristically
adequate
represen
tations
of
problems,
and
Simon
(	)
discusses
the
con-
cept
of
`can'
in
a
w
a
y
that
should
b
e
compared
with
the
presen
t
approac
h.


----- Page 38 (native) -----
.
Mo
dal
Logic
It
is
dicult
to
giv
e
a
concise
denition
of
mo
dal
logic.
It
w
as
originally
in-
v
en
ted
b
y
Lewis
(	)
in
an
attempt
to
a
v
oid
the
`parado
xes'
of
implication
(a
false
prop
osition
implies
an
y
prop
osition).
The
idea
w
as
to
distinguish
t
w
o
sorts
of
truth:
ne
c
essary
truth
and
mere
c
ontingent
truth.
A
con
tingen
tly
true
prop
osition
is
one
whic
h,
though
true,
could
b
e
false.
This
is
formalized
b
y
in
tro
ducing
the
mo
dal
op
erator

(read
`necessarily')
whic
h
forms
prop
o-
sitions
from
prop
ositions.
Then
p's
b
eing
a
necessary
truth
is
expressed
b
y
p's
b
eing
true.
More
recen
tly
,
mo
dal
logic
has
b
ecome
a
m
uc
h-used
to
ol
for
analyzing
the
logic
of
suc
h
v
arious
prop
ositional
op
erators
as
b
elief,
kno
wl-
edge
and
tense.
There
are
v
ery
man
y
p
ossible
axiomatizations
of
the
logic
of

none
of
whic
h
seem
more
in
tuitiv
ely
plausible
than
man
y
others.
A
full
accoun
t
of
the
main
classical
systems
is
giv
en
b
y
F
eys
(	),
who
also
includes
an
excellen
t
bibliograph
y
.
W
e
shall
giv
e
here
an
axiomatization
of
a
fairly
simple
mo
dal
logic,
the
system
M
of
F
eys
{
v
on
W
righ
t.
One
adds
to
an
y
full
axiomatization
of
prop
ositional
calculus
the
follo
wing:
Ax:
:
p
!
p.
Ax:
:
(p
!
q
)
!
(p
!
q
).
Rule
:
from
p
and
p
!
q
,
infer
q
.
Rule
:
from
p,
infer
p.
(This
axiomatization
is
due
to
G
odel.)
There
is
also
a
dual
mo
dal
op
erator
,
dened
as
::.
Its
in
tuitiv
e
meaning
is
`p
ossibly':
p
is
true
when
p
is
at
least
p
ossible,
although
p
ma
y
b
e
in
fact
false
(or
true).
The
reader
will
b
e
able
to
see
the
in
tuitiv
e
corresp
ondence
b
et
w
een
:

p|p
is
imp
ossible,
and
:p|that
is,
p
is
necessarily
false.
M
is
a
fairly
w
eak
mo
dal
logic.
One
can
strengthen
it
b
y
adding
axioms,
for
example,
adding
Ax:
:
p
!

p
yields
the
system
called
S
;
adding
Ax:
:
p
!


p
yields
S
;
and
other
additions
are
p
ossible.
Ho
w
ev
er,
one
can
also
w
eak
en
all
the
systems
in
v
arious
w
a
ys,
for
instance
b
y
c
hanging
Ax:
to
Ax:
0
:
p
!
p.
One
easily
sees
that
Ax:
implies
Ax:
0
,
but
the
con
v
erse
is
not
true.
The
systems
obtained
in
this
w
a
y
are
kno
wn
as
the
de
ontic
v
ersions
of
the
systems.
These
mo
dications
will
b
e
useful
later
when
w
e
come
to
consider
tense-logics
as
mo
dal
logics.
One
should
note
that
the
truth
or
falsit
y
of
p
is
not
decided
b
y
p's
b
eing
true.
Th
us

is
not
a
truth-functional
op
erator
(unlik
e
the
usual
logical


----- Page 39 (native) -----
connectiv
es,
for
instance)
and
so
there
is
no
direct
w
a
y
of
using
truth-tables
to
analyze
prop
ositions
con
taining
mo
dal
op
erators.
In
fact
the
decision
problem
for
mo
dal
prop
ositional
calculi
has
b
een
quite
non
trivial.
It
is
just
this
prop
ert
y
whic
h
mak
es
mo
dal
calculi
so
useful,
as
b
elief,
tense,
etc.,
when
in
terpreted
as
prop
ositional
op
erators,
are
all
non
truthfunctional.
The
proliferation
of
mo
dal
prop
ositional
calculi,
with
no
clear
means
of
comparison,
w
e
shall
call
the
f
ir
st
pr
obl
em
of
mo
dal
logic.
Other
diculties
arise
when
w
e
consider
mo
dal
predicate
calculi,
that
is,
when
w
e
attempt
to
in
tro
duce
quan
tiers.
This
w
as
rst
done
b
y
Barcan-Marcus
(	).
Unfortunately
,
all
the
early
attempts
at
mo
dal
predicate
calculi
had
unin-
tuitiv
e
theorems
(see
for
instance
Kripk
e
	a),
and,
moreo
v
er,
all
of
them
met
with
diculties
connected
with
the
failure
of
Leibniz'
la
w
of
iden
tit
y
,
whic
h
w
e
shall
try
to
outline.
Leibniz'
la
w
is
L
:
x:y
:
x
=
y
!
(F
(x)

F
(y
))
where
F
is
an
y
op
en
sen
tence.
No
w
this
la
w
fails
in
mo
dal
con
texts.
F
or
instance,
consider
this
instance
of
L:
L

:
x:y
:x
=
y
!
((x
=
x)

(x
=
y
)):
By
rule

of
M
(whic
h
is
presen
t
in
almost
all
mo
dal
logics),
since
x
=
x
is
a
theorem,
so
is
(x
=
x).
Th
us
L

yields
L

:
x:
y
:
x
=
y
!
(x
=
y
):
But,
the
argumen
t
go
es,
this
is
coun
terin
tuitiv
e.
F
or
instance
the
morning
star
is
in
fact
the
same
individual
as
the
ev
ening
star
(the
planet
V
en
us).
Ho
w
ev
er,
they
are
not
ne
c
essarily
equal:
one
can
easily
imagine
that
they
migh
t
b
e
distinct.
This
famous
example
is
kno
wn
as
the
`morning
star
para-
do
x'.
This
and
related
diculties
comp
el
one
to
abandon
Leibniz'
la
w
in
mo
dal
predicate
calculi,
or
else
to
mo
dify
the
la
ws
of
quan
tication
(so
that
it
is
imp
ossible
to
obtain
the
undesirable
instances
of
univ
ersal
sen
tences
suc
h
as
L

).
This
solv
es
the
purely
formal
problem,
but
leads
to
sev
ere
diculties
in
in
terpreting
these
calculi,
as
Quine
has
urged
in
sev
eral
pap
ers
(cf.
Quine
	).
The
dicult
y
is
this.
A
sen
tence
(a)
is
usually
though
t
of
as
ascribing
some
prop
ert
y
to
a
certain
individual
a.
No
w
consider
the
morning
star;


----- Page 40 (native) -----
clearly
,
the
morning
star
is
necessarily
equal
to
the
morning
star.
Ho
w
ev
er,
the
ev
ening
star
is
not
necessarily
equal
to
the
morning
star.
Th
us,
this
one
individual|the
planet
V
en
us|b
oth
has
and
do
es
not
ha
v
e
the
prop-
ert
y
of
b
eing
necessarily
equal
to
the
morning
star.
Ev
en
if
w
e
abandon
prop
er
names
the
dicult
y
do
es
not
disapp
ear:
for
ho
w
are
w
e
to
in
terpret
a
statemen
t
lik
e
	x:	y
(x
=
y
^
(x)
^
:(y
))?
Barcan-Marcus
has
urged
an
uncon
v
en
tional
reading
of
the
quan
tiers
to
a
v
oid
this
problem.
The
discussion
b
et
w
een
her
and
Quine
in
Barcan-Marcus
(	)
is
v
ery
illuminating.
Ho
w
ev
er,
this
raises
some
diculties|see
Belnap
and
Dunn
(	)|and
the
recen
t
seman
tic
theory
of
mo
dal
logic
pro
vides
a
more
satisfactory
metho
d
of
in
terpreting
mo
dal
sen
tences.
This
theory
w
as
dev
elop
ed
b
y
sev
eral
authors
(Hin
tikk
a
	,
	a;
Kanger
	;
Kripk
e
	a,
	b,
	),
but
c
hiey
b
y
Kripk
e.
W
e
shall
try
to
giv
e
an
outline
of
this
theory
,
but
if
the
reader
nds
it
inadequate
he
should
consult
Kripk
e
(	a).
The
idea
is
that
mo
dal
calculi
describ
e
sev
eral
p
ossible
worlds
at
once,
in-
stead
of
just
one.
Statemen
ts
are
not
assigned
a
single
truth-v
alue,
but
rather
a
sp
ectum
of
truth-v
alues,
one
in
eac
h
p
ossible
w
orld.
No
w,
a
statemen
t
is
necessary
when
it
is
true
in
al
l
p
ossible
w
orlds|more
or
less.
Actually
,
in
or-
der
to
get
dieren
t
mo
dal
logics
(and
ev
en
then
not
all
of
them)
one
has
to
b
e
a
bit
more
subtle,
and
ha
v
e
a
binary
relation
on
the
set
of
p
ossible
w
orlds|
the
alternativ
eness
relation.
Then
a
statemen
t
is
necessary
in
a
w
orld
when
it
is
true
in
all
alternativ
es
to
that
w
orld.
No
w
it
turns
out
that
man
y
com-
mon
axioms
of
mo
dal
prop
ositional
logics
corresp
ond
directly
to
conditions
of
alternativ
eness.
Th
us
for
instance
in
the
system
M
ab
o
v
e,
Ax:
corre-
sp
onds
to
the
reexiv
eness
of
the
alternativ
eness
relation;
Ax:(p
!

p)
corresp
onds
to
its
transitivit
y
.
If
w
e
mak
e
the
alternativ
eness
relation
in
to
an
equiv
alence
relation,
then
this
is
just
lik
e
not
ha
ving
one
at
all;
and
it
corresp
onds
to
the
axiom:
p
!


p.
This
seman
tic
theory
already
pro
vides
an
answ
er
to
the
rst
problem
of
mo
dal
logic:
a
rational
metho
d
is
a
v
ailable
for
classifying
the
m
ultitude
of
prop
ositional
mo
dal
logics.
More
imp
ortan
tly
,
it
also
pro
vides
an
in
telligible
in
terpretation
for
mo
dal
predicate
calculi.
One
has
to
imagine
eac
h
p
ossible
w
orld
as
ha
ving
a
set
of
individuals
and
an
assignmen
t
of
individuals
to
names
of
the
language.
Then
eac
h
statemen
t
tak
es
on
its
truth
v
alue
in
a
w
orld
s
according
to
the
particular
set
of
individuals
and
assignmen
t
asso
ciated
with
s.
Th
us,
a
p
ossible
w
orld
is
an
in
terpretation
of
the
calculus,
in
the
usual
sense.
0

----- Page 41 (native) -----
No
w,
the
failure
of
Leibniz'
la
w
is
no
longer
puzzling,
for
in
one
w
orld
the
morning
star|for
instance|ma
y
b
e
equal
to
(the
same
individual
as)
the
ev
ening
star,
but
in
another
the
t
w
o
ma
y
b
e
distinct.
There
are
still
diculties,
b
oth
formal|the
quan
tication
rules
ha
v
e
to
b
e
mo
died
to
a
v
oid
unin
tuitiv
e
theorems
(see
Kripk
e,
	a,
for
the
details)|
and
in
terpretativ
e:
it
is
not
ob
vious
what
it
means
to
ha
v
e
the
same
individ-
ual
existing
in
dier
ent
w
orlds.
It
is
p
ossible
to
gain
the
expressiv
e
p
o
w
er
of
mo
dal
logic
without
using
mo
dal
op
erators
b
y
constructing
an
ordinary
truth-functional
logic
whic
h
describ
es
the
m
ultiple
-w
orld
seman
tics
of
mo
dal
logic
directly
.
T
o
do
this
w
e
giv
e
ev
ery
predicate
an
extra
argumen
t
(the
w
orld-v
ariable;
or
in
our
terminology
the
situation-v
ariable)
and
instead
of
writing
`',
w
e
write
t:A(s;
t)
!
(t);
where
A
is
the
alternativ
eness
relation
b
et
w
een
situations.
Of
course
w
e
m
ust
pro
vide
appropriate
axioms
for
A.
The
resulting
theory
will
b
e
expressed
in
the
notation
of
the
situation
calculus;
the
prop
osition

has
b
ecome
a
prop
ositional
uen
t
s:(s),
and
the
`p
ossible
w
orlds'
of
the
mo
dal
seman
tics
are
precisely
the
situations.
Notice,
ho
w
ev
er,
that
the
theory
w
e
get
is
w
eak
er
than
what
w
ould
ha
v
e
b
een
obtained
b
y
adding
mo
dal
op
erators
directly
to
the
situation
calculus,
for
w
e
can
giv
e
no
translation
of
assertions
suc
h
as

(s),
where
s
is
a
situation,
whic
h
this
enric
hed
situation
calculus
w
ould
con
tain.
It
is
p
ossible,
in
this
w
a
y
,
to
reconstruct
within
the
situation
calculus
subtheories
corresp
onding
to
the
tense-logics
of
Prior
and
to
the
kno
wledge
logics
of
Hin
tikk
a,
as
w
e
shall
explain
b
elo
w.
Ho
w
ev
er,
there
is
a
qualication
here:
so
far
w
e
ha
v
e
only
explained
ho
w
to
translate
the
prop
ositional
mo
dal
logics
in
to
the
situation
calculus.
In
order
to
translate
quan
tied
mo
dal
logic,
with
its
diculties
of
referen
tial
opacit
y
,
w
e
m
ust
complicate
the
situation
calculus
to
a
degree
whic
h
mak
es
it
rather
clumsy
.
There
is
a
sp
ecial
predicate
on
individuals
and
situations|exists(i,s)|whic
h
is
regarded
as
true
when
i
names
an
individual
existing
in
the
situation
s.
This
is
necessary
b
ecause
situations
ma
y
con
tain
dieren
t
individuals.
Then
quan
tied
assertions
of
the
mo
dal
logic
are
translated
according
to
the
follo
wing
sc
heme:
x:(x)
!
x:exists(x;
s)
!
(x;
s)
where
s
is
the
in
tro
duced
situation
v
ariable.
W
e
shall
not
go
in
to
the
details
of
this
extra
translation
in
the
examples
b
elo
w,
but
shall
b
e
con
ten
t
to
dene
the


----- Page 42 (native) -----
translations
of
the
prop
ositional
tense
and
kno
wledge
logics
in
to
the
situation
calculus.
.
Logic
of
Kno
wledge
The
logic
of
kno
wledge
w
as
rst
in
v
estigated
as
a
mo
dal
logic
b
y
Hin
tikk
a
in
his
b
o
ok
Know
le
dge
and
b
elief
(	).
W
e
shall
only
describ
e
the
kno
wledge
calculus.
He
in
tro
duces
the
mo
dal
op
erator
K
a
(read
`a
kno
ws
that'),
and
its
dual
P
a
,
dened
as
:K
a
:.
The
seman
tics
is
obtained
b
y
the
analogous
read-
ing
of
K
a
as:
`it
is
true
in
all
p
ossible
w
orlds
compatible
with
a's
kno
wledge
that'.
The
prop
ositional
logic
of
K
a
(similar
to
)
turns
out
to
b
e
S
,
that
is
M
+
Ax:;
but
there
are
some
complexities
o
v
er
quan
tication.
(The
last
c
hapter
of
the
b
o
ok
con
tains
another
excellen
t
accoun
t
of
the
o
v
erall
problem
of
quan
tication
in
mo
dal
con
texts.)
This
analysis
of
kno
wledge
has
b
een
criticized
in
v
arious
w
a
ys
(Chisholm
	,
F
ollesdal
	)
and
Hin
tikk
a
has
replied
in
sev
eral
imp
ortan
t
pap
ers
(	b,
	c,
	).
The
last
pap
er
con-
tains
a
review
of
the
dieren
t
senses
of
`kno
w'
and
the
exten
t
to
whic
h
they
ha
v
e
b
een
adequately
formalized.
It
app
ears
that
t
w
o
senses
ha
v
e
resisted
capture.
First,
the
idea
of
`kno
wing
ho
w',
whic
h
app
ears
related
to
our
`can';
and
secondly
,
the
concept
of
kno
wing
a
p
erson
(place,
etc.)
when
this
means
`b
eing
acquain
ted
with'
as
opp
osed
to
simply
kno
wing
who
a
p
erson
is.
In
order
to
translate
the
(prop
ositional)
kno
wledge
calculus
in
to
`situa-
tion'
language,
w
e
in
tro
duce
a
three-place
predicate
in
to
the
situation
calcu-
lus
termed
`shrug'.
S
hr
ug
(p;
s

;
s

),
where
p
is
a
p
erson
and
s

and
s

are
situations,
is
true
when,
if
p
is
in
fact
in
situation
s

,
then
for
all
he
kno
ws
he
migh
t
b
e
in
situation
s

.
That
is
to
sa
y
,
s

is
an
epistemic
alternative
to
s

,
as
far
as
the
individual
p
is
concerned|this
is
Hin
tikk
a's
term
for
his
alternativ
e
w
orlds
(he
calls
them
mo
del-sets).
Then
w
e
translate
K
p
q
,
where
q
is
a
prop
osition
of
Hin
tikk
a's
calculus,
as
t:shr
ug
(p;
t;
s)
!
q
(t),
where
s:q
(s)
is
the
uen
t
whic
h
translates
q
.
Of
course
w
e
ha
v
e
to
supply
axioms
for
shr
ug
,
and
in
fact
so
far
as
the
pure
kno
wledge-calculus
is
concerned,
the
only
t
w
o
necessary
are
K

:
s:p:shr
ug
(p;
s;
s)
and
K

:
p:s:
t:

r
:
(shr
ug
(p;
t;
s)
^
shr
ug
(p;
r
;
t))
!
shr
ug
(p;
r
;
s)


----- Page 43 (native) -----
that
is,
reexivit
y
and
transitivit
y
.
Others
of
course
ma
y
b
e
needed
when
w
e
add
tenses
and
other
mac
hinery
to
the
situation
calculus,
in
order
to
relate
kno
wledge
to
them.
.
T
ense
Logics
This
is
one
of
the
largest
and
most
activ
e
areas
of
philosophic
logic.
Prior's
b
o
ok
Past,
Pr
esent
and
F
utur
e
(	)
is
an
extremel
y
thorough
and
lucid
accoun
t
of
what
has
b
een
done
in
the
eld.
W
e
ha
v
e
already
men
tioned
the
four
prop
ositional
op
erators
F
,
G,
P
,
H
whic
h
Prior
discusses.
He
regards
these
as
mo
dal
op
erators;
then
the
alternativ
eness
relation
of
the
seman
tic
theory
is
simply
the
time-ordering
relation.
V
arious
axiomatizations
are
giv
en,
corresp
onding
to
deterministic
and
nondeterministic
tenses,
ending
and
nonending
times,
etc;
and
the
problems
of
quan
tication
turn
up
again
here
with
renew
ed
in
tensit
y
.
T
o
attempt
a
summary
of
Prior's
b
o
ok
is
a
hop
eless
task,
and
w
e
simply
urge
the
reader
to
consult
it.
More
recen
tly
sev
eral
pap
ers
ha
v
e
app
eared
(see,
for
instance,
Bull
	)
whic
h
illustrate
the
tec
hnical
sophistication
tense-logic
has
reac
hed,
in
that
full
completeness
pro
ofs
for
v
arious
axiom
systems
are
no
w
a
v
ailable.
As
indicated
ab
o
v
e,
the
situation
calculus
con
tains
a
tense-logic
(or
rather
sev
eral
tense-logics),
in
that
w
e
can
dene
Prior's
four
op
erators
in
our
system
and
b
y
suitable
axioms
reconstruct
v
arious
axiomatizations
of
these
four
op
erators
(in
particular,
all
the
axioms
in
Bull
(	)
can
b
e
translated
in
to
the
situation
calculus).
Only
one
extra
nonlogical
predicate
is
necessary
to
do
this:
it
is
a
binary
predicate
of
situations
called
c
ohistoric
al,
and
is
in
tuitiv
ely
mean
t
to
assert
of
its
argumen
ts
that
one
is
in
the
other's
future.
This
is
necessary
b
ecause
w
e
w
an
t
to
consider
some
pairs
of
situations
as
b
eing
not
temp
orally
related
at
all.
W
e
no
w
dene
F
(for
instance)
th
us:
F
(
;
s)

	t:cohistor
ical
(t;
s)
^
time(t)
>
time(s)
^

(t):
The
other
op
erators
are
dened
analogously
.
Of
course
w
e
ha
v
e
to
supply
axioms
for
`cohistorical'
and
time:
this
is
not
dicult.
F
or
instance,
consider
one
of
Bull's
axioms,
sa
y
Gp
!
GGp,
whic
h
is
b
etter
(for
us)
expressed
in
the
form
F
F
p
!
F
p.
Using
the
denition,
this
translates
in
to:


----- Page 44 (native) -----
(	t:cohistor
ical
(t;
s)
^
time(t)
>
time(s)
^	r
:cohistor
ical
(r
;
t)
^
time(r
)
>
time(t)
^

(r
))
!
(	r
:cohistor
ical
(r
;
s)
^
time(r
)
>
time(s)
^

(r
))
()
whic
h
simplies
(using
the
transitivit
y
of
`>')
to
t:
r
:
(cohistor
ical
(r
;
t)
^
cohistor
ical
(t;
s))
!
cohistor
ical
(r
;
s)
that
is,
the
transitivit
y
of
`cohistorical'.
This
axiom
is
precisely
analogous
to
the
S

axiom
p
!

p,
whic
h
corresp
onded
to
transitivit
y
of
the
alternativ
eness
relation
in
the
mo
dal
seman
tics.
Bull's
other
axioms
translate
in
to
conditions
on
`cohistorical'
and
time
in
a
similar
w
a
y;
w
e
shall
not
b
other
here
with
the
rather
tedious
details.
Rather
more
in
teresting
w
ould
b
e
axioms
relating
`shrug'
to
`cohistorical'
and
time;
unfortunately
w
e
ha
v
e
b
een
unable
to
think
of
an
y
in
tuitiv
ely
plausible
ones.
Th
us,
if
t
w
o
situations
are
epistemic
alternativ
es
(that
is,
shr
ug
(p;
s

;
s

))
then
they
ma
y
or
ma
y
not
ha
v
e
the
same
time
v
alue
(since
w
e
w
an
t
to
allo
w
that
p
ma
y
not
kno
w
what
the
time
is),
and
they
ma
y
or
ma
y
not
b
e
cohistorical.
.
Logics
and
Theories
of
Action
The
most
fully
dev
elop
ed
theory
in
this
area
is
v
on
W
righ
t's
action
logic
describ
ed
in
his
b
o
ok
Norm
and
A
ction
(	).
V
on
W
righ
t
builds
his
logic
on
a
rather
un
usual
tense-logic
of
his
o
wn.
The
basis
is
a
binary
mo
dal
connectiv
e
T
,
so
that
pT
q
,
where
p
and
q
are
prop
ositions,
means
`p;
thenq
'.
Th
us
the
action,
for
instance,
of
op
ening
the
windo
w
is:
(the
window
is
close
d)
T
(the
window
is
op
en).
The
formal
dev
elopmen
t
of
the
calculus
w
as
tak
en
a
long
w
a
y
in
the
b
o
ok
cited
ab
o
v
e,
but
some
problems
of
in
terpretation
remained
as
Castaneda
p
oin
ts
out
in
his
review
(	).
In
a
more
recen
t
pap
er
v
on
W
righ
t
(	)
has
altered
and
extended
his
formalism
so
as
to
answ
er
these
and
other
criticisms,
and
also
has
pro
vided
a
sort
of
seman
tic
theory
based
on
the
notion
of
a
life-tree.
W
e
kno
w
of
no
other
attempts
at
constructing
a
single
theory
of
actions
whic
h
ha
v
e
reac
hed
suc
h
a
degree
of
dev
elopmen
t,
but
there
are
sev
eral
dis-
cussions
of
diculties
and
surv
eys
whic
h
seem
imp
ortan
t.
Resc
her
(	)
discusses
sev
eral
topics
v
ery
neatly
,
and
Da
vidson
(	)
also
mak
es
some


----- Page 45 (native) -----
cogen
t
p
oin
ts.
Da
vidson's
main
thesis
is
that,
in
order
to
translate
statemen
ts
in
v
olving
actions
in
to
the
predicate
calculus,
it
app
ears
necessary
to
allo
w
actions
as
v
alues
of
b
ound
v
ariables,
that
is
(b
y
Quine's
test)
as
real
indi-
viduals.
The
situation
calculus
of
course
follo
ws
this
advice
in
that
w
e
allo
w
quan
tication
o
v
er
strategies,
whic
h
ha
v
e
actions
as
a
sp
ecial
case.
Also
im-
p
ortan
t
are
Simon's
pap
ers
(	,
	)
on
command-logics.
Simon's
main
purp
ose
is
to
sho
w
that
a
sp
ecial
logic
of
commands
is
unnecessary
,
ordinary
logic
serving
as
the
only
deductiv
e
mac
hinery;
but
this
need
not
detain
us
here.
He
mak
es
sev
eral
p
oin
ts,
most
notably
p
erhaps
that
agen
ts
are
most
of
the
time
not
p
erforming
actions,
and
that
in
fact
they
only
stir
to
ac-
tion
when
forced
to
b
y
some
outside
in
terference.
He
has
the
particularly
in
teresting
example
of
a
serial
pro
cessor
op
erating
in
a
parallel-demand
en-
vironmen
t,
and
the
resulting
need
for
in
terrupts.
Action
logics
suc
h
as
v
on
W
righ
t's
and
ours
do
not
distinguish
b
et
w
een
action
and
inaction,
and
w
e
are
not
a
w
are
of
an
y
action-logic
whic
h
has
reac
hed
a
stage
of
sophistication
adequate
to
meet
Simon's
implied
criticism.
There
is
a
large
b
o
dy
of
purely
philosophical
writings
on
action,
time,
determinism
,
etc.,
most
of
whic
h
is
irrelev
an
t
for
presen
t
purp
oses.
Ho
w
ev
er,
w
e
men
tion
t
w
o
whic
h
ha
v
e
recen
tly
app
eared
and
whic
h
seem
in
teresting:
a
pap
er
b
y
Chisholm
(	)
and
another
pap
er
b
y
Ev
ans
(	),
summarizi
ng
the
recen
t
discussion
on
the
distinctions
b
et
w
een
states,
p
erformances
and
activities.
.
Other
T
opics
There
are
t
w
o
other
areas
where
some
analysis
of
actions
has
b
een
neces-
sary:
command-logics
and
logics
and
theories
of
obligation.
F
or
the
former
the
b
est
reference
is
Resc
her's
b
o
ok
(	)
whic
h
has
an
excellen
t
bibliogra-
ph
y
.
Note
also
Simon's
coun
terargumen
ts
to
some
of
Resc
her's
theses
(Simon
	,
	).
Simon
prop
oses
that
no
sp
ecial
logic
of
commands
is
necessary
,
commands
b
eing
analyzed
in
the
form
`bring
it
ab
out
that
p!'
for
some
prop
osition
p,
or,
more
generally
,
in
the
form
`bring
it
ab
out
that
P
(x)
b
y
c
hanging
x!',
where
x
is
a
c
ommand
v
ariable,
that
is,
under
the
agen
t's
con-
trol.
The
translations
b
et
w
een
commands
and
statemen
ts
tak
e
place
only
in
the
con
text
of
a
`complete
mo
del',
whic
h
sp
ecies
en
vironmen
tal
constrain
ts
and
denes
the
command
v
ariables.
Resc
her
argues
that
these
sc
hemas
for
commands
are
inadequate
to
handle
the
c
onditional
c
ommand
`when
p,
do
q
',
whic
h
b
ecomes
`bring
it
ab
out
that
(p
!
q
)!':
this,
unlik
e
the
former,
is


----- Page 46 (native) -----
satised
b
y
making
p
false.
There
are
man
y
pap
ers
on
the
logic
of
obligation
and
p
ermission.
V
on
W
righ
t's
w
ork
is
orien
ted
in
this
direction;
Casta
~
neda
has
man
y
pap
ers
on
the
sub
ject
and
Anderson
also
has
written
extensiv
ely
(his
early
inuen
tial
rep
ort
(	)
is
esp
ecially
w
orth
reading).
The
review
pages
of
the
Journal
of
Symb
olic
L
o
gic
pro
vide
man
y
other
references.
Un
til
fairly
recen
tly
these
theories
did
not
seem
of
v
ery
m
uc
h
relev
ance
to
logics
of
action,
but
in
their
new
maturit
y
they
are
b
eginning
to
b
e
so.
.
Coun
terfactuals
There
is,
of
course,
a
large
literature
on
this
ancien
t
philosophical
problem,
almost
none
of
whic
h
seems
directly
relev
an
t
to
us.
Ho
w
ev
er,
there
is
one
recen
t
theory
,
dev
elop
ed
b
y
Resc
her
(	),
whic
h
ma
y
b
e
of
use.
Resc
her's
b
o
ok
is
so
clearly
written
that
w
e
shall
not
attempt
a
description
of
his
theory
here.
The
reader
should
b
e
a
w
are
of
Sosa's
critical
review
(	)
whic
h
suggests
some
minor
alterations.
The
imp
ortance
of
this
theory
for
us
is
that
it
suggests
an
alternativ
e
approac
h
to
the
dicult
y
whic
h
w
e
ha
v
e
referred
to
as
the
frame
problem.
In
outline,
this
is
as
follo
ws.
One
assumes,
as
a
rule
of
pro
cedure
(or
p
erhaps
as
a
rule
of
inference),
that
when
actions
are
p
erformed,
al
l
prop
ositional
uen
ts
whic
h
applied
to
the
previous
situation
also
apply
to
the
new
situation.
This
will
often
yield
an
inconsisten
t
set
of
statemen
ts
ab
out
the
new
situation;
Resc
her's
theory
pro
vides
a
mec
hanism
for
restoring
consistency
in
a
rational
w
a
y
,
and
giving
as
a
b
y-pro
duct
those
uen
ts
whic
h
c
hange
in
v
alue
as
a
result
of
p
erforming
the
action.
Ho
w
ev
er,
w
e
ha
v
e
not
in
v
estigated
this
in
detail.
.
The
Comm
unication
Pro
cess
W
e
ha
v
e
not
considered
the
problems
of
formally
describing
the
pro
cess
of
comm
unic
ation
in
this
pap
er,
but
it
seems
clear
that
they
will
ha
v
e
to
b
e
tac
kled
ev
en
tually
.
Philosophical
logicians
ha
v
e
b
een
sp
on
taneously
activ
e
here.
The
ma
jor
w
ork
is
Harrah's
b
o
ok
(	);
Cressw
ell
has
written
sev-
eral
pap
ers
on
`the
logic
of
in
terrogativ
es',
see
for
instance
Cressw
ell
(	).
Among
other
authors
w
e
ma
y
men
tion

Aqvist
(	)
and
Belnap
(	);
again
the
review
pages
of
the
Journal
of
Symb
olic
L
o
gic
will
pro
vide
other
references.


----- Page 47 (native) -----
Ac
kno
wledgemen
ts
The
researc
h
rep
orted
here
w
as
supp
orted
in
part
b
y
the
Adv
anced
Re-
searc
h
Pro
jects
Agency
of
the
Oce
of
the
Secretary
of
Defense
(SD-),
and
in
part
b
y
the
Science
Researc
h
Council
(B/SR/		).

References
Anderson,
A.R.
(	).
The
formal
analysis
of
normativ
e
systems.
Reprin
ted
in
The
L
o
gic
of
de
cision
and
action
(ed.
Resc
her,
N.).
Pittsburgh:
Univ
ersit
y
of
Pittsburgh
Press.

Aqvist,
L.
(	).
A
new
appr
o
ach
to
the
lo
gic
al
the
ory
of
interr
o
gatives,
p
art
I.
Uppsala:
Uppsala
Philosophical
Asso
ciation.
Barcan-Marcus,
R.C.
(	).
A
functional
calculus
of
the
rst
order
based
on
strict
implication.
Journal
of
Symb
olic
L
o
gic,
,
-.
Barcan-Marcus,
R.C.
(	).
Mo
dalities
and
in
tensional
languages.
Boston
studies
in
the
Philosophy
of
Scienc
e.
(ed.
W
artofsky
,
W.).
Dordrec
h
t,
Hol-
land.
Belnap,
N.D.
(	).
A
n
analysis
of
questions.
San
ta
Monica.
Belnap,
N.D.
and
Dunn,
J.M.
(	).
The
substitution
in
terpretation
of
the
quan
tiers.
Nous,
,
-.
Bull,
R.A.
(	).
An
algebraic
study
of
tense
logics
with
linear
time.
Jour-
nal
of
Symb
olic
L
o
gic,
,
-	.
Casta
~
neda,
H.N.
(	).
The
logic
of
c
hange,
action
and
norms.
Journal
of
Philosophy,
,
-.
Chisholm,
R.M.
(	).
The
logic
of
kno
wing.
Journal
of
Philosophy,
0,
-	.
Chisholm,
R.M.
(	).
He
could
ha
v
e
done
otherwise.
Journal
of
Philoso-
phy,
,
0	-.
Ch
urc
h,
A.
(	).
Intr
o
duction
to
Mathematic
al
L
o
gic.
Princeton:
Prince-
ton
Univ
ersit
y
Press.
Cressw
ell,
M.J.
(	).
The
logic
of
in
terrogativ
es.
F
ormal
systems
and
r
e-


----- Page 48 (native) -----
cursive
functions.
(ed.
Crossley
,
J.M.
and
Dummett,
M.A.E.).
Amsterdam:
North-Holland.
Da
vidson,
D.
(	).
The
logical
form
of
action
sen
tences.
The
lo
gic
of
de
cision
and
action.
(ed.
Resc
her,
N.).
Pittsburgh:
Univ
ersit
y
of
Pittsburgh
Press.
Ev
ans,
C.O.
(	).
States,
activities
and
p
erformances.
A
ustr
alian
Journal
of
Philosophy,
,
	-0.
F
eys,
R.
(	).
Mo
dal
L
o
gics.
(ed.
Dopp,
J.).
Louv
ain:
Coll.
de
Logique
Math.
serie
B.
F
ogel,
L.J.,
Ow
ens,
A.J.
and
W
alsh,
M.J.
(	).
A
rticial
Intel
ligenc
e
thr
ough
simulate
d
evolution.
New
Y
ork:
John
Wiley
.
F
ollesdal,
D.
(	).
Kno
wledge,
iden
tit
y
and
existence.
The
oria,
,
-.
F
riedb
erg,
R.M.
(	).
A
learning
mac
hine,
part
I.
IBM
J.
R
es.
Dev.,
,
-.
F
riedb
erg,
R.M.,
Dunham,
B.,
and
North,
J.H.
(		).
A
learning
mac
hine,
part
I
I.
IBM
J.
R
es.
Dev.,
,
-.
Galan
ter,
E.
and
Gerstenhab
er,
M.
(	).
On
though
t:
the
extrinsic
theory
.
Psycholo
gic
al
R
eview,
,
-.
Green,
C.
(		).
Theorem-pro
ving
b
y
resolution
as
a
basis
for
question-
answ
ering
systems.
Machine
Intel
ligen
c
e
,
pp.
-0
(eds.
Meltzer,
B.
and
Mic
hie,
D.).
Edin
burgh:
Edin
burgh
Univ
ersit
y
Press.
Harrah,
D.
(	).
Communic
ation:
a
lo
gic
al
mo
del.
Cam
bridge,
Mas-
sac
h
usetts:
MIT
Press.
Hin
tikk
a,
J.
(	).
Know
le
dge
and
b
elief:
an
intr
o
duction
to
the
lo
gic
of
two
notions.
New
Y
ork:
Cornell
Univ
ersit
y
Press.
Hin
tikk
a,
J.
(	).
The
mo
des
of
mo
dalit
y
.
A
cta
Philosophic
a
F
ennic
a,
,
-.
Hin
tikk
a,
J.
(	a).
A
program
and
a
set
of
concepts
for
philosophical
logic.
The
Monist,
,
	-.
Hin
tikk
a,
J.
(	b).
Existence
and
iden
tit
y
in
epistemic
con
texts.
The
oria,
,
-.


----- Page 49 (native) -----
Hin
tikk
a,
J.
(	c).
Individuals,
p
ossible
w
orlds
and
epistemic
logic.
Nous,
,
-.
Hin
tikk
a,
J.
(	).
Dieren
t
constructions
in
terms
of
the
basic
epistemo-
logical
v
erbs.
Contemp
or
ary
Philosophy
in
Sc
andinavia
(eds.
Olsen,
R.E.
and
P
aul,
A.
M.),
Baltimore:
The
John
Hopkins
Press,
0-.
Kanger,
S.
(	).
A
note
on
quan
tication
and
mo
dalities.
The
oria,
,
-.
Kripk
e,
S.
(	a).
Seman
tical
considerations
on
mo
dal
logic.
A
cta
Philo-
sophic
a
F
ennic
a,
,
-	.
Kripk
e,
S.
(	b).
Seman
tical
analysis
of
mo
dal
logic
I.
Zeitschrift
fur
math.
L
o
gik
und
Grund
lagen
der
Mathematik,
	,
-	.
Kripk
e,
S.
(	).
Seman
tical
analysis
of
mo
dal
logic
I
I.
The
the
ory
of
mo
dels
(eds.
Addison,
Henkin
and
T
arski).
Amsterdam:
North-Holland.
Lewis,
C.I.
(	).
A
survey
of
symb
olic
lo
gic.
Berk
eley:
Univ
ersit
y
of
California
Press.
Manna,
Z.
(	a).
T
ermination
of
algorithms.
Ph.D.
Thesis,
Carnegie-
Mellon
Univ
ersit
y
.
Manna,
Z.
(	b).
F
ormalization
of
pr
op
erties
of
pr
o
gr
ams
Stanford
Arti-
cial
In
telligence
Rep
ort:
Pro
ject
Memo
AI-.
McCarth
y
,
J.
(		).
Programs
with
common
sense.
Me
chanization
of
thought
pr
o
c
esses,
V
ol.
I.
London:
Her
Ma
jest
y's
Stationery
Oce.
(Reprin
ted
in
this
v
olume,
pp.
000{000).
McCarth
y
,
J.
(	).
T
o
w
ards
a
mathematical
science
of
computation.
Pr
o
c.
IFIP
Congr
ess
.
Amsterdam:
North-Holland
Press.
McCarth
y
,
J.
(	).
Situations,
actions
and
c
ausal
laws.
Stanford
Articial
In
telligence
Pro
ject:
Memo
.
Minsky
,
M.
(	).
Steps
to
w
ards
articial
in
telligence.
Pr
o
c
e
e
dings
of
the
I.R.E.,
	,
-0.
New
ell,
A.,
Sha
w,
V.C.
and
Simon,
H.A.
(		).
Rep
ort
on
a
general
problem-solving
program.
Pr
o
c
e
e
dings
ICIP.
P
aris:UNESCO
House.
New
ell,
A.
and
Simon,
H.A.
(	).
GPS
-
a
program
that
sim
ulates
h
uman
problem-solving.
Pr
o
c
e
e
dings
of
a
c
onfer
enc
e
in
le
arning
automata.
Munic
h:


----- Page 50 (native) -----
Olden
b
ourgh.
New
ell,
A.
(	).
Limitations
of
the
curren
t
sto
c
k
of
ideas
ab
out
problem-
solving.
Pr
o
c
e
e
dings
of
a
c
onfer
enc
e
on
Ele
ctr
onic
Information
Hand
ling,
pp.
	-0
(eds.
Ken
t,
A.
and
T
aulb
ee,
O.).
New
Y
ork:
Spartan.
New
ell,
A.
and
Ernst,
C.
(	).
The
searc
h
for
generalit
y
.
Pr
o
c.
IFIP
Congr
ess
.
Piv
ar,
M.
and
Fink
elstein,
M.
(	).
The
Pr
o
gr
amming
L
anguage
LISP:
its
op
er
ation
and
applic
ations
(eds.
Berk
ely
,
E.C.
and
Bobro
w,
D.G.).
Cam-
bridge,
Massac
h
usetts:
MIT
Press.
Prior,
A.N.
(	).
Time
and
mo
dality.
Oxford:
Clarendon
Press.
Prior,
A.N.
(	).
Past,
pr
esent
and
futur
e.
Oxford:
Clarendon
Press.
Quine,
W.V.O.
(	).
Reference
and
mo
dalit
y
.
F
r
om
a
lo
gic
al
p
oint
of
view.
Cam
bridge,
Massac
h
usetts:
Harv
ard
Univ
ersit
y
Press.
Resc
her,
N.
(	).
Hyp
othetic
al
r
e
asoning.
Amsterdam:
North-Holland.
Resc
her,
N.
(	).
The
lo
gic
of
c
ommands.
London:
Routledge.
Resc
her,
N.
(	).
Asp
ects
of
action.
The
lo
gic
of
de
cision
and
action
(ed.
Resc
her,
N.).
Pittsburgh:
Univ
ersit
y
of
Pittsburgh
Press.
Shannon,
C.
(	0).
Programming
a
computer
for
pla
ying
c
hess.
Philosoph-
ic
al
Magazine,
.
Simon,
H.A.
(	).
The
logic
of
rational
decision.
British
Journal
for
the
Philosophy
of
Scienc
e,
,
	-.
Simon,
H.A
(	).
On
R
e
asoning
ab
out
actions.
Carnegie
Institute
of
T
ec
h-
nology:
Complex
Information
Pro
cessing
P
ap
er
.
Simon,
H.A.
(	).
The
logic
of
heuristic
decision
making.
The
lo
gic
of
de
cision
and
action
(ed.
Resc
her,
N.).
Pittsburgh:
Univ
ersit
y
of
Pittsburgh
Press.
Sosa,
E.
(	).
Hyp
othetical
reasoning.
Journal
of
Philosophy,
,
	-0.
T
uring,
A.M.
(	0).
Computing
mac
hinery
and
in
telligence.
Mind,
	,
-0.
v
on
W
righ
t,
C.H.
(	).
Norm
and
action:
a
lo
gic
al
enquiry.
London:
Routledge.
0

----- Page 51 (native) -----
v
on
W
righ
t,
C.H.
(	).
The
Logic
of
Action
-
a
sk
etc
h.
The
lo
gic
of
de
cision
and
action
(ed.
Resc
her,
N.).
Pittsburgh:Univ
ersit
y
of
Pittsburgh
Press.
