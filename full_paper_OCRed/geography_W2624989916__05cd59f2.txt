

----- Page 1 (native) -----
1
A Survey on Mobile Edge Computing: The
Communication Perspective
Yuyi Mao, Changsheng You, Jun Zhang, Kaibin Huang, and Khaled B. Letaief
Abstract‚ÄîDriven by the visions of Internet of Things and
5G communications, recent years have seen a paradigm shift in
mobile computing, from the centralized Mobile Cloud Computing
towards Mobile Edge Computing (MEC). The main feature of
MEC is to push mobile computing, network control and storage
to the network edges (e.g., base stations and access points) so as
to enable computation-intensive and latency-critical applications
at the resource-limited mobile devices. MEC promises dramatic
reduction in latency and mobile energy consumption, tackling
the key challenges for materializing 5G vision. The promised
gains of MEC have motivated extensive efforts in both academia
and industry on developing the technology. A main thrust of
MEC research is to seamlessly merge the two disciplines of
wireless communications and mobile computing, resulting in a
wide-range of new designs ranging from techniques for compu-
tation ofÔ¨Çoading to network architectures. This paper provides a
comprehensive survey of the state-of-the-art MEC research with
a focus on joint radio-and-computational resource management.
We also discusse a set of issues, challenges and future research
directions for MEC research, including MEC system deployment,
cache-enabled MEC, mobility management for MEC, green
MEC, as well as privacy-aware MEC. Advancements in these
directions will facilitate the transformation of MEC from theory
to practice. Finally, we introduce recent standardization efforts
on MEC as well as some typical MEC application scenarios.
Index Terms‚ÄîMobile edge computing, fog computing, mobile
cloud computing, computation ofÔ¨Çoading, resource management,
green computing.
I. INTRODUCTION
The last decade has seen Cloud Computing emerging as a
new paradigm of computing. Its vision is the centralization of
computing, storage and network management in the Clouds,
referring to data centers, backbone IP networks and cellular
core networks [1], [2]. The vast resources available in the
Clouds can then be leveraged to deliver elastic computing
power and storage to support resource-constrained end-user
devices. Cloud Computing has been driving the rapid growth
of many Internet companies. For example, the Cloud business
has risen to be the most proÔ¨Åtable sector for Amazon [3], and
Dropbox‚Äôs success depended highly on the Cloud service of
Amazon.
However, in recent years, a new trend in computing is hap-
pening with the function of Clouds being increasingly moving
towards the network edges [4]. It is estimated that tens of bil-
lions of Edge devices will be deployed in the near future, and
Y. Mao, J. Zhang and K. B. Letaief are with the Dept. of Elec-
tronic and Computer Engineering, The Hong Kong University of Science
and Technology, Hong Kong (Email: ymaoac@ust.hk, eejzhang@ust.hk,
eekhaled@ust.hk). K. B. Letaief is also afÔ¨Åliated with Hamad bin Khalifa
University, Doha, Qatar.
C. You and K. Huang are with the Dept. of Electrical and Elec-
tronic Engineering, The University of Hong Kong, Hong Kong (Email:
csyou@eee.hku.hk, huangkb@eee.hku.hk).
their processor speeds are growing exponentially, following
Moore‚Äôs Law. Harvesting the vast amount of the idle compu-
tation power and storage space distributed at the network edges
can yield sufÔ¨Åcient capacities for performing computation-
intensive and latency-critical tasks at mobile devices. This
paradigm is called Mobile Edge Computing (MEC) [5]. While
long propagation delays remain a key drawback for Cloud
Computing, MEC, with the proximate access, is widely agreed
to be a key technology for realizing various visions for next-
generation Internet, such as Tactile Internet (with millisecond-
scale reaction time) [6], Internet of Things (IoT) [7], and
Internet of Me [8]. Presently, researchers from both academia
and industry have been actively promoting MEC technology
by pursuing the fusion of techniques and theories from both
disciplines of mobile computing and wireless communications.
This paper aims at providing a survey of key research progress
in this young Ô¨Åeld from the communication perspective. We
shall also present a research outlook containing an ensemble
of promising research directions for MEC.
A. Mobile Computing for 5G: From Clouds to Edges
In the past decade, the popularity of mobile devices and the
exponential growth of mobile Internet trafÔ¨Åc have been driving
the tremendous advancements in wireless communications and
networking. In particular, the breakthroughs in small-cell net-
works, multi-antenna, and millimeter-wave communications
promise to provide users gigabit wireless access in next-
generation systems [9]. The high-rate and highly-reliable air
interface allows to run computing services of mobile devices
at the remote cloud data center, resulting in the research area
called Mobile Cloud Computing (MCC). However, there is
an inherent limitation of MCC, namely, the long propagation
distance from the end user to the remote cloud center, which
will result in excessively long latency for mobile applications.
MCC is thus not adequate for a wide-range of emerging
mobile applications that are latency-critical. Presently, new
network architectures are being designed to better integrate the
concept of Cloud Computing into mobile networks, as will be
discussed in the latter part of this article.
In 5G wireless systems, ultra-dense edge devices, including
small-cell base stations (BSs), wireless access points (APs),
laptops, tablets, and smartphones, will be deployed, each
having a computation capacity comparable with that of a
computer server a decade ago. As such, a large population of
devices will be idle at every time instant. It will, in particular,
be harvesting enormous computation and storage resources
available at the network edges, which will be sufÔ¨Åcient to
enable ubiquitous mobile computing. In a nutshell, the main
This is the Preprint Version.
This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no 
longer be accessible.
The following article Y. Mao, C. You, J. Zhang, K. Huang and K. B. Letaief, "A Survey on Mobile Edge Computing: The Communication Perspective," in 
IEEE Communications Surveys & Tutorials, vol. 19, no. 4, pp. 2322-2358, Fourthquarter 2017 is available at https://doi.org/10.1109/
COMST.2017.2745201.

----- Page 2 (native) -----
2
target of wireless systems, from 1G to 4G, is the pursuit of
increasingly higher wireless speeds to support the transition
from voice-centric to multimedia-centric trafÔ¨Åc. As wireless
speeds approach the wireline counterparts, the mission of 5G
is different and much more complex, namely to support the
explosive evolution of ICT and Internet. In terms of func-
tions, 5G systems will support communications, computing,
control and content delivery (4C). In terms of applications,
a wide-range of new applications and services for 5G are
emerging, such as real-time online gaming, virtual reality
(VR) and ultra-high-deÔ¨Ånition (UHD) video streaming, which
require unprecedented high access speed and low latency.
The past decade also saw the take-off of different visions of
next-generation Internet including IoT, Tactile Internet (with
millisecond latency), Internet-of-Me, and social networks. In
particular, it was predicted by Cisco that about 50 billion
IoT devices (e.g., sensors and wearable devices) will be
added to the Internet by 2020, most of which have limited
resources for computing, communication and storage, and
have to rely on Clouds or edge devices for enhancing their
capabilities [10]. It is now widely agreed that relying only
on Cloud Computing is inadequate to realize the ambitious
millisecond-scale latency for computing and communication
in 5G. Furthermore, the data exchange between end users and
remote Clouds will allow the data tsunami to saturate and
bring down the backhaul networks. This makes it essential to
supplement Cloud Computing with MEC that pushes trafÔ¨Åc,
computing and network functions towards the network edges.
This is also aligned with a key characteristic of next-generation
networks that information is increasingly generated locally
and consumed locally, which arises from the booming of
applications in IoT, social networks and content delivery [4].
The concept of MEC was Ô¨Årstly proposed by the Euro-
pean Telecommunications Standard Institute (ETSI) in 2014,
and was deÔ¨Åned as a new platform that ‚Äúprovides IT and
cloud-computing capabilities within the Radio Access Network
(RAN) in close proximity to mobile subscribers‚Äù [5]. The
original deÔ¨Ånition of MEC refers to the use of BSs for
ofÔ¨Çoading computation tasks from mobile devices. Recently,
the concept of Fog Computing has been proposed by Cisco as a
generalized form of MEC where the deÔ¨Ånition of edge devices
gets broader, ranging from smartphones to set-top boxes [11].
This led to the emergence of a new research area called
Fog Computing and Networking [4], [12], [13]. However,
the areas of Fog Computing and MEC are overlapping and
the terminologies are frequently used interchangeably. In this
paper, we focus on MEC but many technologies discussed are
also applicable to Fog Computing.
MEC is implemented based on a virtualized platform that
leverages recent advancements in network functions virtualiza-
tion (NFV), information-centric networks (ICN) and software-
deÔ¨Åned networks (SDN). SpeciÔ¨Åcally, NFV enables a single
edge device to provide computing services to multiple mobile
devices by creating multiple virtual machines (VMs) 1 for si-
multaneously performing different tasks or operating different
1The VM is a virtual computer mapped to the physical machine‚Äôs hard-
wares, providing virtual CPU, memory, hard drive, network interface, and
other devices [14].
Image
Aquisition
Image
Aquisition
Face
Detection
Face
Detection
PreÕ≤
processing
Classification
Classification
Feature
Extraction
Feature
Extraction
Database
(TrainingSamples)
DigitalImage
FaceImage
Normalized
FaceImage
Feature
Vector
Classification
Results
MECServer
Fig. 1. Main computation components in a face recognition application [17].
Video
Source
Video
Source
NumberofFeatures
Renderer
Renderer
Tracker
Tracker
Mapper
Mapper
Resolution ImageFormat
MECServer
Object
Recognizer
Object
Recognizer
Fig. 2. Main computation components in an AR application [18].
network functions [15]. On the other hand, ICN provides an
alternative end-to-end service recognition paradigm for MEC,
shifting from a host-centric to an information-centric one
for implementing context-aware computing. Last, SDN allows
MEC network administrators to manage services via function
abstraction, achieving scalable and dynamic computing [16].
A main focus of MEC research is to develop these general
network technologies so that they can be implemented at the
network edges.
There is an increasing number of emerging mobile ap-
plications that will beneÔ¨Åt from MEC, by ofÔ¨Çoading their
computation-intensive tasks to the MEC servers for cloud
execution. In the following, we will provide two examples to
illustrate the basic principles of MEC. One is the face recog-
nition application as shown in Fig. 1, which typically con-
sists of Ô¨Åve main computation components, including image
acquisition, face detection, pre-processing, feature extraction,
and classiÔ¨Åcation [17]. While the image acquisition component
needs to be executed at the mobile device for supporting the
user interface, the other components could be ofÔ¨Çoaded for
cloud processing, which contain complex computation such
as signal processing and machine learning (ML) algorithms.
Another popular stream of applications that can leverage the
rich resources at the network edges are augmented reality
(AR) applications, which are able to combine the computer-
generated data with physical reality. AR applications as shown
in Fig. 2 have Ô¨Åve critical components [18]‚Äì[20], namely,
the video source (which obtains raw video frames from the
mobile camera), a tracker (which tracks the position of the
user), a mapper (which builds a model of the environment),
an object recognizer (which identiÔ¨Åes known objects in the

----- Page 3 (native) -----
3
environment), and a renderer (which prepares the processed
frame for display). Among these components, the video source
and renderer should be executed locally, while the most
computation-intensive components, i.e., the tracker, mapper
and object recognizer, can be ofÔ¨Çoaded for cloud execution.
In this way, mobile users can enjoy various beneÔ¨Åts from
MEC such as latency reduction and energy savings, as will
be elaborated in the next subsection.
B. Mobile Edge Computing Versus Mobile Cloud Computing
As shown in Table I, there exist signiÔ¨Åcant disparities
between MEC and MCC systems in terms of computing server,
distance to end users and typical latency, etc. Compared with
MCC, MEC has the advantages of achieving lower latency,
saving energy for mobile devices, supporting context-aware
computing, and enhancing privacy and security for mobile
applications. These advantages are brieÔ¨Çy described through
some examples and applications in the following.
Low Latency: The latency for a mobile service is the
aggregation of three components: propagation, computation,
and communication latency, depending on the propagation dis-
tance, computation capacity, and data rate, respectively. First,
the information-propagation distances for MEC are typically
tens-of-meters for the cases of dense small-cell networks or
device-to-device (D2D) transmissions, and typically no longer
than 1km for general cases. In contrast, Cloud Computing
requires transmissions from end users to nodes in core net-
works or data centers with distances ranging from tens of
kilometers to that across continents. This results in much
shorter propagation delay for MEC than that for MCC. Second,
MCC requires the information to pass through several net-
works including the radio-access network, backhaul network
and Internet, where trafÔ¨Åc control, routing and other network-
management operations can contribute to excessive delay. With
the communication constrained at the network edges, MEC
is free from these issues. Last, for the computation latency,
a Cloud has a massive computation power that is several
orders of magnitude higher than that of an edge device (e.g.,
a BS). However, the Cloud has to be shared by a much larger
number of users than an edge device, reducing their gap in the
computation latency. Furthermore, a modern BS is powerful
enough for running highly sophisticated computing programs.
For instance, the edge cloud at a BS has 102-104 times higher
computation capability than the minimum requirement (e.g.,
a CPU over 3.3GHz, 8GB RAM, 70GB storage space) for
running the Call-of-Duty 13, a popular shooter game2. In
general, experiments have shown that the total latency for
MCC is in the range of 30-100ms [31]. This is unacceptable
for many latency-critical mobile applications such as real-
time online gaming, virtual sports and autonomous driving,
which may require tactile speed with latency approaching
1ms [37]. In contrast, with short propagation distances and
simple protocols, MEC has the potential of realizing tactile-
level latency for latency-critical 5G applications.
Mobile Energy Savings: Due to their compact forms,
IoT devices have limited energy storage but are expected to
2https://www.callofduty.com/
cooperate and perform sophisticated tasks such as surveillance,
crowd-sensing and health monitoring [38]. Powering the tens
of billions of IoT devices remains a key challenge for de-
signing IoT given that frequent battery recharging/replacement
is impractical if not impossible. By effectively supporting
computation ofÔ¨Çoading, MEC stands out as a promising solu-
tion for prolonging battery lives of IoT devices. SpeciÔ¨Åcally,
computation-intensive tasks can be ofÔ¨Çoaded from IoT devices
to edge devices so as to reduce their energy consumption.
SigniÔ¨Åcant energy savings by computation ofÔ¨Çoading have
been demonstrated in experiments, e.g., the completion of up
to 44-time more computation load for a multimedia application
eyeDentify [39] or the increase of battery life by 30-50% for
different AR applications [40].
Context-Awareness: Another key feature that differentiates
MEC from MCC is the ability of an MEC server for lever-
aging the proximity of edge devices to end users to track
their real-time information such as behaviors, locations, and
environments. Inference based on such information allows the
delivery of context-aware services to end users [41]‚Äì[43]. For
instance, the museum video guide, an AR application, can
predict users‚Äô interests based on their locations in the museum
to automatically deliver contents related to e.g., artworks and
antiques [44]. Another example is the CTrack system that uses
the BS Ô¨Ångerprints to track and predict the trajectories of a
large number of users for the purposes of trafÔ¨Åc monitoring,
navigation and routing, and personalized trip management
[45].
Privacy/Security Enhancement: The capability of enhanc-
ing the privacy and security of mobile applications is also
an attractive beneÔ¨Åt brought by MEC compared to MCC.
In MCC systems, the Cloud Computing platforms are the
remote public large data centers, such as the Amazon EC2
and Microsoft Azure, which are susceptible to attacks due to
their high concentration of information resources of users. In
addition, the ownership and management of users‚Äô data are
separated in MCC, which shall cause the issues of private
data leakage and loss [46]. The use of proximate edge servers
provides a promising solution to circumvent these problems.
On one hand, due to the distributed deployment, small-scale
nature, and the less concentration of valuable information,
MEC servers are much less likely to become the target of a
security attack. Second, many MEC servers could be private-
owned cloudlets, which shall ease the concern of informa-
tion leakage. Applications that require sensitive information
exchange between end users and servers would beneÔ¨Åt from
MEC. For instance, the enterprise deployment of MEC could
help avoid uploading restricted data and material to remote
data centers, as the enterprise administrator itself manages the
authorization, access control, and classiÔ¨Åes different levels of
service requests without the need of an external unit [47].
C. Paper Motivation and Outline
MEC has emerged as a key enabling technology for realiz-
ing the IoT and 5G visions [15], [48], [49]. MEC research lies
at the intersection of mobile computing and wireless commu-
nications, where the existence of many research opportunities

----- Page 4 (native) -----
4
TABLE I
COMPARISON OF MEC AND MCC SYSTEMS.
MEC
MCC
Server hardware
Small-scale data centers
Large-scale data centers (each contains
with moderate resources [5], [21]
a large number of highly-capable servers) [22], [23]
Server location
Co-locate with wireless gateways,
Installed at dedicated buildings,
WiFi routers, and LTE BSs [5]
with size of several football Ô¨Åelds [24], [25]
Deployment
Densely deployed by telecom operators,
Deployed by IT companies, e.g., Google
MEC vendors, enterprises, and
and Amazon, at a few locations
home users. Require lightweight
over the world. Require sophisticated
conÔ¨Åguration and planning [5]
conÔ¨Åguration and planning [22]
Distance to end users
Small
Large
(tens to hundreds of meters) [15]
(may across the country border) [26]
Backhaul usage
Infrequent use
Frequent use
Alleviate congestion [27]
Likely to cause congestion [27]
System management
Hierarchical control
Centralized control [28]
(centralized/distributed) [28]
Supportable latency
Less than tens of milliseconds [15], [29]
Larger than 100 milliseconds [30], [31]
Applications
Latency-critical and computation-intensive
Latency-tolerant and computation-intensive
applications, e.g., AR, automatic driving,
applications, e.g., online social networking,
and interactive online gaming [5], [32].
and mobile commerce/health/learning [33]‚Äì[36].
has resulted in a highly active area. In recent years, researchers
from both academia and industry have investigated a wide-
range of issues related to MEC, including system and network
modeling, optimal control, multiuser resource allocation, im-
plementation and standardization. Subsequently, several survey
articles have been published to provide overviews of the
MEC area with different focuses, including system models,
architectures, enabling techniques, applications, edge caching,
edge computation ofÔ¨Çoading, and connections with IoT and 5G
[27], [28], [50]‚Äì[56]. Their themes are summarized as follows.
An overview of MEC platforms is presented in [50] where
different existing MEC frameworks, architectures, and their
application scenarios, including FemtoClouds, REPLISM, and
ME-VOLTE, are discussed. The survey of [51] focuses on
the enabling techniques in MEC such as cloud computing,
VM, NFV, SDN that allow the Ô¨Çexible control and multi-
tenancy support. In [52], the authors categorize diverse MEC
applications, service models, deployment scenarios, as well
as network architectures. The survey in [53] presents a tax-
onomy for MEC applications and identiÔ¨Åes potential direc-
tions for research and development, such as content scaling,
local connectivity, augmentation, and data aggregation and
analytics. In [28], emerging techniques of edge computing,
caching, and communications (3C) in MEC are surveyed,
showing the convergence of 3C. Besides, key enablers of MEC
such as cloud technology, SDN/NFV, and smart devices are
also discussed. The survey in [54] focuses on three critical
design problems in computation ofÔ¨Çoading for MEC, namely,
the ofÔ¨Çoading decision, computation resource allocation, and
mobility management. In addition, the role of MEC in IoT,
i.e., creating new IoT services, is highlighted in [55] through
MEC deployment examples with reference to IoT use cases.
Several attractive use scenarios of MEC in 5G networks
are also introduced in [27], ranging from mobile-edge or-
chestration, collaborative caching and processing, and multi-
layer interference cancellation. Furthermore, potential business
opportunities related to MEC are discussed in [56] from the
perspectives of application developers, service providers, and
network equipment vendors. In view of prior work, there
still lacks a systematic survey article providing comprehensive
and concrete discussions on speciÔ¨Åc MEC research results
with a deep integration of mobile computing and wireless
communications, which motivates the current work. This paper
differs from existing surveys on MEC in the following aspects.
First, the current survey summarizes existing models of com-
puting and communications in MEC to facilitate theoretical
analysis and provide a quick reference for both researchers
and practitioners. Next, we present a comprehensive literature
review on joint radio-and-computational resource allocation
for MEC, which is the central theme of the current paper. The
literature review in our paper shall be a valuable addition to the
existing survey literature on MEC, which can beneÔ¨Åt readers
from the research community in building up a systematic
understanding of the state-of-the-art resource management
techniques for MEC systems. Furthermore, we identify and
discuss several research challenges and opportunities in MEC
from the communication perspective, for which potential so-
lutions are elaborated. In addition, to bridge the gap between
theoretical research and real implementation of MEC, recent
standardization efforts and use scenarios of MEC will then be
introduced.
This paper is organized as follows. In Section II, we summa-
rize the basic MEC models, comprising models of computation
tasks, communications, mobile devices and MEC servers,
based on which the models of MEC latency and energy con-
sumption are developed. Next, a comprehensive review is pre-
sented in Section III, focusing on the research of joint radio-
and-computational resource management for different types
of MEC systems, including single-user, multiuser systems as
well as multi-server MEC. Subsequently, a set of key research
issues and future directions are discussed in Section III-D3
including 1) deployment of MEC systems, 2) cache-enabled
MEC, 3) mobility management for MEC, 4) green MEC,
and 5) security-and-privacy issues in MEC. SpeciÔ¨Åcally, we
analyze the design challenges for each research problem
and provide several potential research approaches. Last, the
MEC standardization efforts and applications are reviewed and
discussed in Section V, followed by concluding remarks in

----- Page 5 (native) -----
5
TABLE II
SUMMARY OF IMPORTANT ACRONYMS.
Acronym
DeÔ¨Ånition
Acronym
DeÔ¨Ånition
AF
application function
MEC
mobile edge computing
AR
augmented reality
ML
machine learning
AP
access point
mMTC
massive machine type communication
BS
base station
NEF
network exposure function
CAPEX
capital expenditure
NFC
near-Ô¨Åled communications
C-RAN
cloud radio access network
NFV
network functions virtualization
CSI
channel-state information
OFDMA
orthogonal frequency division multiple access
DAG
directed acyclic graph
PCF
policy control function
DCN
data-center network
PMR
peak-to-mean ratio
DNS
domain name system
PoC
proof of concept
DP
dynamic programming
QoS
quality of service
DPP
determinantal point process
RAM
random access memory
DVFS
dynamic frequency and voltage scaling
RAN
radio access network
D2D
device-to-device
RFID
radio frequency identiÔ¨Åcation
EH
energy harvesting
RNIS
radio network information services
eMBB
enhanced mobile broadband
SDN
software-deÔ¨Åned networks
ESI
energy side information
SINR
signal-to-interference-plus-noise ratio
ETSI
European Telecommunications Standard Institute
TOF
trafÔ¨Åc ofÔ¨Çoading function
GLB
geographical load balancing
UE
user equipment
Het-MEC
heterogeneous MEC
UHD
ultra-high-deÔ¨Ånition
HetNets
heterogeneous networks
UPF
user plane function
HPPP
homogeneous Poisson point process
UPS
uninterrupted power supply
IaaS
Infrastructure as a Service
URLLC
ultra-reliable and low latency communication
ICN
information-centric networks
VM
virtual machine
ISG
industry speciÔ¨Åcation group
VR
virtual reality
ISI
inter-symbol interference
V2X
vehicular-to-everything
IoT
Internet of Things
WPT
wireless power transfer
KKT
Karush-Kuhn-Tucker
3C
computing, caching, and communications
LP
linear programming
3GPP
3rd Generation Partnership Project
LTE
long-term evolution
4C
communications, computing, control and content delivery
MCC
mobile cloud computing
5GPPP
European 5G infrastructure Public Private Partnership
MDP
Markov decision process
5QI
5G QoS Indicator
Section VI. We summarze the deÔ¨Ånitions of the acronyms that
will be frequently use in this paper in TABLE II for ease of
reference.
II. MEC COMPUTATION AND COMMUNICATION MODELS
In this section, system models are introduced for the key
computation/communication components of the typical MEC
system. The models provide mechanisms for abstracting var-
ious functions and operations into optimization problems and
facilitating theoretical analysis as discussed in the following
sections.
For the MEC system shown in Fig. 3, the key components
include mobile devices (a.k.a. end users, clients, service sub-
scribers) and MEC servers. The MEC servers are typically
small-scale data centers deployed by the cloud and telecom
operators in close proximity with end users and can be co-
located with wireless APs. Through a gateway, the servers
are connected to the data centers via Internet. Mobile devices
and servers are separated by the air interface where reliable
wireless links can be established using advanced wireless
communication and networking technologies. In the following
subsections, we will introduce the models for different compo-
nents of MEC systems, including models for the computation
tasks, wireless communication channels and networks, as well
as the computation latency and energy consumption models of
mobile devices and MEC servers.
A. Computation Task Models
There are various parameters that play critical roles in
modeling the computation tasks, including latency, bandwidth
utilization, context awareness, generality, and scalability [57].
Though it is highly sophisticated to develop accurate models
for tasks, there exist simple ones that are reasonable and allow
mathematical tractability. In this subsection, we introduce two
computation-task models popularly used in existing literature
on MCC and MEC, corresponding to binary and partial
computation ofÔ¨Çoading, respectively.
1) Task Model for Binary OfÔ¨Çoading: A highly integrated
or relatively simple task cannot be partitioned and has to be
executed as a whole either locally at the mobile device or
ofÔ¨Çoaded to the MEC server, called binary ofÔ¨Çoading. Such a
task can be represented by a three-Ô¨Åeld notation A (L, œÑd, X).
This commonly-used notation contains the information of
the task input-data size L (in bits), the completion deadline
œÑd (in second), and the computation workload/intensity X
(in CPU cycles per bit). These parameters are related to
the nature of the applications and can be estimated through
task proÔ¨Ålers [58], [59]. The use of these three parameters
not only captures essential properties of mobile applications
such as the computation and communication demands, but
also facilitates simple evaluation of the execution latency and
energy consumption performance (which will be analyzed in
Section II-C).
The task A (L, œÑd, X) is required to be completed before

----- Page 6 (native) -----
6
DP
DP
DP
DP
Connectedvehicles
Surveillancenetworks
Smartdevicesapplications
Healthmonitoring
Gaming
ARApps.
3DModeling
Socialnetworking
MECServer
0RELOHFRUHQHWZRUN
*DWHZD\
,QWHUQHW
EDFNERQH
'DWDFHQWHU
$63V
&'1V
Fig. 3. Architecture of the MEC systems.
a hard deadline œÑd. This model can also be generalized to
handle the soft deadline requirement which allows a small
portion of tasks to be completed after œÑd [60]. In this case,
the number of CPU cycles needed to execute 1-bit of task
input data is modeled as a random variable X. SpeciÔ¨Åcally,
deÔ¨Åne x0 as a positive integer such that Pr(X > x0) ‚â§œÅ
where œÅ is a small real number: 0 < œÅ ‚â™1. It follows that
Pr(LX > WœÅ) ‚â§œÅ where WœÅ = Lx0. Then given the L-bit
task-input data, WœÅ upper bounds the number of required CPU
cycles almost surely.
2) Task
Models
for
Partial
OfÔ¨Çoading:
In practice,
many mobile applications are composed of multiple proce-
dures/components (e.g., the computation components in an
AR application as shown in Fig. 2), making it possible
to implement Ô¨Åne-grained (partial) computation ofÔ¨Çoading.
SpeciÔ¨Åcally, the program can be partitioned into two parts with
one executed at the mobile device and the other ofÔ¨Çoaded for
edge execution.
The simplest task model for partial ofÔ¨Çoading is the data-
partition model, where the task-input bits are bit-wise indepen-
dent and can be arbitrarily divided into different groups and
executed by different entities in MEC systems, e.g., parallel
execution at the mobiles and MEC server.
Nevertheless,
the
dependency
among
different
proce-
dures/components in many applications cannot be ignored
as it signiÔ¨Åcantly affects the procedure of execution and
computation ofÔ¨Çoading due to the following reasons:
‚Ä¢ First, the execution order of functions or routines cannot
be arbitrarily chosen because the outputs of some com-
ponents are the inputs of others.
‚Ä¢ Second, due to either software or hardware constraints,
some functions or routines can be ofÔ¨Çoaded to the server
for remote execution, while the ones can only be executed
locally such as the image display function.
This calls for task models that are more sophisticated
than the mentioned data-partition model that can capture
the inter-dependency among different computation functions
and routines in an application. One such model is called the
task-call graph. The graph is typically a directed acyclic
graph (DAG), which is a Ô¨Ånite directed graph with no
directed cycles. We shall denote it as G (V, E), where the set
of vertices V represents different procedures in the application
and the set of edges E speciÔ¨Åes their call dependencies. There
are three typical dependency models of sub-tasks (i.e., task
components such as functions or routines), namely sequential,
parallel, and general dependency [61], [62], as illustrated
in Fig. 4. For the mobile initiated applications, the Ô¨Årst and
the last steps, e.g., collecting the I/O data and displaying
the computation results on the screen, are normally required
to be executed locally. Thus, node 1 and node N in Fig.
4(a)-4(c) are components that must be executed locally.
Besides, the required computation workloads and resources
of each procedure, e.g., the number of required CPU cycles
and the amount of needed memory, can also be speciÔ¨Åed
in the vertices of the task-call graph, while the amount of
input/output data of each procedure can be characterized by
imposing weights on the edges.

----- Page 7 (native) -----
7



Õº
N
N
¬´
w
w
wNN
F
F
F
FN
FN
(a) Sequential dependency



Õº
N
N
¬´

F
F
FN
F
F
FN
w
wN
(b) Parallel dependency



Õº
N
N
¬´



Õº
N

¬´
F
F
F
F
F
F
FN
F
FN
FN
w
w
wNN
wNN-1
w
w
w
w
(c) General dependency
Fig. 4. Typical topologies of the task-call graphs.
B. Communication Models
In the literature of MCC, communication channels between
the mobile devices and cloud servers are typically abstracted as
bit pipes with either constant rates or random rates with given
distributions. Such coarse models are adopted for tractability
and may be reasonable for the design of MCC systems
where the focuses are to tackle the latency in the core
networks and management of large-scale cloud but not the
wireless-communication latency. The scenario is different for
MEC systems. Given small-scale edge clouds and targeting
latency-critical applications, reducing communication latency
by designing a highly efÔ¨Åcient air interface is the main
design focus. Consequently, the mentioned bit-pipe models
are insufÔ¨Åcient as they overlook some fundamental properties
of wireless propagation and are too simpliÔ¨Åed to allow the
implementation of advanced communication techniques. To be
speciÔ¨Åc, wireless channels differ from the wired counterparts
in the following key aspects [63]:
1) Due to atmospheric ducting, reÔ¨Çection and refraction
from scattering objects in the environment (e.g., build-
ings, walls and trees), there exists the well-known multi-
path fading in wireless channels, making the channels
highly time-varying and can cause severe inter-symbol
inference (ISI). Thus, effective ISI suppression tech-
niques, such as equalization and spread spectrum, are
needed for reliable transmissions.
2) The broadcast nature of wireless transmissions results
in a signal being interfered by other signals occupy-
ing the same spectrum, which reduces their respective
receive signal-to-interference-plus-noise ratios (SINRs)
and thereby results in the probabilities of error in detec-
tion. To cope with the performance degradation, inter-
ference management becomes one of the most important
design issues for wireless communication systems and
has attracted extensive research efforts [64]‚Äì[66].
3) Spectrum shortage has been the main foe for very
high-rate radio access, motivating extensive research on
exploiting new spectrum resources [67], [68], designing
novel transceiver architectures [69]‚Äì[71] and network
paradigms [72], [73] to improve the spectrum efÔ¨Åciency,
as well as developing spectrum sharing and aggregation
techniques to facilitate efÔ¨Åcient use of fragmented and
underutilized spectrum resources [74]‚Äì[76].
The random variations of wireless channels in time, fre-
quency and space make it important for designing efÔ¨Åcient
MEC systems to seamlessly integrate control of computation
ofÔ¨Çoading and radio resource management. For instance, when
the wireless channel is in deep fade, the reduction on execution
latency by remote execution may not be sufÔ¨Åcient to compen-
sate for the increase of transmission latency due to the steep
drop in transmission-data rates. For such cases, it is desirable
to defer ofÔ¨Çoading till the channel gain is favorable or switch
to an alternative frequency/spatial channel with a better quality
for ofÔ¨Çoading. Furthermore, increasing transmission power can
increase the data rate, but also lead to a larger transmission
energy consumption. The above considerations necessitate the
joint design of ofÔ¨Çoading and wireless transmissions, which
should be adaptive to the time-varying channels based on the
accurate channel-state information (CSI).
In MEC systems, communications are typically between
APs and mobile devices with the possibility of direct D2D
communications. The MEC servers are small-scale data cen-
ters deployed by the Cloud Computing/telecom operators,
which can be co-located with the wireless APs, e.g., the
public WiFi routers and BSs, as so to reduce the capital
expenditure (CAPEX) (e.g., site rental). As shown in Fig. 3,
the wireless APs not only provide the wireless interface for
the MEC servers, but also enable the access to the remote
data center through backhaul links, which could help the MEC
server to further ofÔ¨Çoad some computation tasks to other MEC
servers or to large-scale cloud data centers. For the mobile
devices that cannot communicate with MEC servers directly
due to insufÔ¨Åcient wireless interfaces, D2D communications
with neighboring devices provide the opportunity to forward
the computation tasks to MEC servers. Furthermore, D2D
communications also enable the peer-to-peer cooperation on
resource sharing and computation-load balancing within a
cluster of mobile devices.
Presently, there exist different types of commercialized
technologies for mobile communications, including the near-
Ô¨Åled communications (NFC), radio frequency identiÔ¨Åcation
(RFID), Bluetooth, WiFi, and cellular technologies such as the
long-term evolution (LTE). Besides, the 5G network, which
will be realized by the development of LTE in combination
with new radio-access technologies, is currently being stan-
dardized and will be put into commercial use as early as
2020 [77]. These technologies can support wireless ofÔ¨Çoading
from mobiles to APs or peer-to-peer mobile cooperation for

----- Page 8 (native) -----
8
TABLE III
CHARACTERISTICS OF TYPICAL WIRELESS COMMUNICATION TECHNOLOGIES.
NFC
RFID
Bluetooth
WiFi
LTE
5G
Max. Coverage
10cm
3m
100m
100m
up to 5km
Excellent coverage
Operation Freq.
LF: 120-134kHz
13.56MHz
HF: 13.56MHz
2.4GHz
2.4GHz, 5GHz
TDD: 1.85-3.8GHz
6-100GHz
UHF: 850-960MHz
FDD: 0.7-2.6GHz
Data Rate
Indoor/dense outdoor:
106, 212,
Low (LF) to
135Mbps
DL: 300Mbps
up to 10Gbps
414kbps
high (UHF)
22Mbps
(IEEE 802.11n)
UL: 75Mbps
Urban/suburban:
> hundreds of Mbps
varying data rates and transmission ranges. We list the key
characteristics of typical wireless communication technologies
in Table III, which differ signiÔ¨Åcantly in terms of the operation
frequency, maximum coverage range, and data rate. For NFC,
the coverage range and data rate are very low and thus
the technology is suitable for applications that require little
information exchange, e.g., e-payment and physical access
authentication. RFID is similar to NFC, but only allows one-
way communications. Bluetooth is a more powerful tech-
nique to enable short-range D2D communications in MEC
systems. For long-range communications between mobiles and
MEC servers, WiFi and LTE (or 5G in the future) are two
primary technologies enabling the access to MEC systems,
which can be adaptively switched depending on their link
reliability. For the deployment of wireless technologies in
MEC systems, the communication and networking protocols
need to be redesigned to integrate both the computing and
communication infrastructures, and effectively improve the
computation efÔ¨Åciency that is more sophisticated than the data
transmission.
C. Computation Models of Mobile Devices
In this subsection, we introduce the computation models of
mobile devices and discuss methodologies of evaluating the
computation performance.
The CPU of a mobile device is the primary engine for
local computation. The CPU performance is controlled by
the CPU-cycle frequency fm (also known as the CPU clock
speed). The state-of-the-art mobile CPU architecture adopts
the advanced dynamic frequency and voltage scaling (DVFS)
technique, which allows stepping-up or -down of the CPU-
cycle frequency (or voltage), resulting in growing and reducing
energy consumption, respectively. In practice, the value of
fm is bounded by a maximum value, f max
CPU, which reÔ¨Çects
the limitation of the mobile‚Äôs computation capability. Based
on the computation task model introduced in Section II-A,
the execution latency for task A (L, œÑ, X) can be calculated
accordingly to
tm = LX
fm
,
(1)
which indicates that a high CPU clock speed is desirable in
order to reduce the execution latency, at the cost of higher
CPU energy consumption.
As the mobile devices are energy-constrained, the energy
consumption for local computation is another critical mea-
surement for the mobile computing efÔ¨Åciency. According to
the circuit theory [78]‚Äì[81], the CPU power consumption can
be divided into several factors including the dynamic, short-
circuit, and leakage power consumption3, where the dynamic
power consumption dominates the others. In particular, it
is shown in [80] that the dynamic power consumption is
proportional to the product of V 2
cirfm where Vcir is the circuit
supplied voltage. It is further noticed in [78], [81] that, the
clock frequency of the CPU chip is approximately linear
proportional to the voltage supply when operating at the low
voltage limits. Thus, the energy consumption of a CPU cycle
is given by Œ∫f 2
m, where Œ∫ is a constant related to the hardware
architecture. For the computation task A (L, œÑ, X) with CPU
clock speed fm, the energy consumption can be derived:
Em = Œ∫LXf 2
m.
(2)
One can observe from (1) and (2) that the mobile device may
not be able to complete a computation-intensive task within
the required deadline, or else the energy consumption incurred
by mobile execution is so high that the onboard battery will be
depleted quickly. In such cases, ofÔ¨Çoading the task execution
process to an MEC server is desirable.
Besides CPUs, other hardware components in the mobile
devices, e.g., the random access memory (RAM) and Ô¨Çash
memory, also contribute to the computation latency and
energy consumption [82], while detailed discussions are
beyond the scope of this survey.
D. Computation Models of MEC Servers
In this subsection, we introduce the computation models
of the MEC servers. Similar as the mobile devices, the
computation latency and energy consumption are of particular
interests.
The server-computation latency is negligible compared with
communication or local-computation latency in MEC systems
where the computation loads for servers are much lower than
their computation capacities [81], [83]. This model can be also
relevant for multiuser MEC systems with resource-constrained
3The dynamic power consumption comes from the toggling activities of the
logic gates inside a CPU, which shall charge/discharge the capacitors inside
the logic gates. When a logic gate toggles, some of its transistors may change
states, and thus, there might be a short period of time when some transistors
are conducting simultaneously. In this case, the direct path between the source
and ground will result in some short-circuit power loss. The leakage power
dissipation is due to the Ô¨Çowing current between doped parts of the transistors
[80], available on https://en.wikipedia.org/wiki/CPU power dissipation.

----- Page 9 (native) -----
9
servers if the servers‚Äô computation loads are regulated by mul-
tiuser resource management under latency and computation-
capacity constraints [84].
On the other hand, as edge servers have relatively limited
computation resources, it is necessary to consider the non-
negligible server execution time in the general design of
MEC systems, yielding the computation model for the severs
discussed in the remainder of this subsection. Two possible
models are considered in the literature, corresponding to the
deterministic and stochastic server-computation latency. The
deterministic model is proposed to consider the exact server-
computation latency for latency-sensitive applications, which
is implemented using techniques such as VMs and DVFS.
SpeciÔ¨Åcally, assume the MEC server allocates different VMs
for different mobile devices, allowing independent computa-
tion [85]. Let fs,k denote the allocated servers‚Äô CPU-cycle
number for mobile device k. Similar to Section II-C, it
follows that the server execution time denoted by ts,k can
be calculated as ts,k =
wk
fs,k
, where wk is the number of
required CPU cycles for processing the ofÔ¨Çoaded computation
workload. This model has been widely used for designing
computation-resource allocation policies [86]‚Äì[88]. A similar
model was proposed in [84], where the MEC server is assumed
to perform load balancing for the total ofÔ¨Çoaded computation
workloads. In other words, the CPU cycles at the MEC server
are proportionally allocated to each mobile device such that
they experience the same execution latency. Furthermore, in
addition to the CPU processing time, the server scheduling
queuing delay should be accounted for MEC servers with
relatively small computation capacities, where parallel com-
puting via virtualization techniques is not feasible and thus
it needs to process the computation workloads sequentially.
Without loss of generality, denote k as the processing order for
a mobile device and name it as mobile k. Thus, the total server-
computation latency including the queuing delay for device k
denoted by Ts,k can be given as
Ts,k =
X
i‚â§k
ts,i.
(3)
For
latency-tolerant
applications,
the
average
server-
computation time can be derived based on stochastic models.
For example, in [89], the task arrivals and service time
are modeled by the Poisson and exponential processes,
respectively. Thus, the average server-computation time can
be derived using techniques from queuing theory. Last,
for all above models, as investigated in [1], multiple VMs
sharing the same physical machine will introduce the I/O
interference among different VMs. It results in the longer
computation latency for each VM denoted by T
‚Ä≤
s,k, which
can be modeled by T
‚Ä≤
s,k = Ts,k(1 + œµ)n where œµ is the
performance degradation factor as the percentage increasing
of the latency [90].
The energy consumption of an MEC server is jointly
determined by the usage of the CPU, storage, memory, and
network interfaces. Since the CPU contribution is dominant
among these factors, it is the main focus in the literature. Two
tractable models are widely used for the energy consumption
of MEC servers. One model is based on the DVFS technique
described as follows. Consider an MEC server that handles K
computation tasks and the k-th task is allocated with wk CPU
cycles with CPU-cycle frequency fs,k. Hence, the total energy
consumed by the CPU at the MEC server, denoted by Es, can
be expressed as
Es =
K
X
k=1
Œ∫wkf 2
s,k,
(4)
which is similar to that for the mobile devices. The other model
is based on an observation in recent works [91]‚Äì[93] that the
server-energy consumption is linear to the CPU utilization
ratio which depends on the computation load. Moreover, even
for an idle server, it still, on average, consumes up to 70%
of the energy consumption for the case with the full CPU
speed. Thus, the energy consumption at the MEC server can
be calculated according to
Es = Œ±Emax + (1 ‚àíŒ±)Emaxu,
(5)
where Emax is the energy consumption for a fully-utilized
server, Œ± is the fraction of the idle energy consumption (e.g.,
70%) and u denotes the CPU utilization ratio. This model
suggests that energy-efÔ¨Åcient MEC should allow servers to be
switched into the sleep mode in the case of light load and
consolidation of computation loads into fewer active servers.
E. Summary and Insights
The MEC computation and communication models are
summarized in Fig. 5, laying the foundation for the analysis of
MEC resource management in the next section. These models
shed several useful insights on the ofÔ¨Çoading design, listed as
follows.
‚Ä¢ The effective design of MEC should leverage and inte-
grate advanced techniques from both areas of wireless
communications and mobile computing.
‚Ä¢ It is vital to choose suitable computation task models
for different MEC applications. For example, the soft-
deadline task model can be applied for social network-
ing applications but is not suitable for AR applications
due to the stringent computation latency requirements.
Moreover, for a speciÔ¨Åc application, the task model also
depends on the ofÔ¨Çoading scenario, e.g., the data-partition
model can be used when the input-data is ofÔ¨Çoaded, and
the task-call graph should be considered when each task
component can be ofÔ¨Çoaded as a whole.
‚Ä¢ The wireless channel condition signiÔ¨Åcantly affects the
amount of energy consumption for computation ofÔ¨Çoad-
ing. MEC has the potential to reduce the transmission
energy consumption due to short distances between users
and MEC servers. Advanced wireless communication
techniques, such as interference cancelation and adaptive
power control, can further reduce the ofÔ¨Çoading energy
consumption.
‚Ä¢ Dynamic CPU-cycle frequency control is the key tech-
nique for controlling the computation latency and en-
ergy consumption for both mobile devices and MEC
servers. SpeciÔ¨Åcally, increasing the CPU-cycle frequency

----- Page 10 (native) -----
10
Fig. 5. Summary of MEC models.
can reduce the computing time but contributes to higher
energy consumption. The effective CPU-cycle frequency
control should approach the optimal tradeoff between
computation latency and energy consumption.
‚Ä¢ Apart from the task-execution latency, the computation
scheduling delay is non-negligible if the MEC server has
a relatively small computation capacity or heavy compu-
tation loads are ofÔ¨Çoaded to the server. Load-balancing
and intelligent scheduling policies can be designed to
reduce the total computation latency.
III. RESOURCE MANAGEMENT IN MEC SYSTEMS
The joint radio-and-computational resource management
plays a pivotal role in realizing energy-efÔ¨Åcient and low-
latency MEC. The implementation of relevant techniques is
facilitated by the network architecture where MEC servers
and wireless APs (e.g., BSs and WiFi routers) are co-located.
In this section, we provide a comprehensive overview of
the literature on resource management for MEC systems
summarized in Fig. 6. Our discussion starts from the simple
single-user systems comprising a single mobile device and a
single MEC server, allowing the exposition of the key design
considerations and basic design methodologies. Subsequently,
more complex multiuser MEC systems are considered where
multiple ofÔ¨Çoading users compete for the use of both the radio
and server-computation resources and have been coordinated.
Last, we extend the discussion to MEC systems with het-
erogeneous servers which not only provide the freedom of
server selection but also allow the cooperation among servers.
Such network-level operations can signiÔ¨Åcantly enhance the
performance of MEC systems.
A. Single-User MEC Systems
This subsection focuses on the simple single-user MEC sys-
tems and reviews a set of recent research efforts for this case.
The discussion is divided according to three popularly-used
task models, namely, deterministic task model with binary
ofÔ¨Çoading, deterministic task model with partial ofÔ¨Çoading,
and stochastic task model.
1) Deterministic Task Model with Binary OfÔ¨Çoading:
Consider the mentioned single-user MEC system where the
binary ofÔ¨Çoading decision is on whether a particular task
should be ofÔ¨Çoaded for edge execution or local computation.
The investigations for the optimal ofÔ¨Çoading policies can be

----- Page 11 (native) -----
11
Resource Management 
in  MEC Systems
Multiuser MEC Systems
Single-User MEC 
Systems 
  1. Deterministic Task Model with Binary OfÔ¨Çoading
  2. Deterministic Task Model with Partial OfÔ¨Çoading
  3. Stochastic Task Model
  1. Joint Radio-and-Computational Resource Allocation
  2. MEC Server Scheduling
  3. Multiuser Cooperative Edge Computing
MEC Systems with 
Heterogeneous Servers 
  1. Server Selection
  2. Server Cooperation
  3. Computation Migration
Fig. 6. ClassiÔ¨Åcation of resource management techniques for MEC.
dated back to those for conventional Cloud Computing sys-
tems, where the communication links were typically assumed
to have a Ô¨Åxed rate B. In [94] and [95], general guidelines
are developed for determining the ofÔ¨Çoading decision for the
purposes of minimizing the mobile-energy consumption and
computation latency. Denote w as the amount of computation
(in CPU cycles) for a task, fm as the CPU speed of the mobile
device, d as the input data size, and fs as the CPU speed at the
cloud server. OfÔ¨Çoading the computation to the cloud server
can improve the latency performance only when
w
fm
> d
B + w
fs
,
(6)
which holds for applications that require heavy computation
and have small amount of data input, or when the cloud server
is fast, and the transmission rate is sufÔ¨Åciently high. Moreover,
let pm represent the CPU power consumption at the mobile
device, and pt as the transmission power, pi as the power
consumption at the device when the task is running at the
server. OfÔ¨Çoading the task could help save mobile energy when
pm √ó w
fm
> pt √ó d
B + pi √ó w
fs
(7)
holds, i.e., applications with heavy computation and light
communication should be ofÔ¨Çoaded.
Nevertheless, the data rates for wireless communications are
not constant and change with the time-varying channel gains
as well as depend on the transmission power. This calls for
the design of control policies for power adaptation and data
scheduling to streamline the ofÔ¨Çoading process. In addition, as
the CPU power consumption increases super-linearly with the
CPU-cycle frequency, the computation energy consumption for
mobile execution can be minimized using DVFS techniques.
These issues led to the active Ô¨Åeld of adaptive MEC as
summarized below.
In [96], the problem of transmission-energy minimization
under a computation-deadline constraint was formulated with
the optimization variable being the input-data transmission
time, where the famous Shannon-Hartley formula gives the
power-rate function. The optimization problem is convex and
can be solved in closed form. In particular, task ofÔ¨Çoading
is desirable when the channel power gain is greater than a
threshold and the server CPU is fast enough, which reveals
the effects of wireless channels on the ofÔ¨Çoading decision.
A further study was conducted by Zhang et al. in [81] to
minimize the energy consumption for executing a task with
a soft real-time requirement, targeting e.g., multimedia appli-
cations, which requires the task to be completed within the
deadline with a given probability œÅ. The ofÔ¨Çoading decision
was determined by the computation mode (either ofÔ¨Çoading
or local computing) that incurs less energy consumption. On
one hand, the energy consumption for local execution was op-
timized using the DVFS technique, which was formulated as a
convex optimization problem with the objective function being
the expected energy consumption of the WœÅ CPU cycles and
a time duration constraint for these CPU cycles. The optimal
CPU-cycle frequencies over the computation duration were
derived in closed form by solving the Karush-Kuhn-Tucker
(KKT) conditions, suggesting that the processor should speed
up as the number of completed CPU cycles increases. On the
other hand, the expected energy consumption for task ofÔ¨Çoad-
ing was minimized via data transmission scheduling. Under the
Gilbert-Elliott channel model, the optimal data transmission
scheduling was obtained through dynamic programming (DP)
techniques, and the scaling law of the minimum expected
energy consumption with respect to the execution deadline was
also derived. This framework was further developed in [83]
where both the local computing and ofÔ¨Çoading are powered
by wireless energy transfer. SpeciÔ¨Åcally, the optimal CPU-
cycle frequencies for local computing and time division for
ofÔ¨Çoading should be adaptive to the transferred power.
2) Deterministic Task Model with Partial OfÔ¨Çoading: The
running of a relatively sophisticated mobile application can be
decomposed into a set of smaller sub-tasks. Inspired by recent
advancements of parallel computing, partial ofÔ¨Çoading (also
known as program partitioning) schemes were proposed to
further optimize MEC performance in [61], [62], [97]‚Äì[102].
In [97], full granularity in program partitioning was con-

----- Page 12 (native) -----
12
sidered where the task-input data can be arbitrarily divided
for local and remote executions. Joint optimization of the
ofÔ¨Çoading ratio, transmission power and CPU-cycle frequency
was performed to minimize the mobile-energy consumption
(or latency) subject to a latency (or energy consumption)
constraint. Both the energy and latency minimization problems
are non-convex in contrast to the ones for binary-ofÔ¨Çoading.
The former problem can be solved optimally with a variable-
substitution technique while a sub-optimal algorithm was
proposed for the latter one in [97].
In [61], [62], [98]‚Äì[102], applications were modeled by
task-call graphs discussed earlier that specify the dependency
among different sub-tasks, and the code partitioning schemes
designed to dynamically generate the optimal set of tasks for
ofÔ¨Çoading. In [61], by leveraging the concept of load balancing
between the mobile device and the server, a heuristic program-
partitioning algorithm was developed to minimize the execu-
tion latency. Kao et al. investigated the latency minimization
problem with a prescribed resource utilization constraint in
[98], and proposed a polynomial-time approximate solution
with guaranteed performance. To maximize the energy savings
achieved by computation ofÔ¨Çoading, the scheduling and cloud
ofÔ¨Çoading decisions were jointly optimized using an integer
programming approach in [62]. In [99], considering the wire-
less channel models including the block fading channel, in-
dependent and identical distributed (i.i.d.) stochastic channel,
and the Markovian stochastic channel, the expected energy
consumption minimization problem with a completion time
constraint was found to be a stochastic shortest-path problem,
and the one-climb policies (i.e., the execution only migrates
once from the mobile device to the server) were shown to be
optimal. In addition, the program-partitioning schemes were
also optimized together with the physical layer parameters,
such as the transmission and reception power, constellation
size, as well as the data allocation for different radio interfaces
[100]‚Äì[102].
3) Stochastic Task Model: Resource management policies
have been also developed for MEC systems with stochastic
task models characterized by random task arrivals, where the
arrived but not yet executed tasks join the queues in buffers
[103]‚Äì[108]. For such systems, the long-term performance,
e.g., the long-term average energy consumption and execution
latency, are more relevant compared with those of determin-
istic task arrivals, and the temporal correlation of the optimal
system operations makes the design more challenging. As a
result, the design of MEC systems with random task arrivals
is an area less explored compared with the simpler cases
with deterministic task models. In [103], in order to minimize
the mobile-energy consumption while keeping the proportion
of executions violating the deadline requirement below a
threshold, a dynamic ofÔ¨Çoading algorithm was proposed to
determine the ofÔ¨Çoaded software components from an applica-
tion running at a mobile user based on Lyapunov optimization
techniques, where 3G and WiFi networks are accessible to the
device but their rates vary at different locations. Assuming that
concurrent local and edge executions are feasible, the latency-
optimal task scheduling policies were designed in [104] based
on the theory of Markov decision process (MDP), which
controls the states of the local processing and transmission
units and the task buffer queue length based on the channel
state. It was shown that the optimal task-scheduling policy
signiÔ¨Åcantly outperforms the greedy scheduling policy (i.e.,
tasks are scheduled to the local CPU/transmission unit when-
ever they are idle). To jointly optimize the computation latency
and energy consumption, the problem of minimizing the long-
term average execution cost was considered in [102] and [106],
where the former only optimized the ofÔ¨Çoading data size
based on the MDP theory while the latter jointly controlled
the local CPU frequency, modulation scheme as well as data
rates under a semi-MDP framework. In [107], the energy-
latency tradeoff in MEC systems with heterogeneous types of
applications was investigated, including the non-ofÔ¨Çoadable
workload, cloud-ofÔ¨Çoadable workload and network trafÔ¨Åc.
A Lyapunov optimization-based algorithm was proposed to
jointly decide the ofÔ¨Çoading policy, task allocation, CPU clock
speed, and selected network interface. It was also shown
that the energy consumption decreases inversely proportional
to V while the latency increases linearly with V , where V
is a control parameter in the proposed algorithm. Similar
investigation was conducted for MEC systems with a multi-
core mobile device in [108].
4) Summary and Insight:
The comparison of resource
management schemes for single-user MEC systems is shown
in Table IV. This series of work yields a number of useful
insights on controlling computation ofÔ¨Çoading as summarized
below.
‚Ä¢ Consider binary ofÔ¨Çoading. For energy savings, com-
putation ofÔ¨Çoading is preferred to local computation
when the user has desirable channel condition or small
local computation capability. Moreover, beamforming and
MIMO techniques can be exploited to reduce the energy
consumption for ofÔ¨Çoading. For latency reduction, com-
putation ofÔ¨Çoading is advantageous over local computa-
tion when the user has a large bandwidth and the MEC
server is provisioned with huge computation capacity.
‚Ä¢ Partial ofÔ¨Çoading allows Ô¨Çexible components/data par-
titioning. By ofÔ¨Çoading time-consuming or energy-
consuming sub-tasks to MEC servers, partial ofÔ¨Çoading
can achieve larger energy savings and smaller compu-
tation latency compared with binary ofÔ¨Çoading. Graph
theory is a powerful tool for designing the ofÔ¨Çoading
scheduling according to the task dependency graph.
‚Ä¢ For stochastic task models, the temporal correlation of
task arrivals and channels can be exploited to design
adaptive dynamic computation ofÔ¨Çoading policies. More-
over, it is critical to maintain the task buffer stability at
the user and MEC server via ofÔ¨Çoading rate control.
B. Multiuser MEC Systems
While the preceding subsection aims at resource manage-
ment policies for single-user MEC systems with a dedicated
MEC server, this subsection considers the multiuser MEC
systems comprising multiple mobile devices that share one
edge server. Several new challenges are investigated in the
sequel, including the multiuser joint radio-and-computational

----- Page 13 (native) -----
13
TABLE IV
THE COMPARISON OF PAPERS FOCUSING ON SINGLE-USER MEC SYSTEMS.
Task model
Design Objective
Reference
Proposed Solution
Binary OfÔ¨Çoading
Energy
[81]
Optimize local computing and ofÔ¨Çoading by controlling the CPU
frequency and transmission rate
[83]
Propose a novel framework of wirelessly powered MEC and optimize
both local computing and ofÔ¨Çoading
[94]
Propose general guidelines to make ofÔ¨Çoading decision for energy
consumption minimization
[96]
Propose the optimal binary computation ofÔ¨Çoading decision using
convex optimization
Energy and latency
[95]
Propose general guidelines to make ofÔ¨Çoading decision for energy-
consumption and computation-latency minimization
Partial OfÔ¨Çoading
Energy
[62]
Propose a joint scheduling and computation ofÔ¨Çoading algorithm by
parallel processing appropriate components in the mobile and cloud
[99]
Formulate a stochastic shortest-path problem and derive the one-climb
optimal policy
[101]
Jointly optimize the program partitioning with the selection of transmit
power and constellation size
[102]
Propose an iterative algorithm for the optimal ofÔ¨Çoading scheduling as
well as the percentage of the data to be carried on each radio interface
Latency
[61]
Propose a heuristic load-balancing program-partitioning algorithm
[98]
Propose a polynomial-time approximate solution with guaranteed
performance
Energy and latency
[97]
Jointly optimize the ofÔ¨Çoading ratio, transmission power and CPU-
cycle frequency using variable-substitution technique
[100]
Propose an algorithmic to leverage the structure of the call graphs by
means of message passing under both serial and parallel implementa-
tions of processing and communication
Stochastic Model
Energy
[103]
Propose a Lyapunov optimization-based dynamic computation ofÔ¨Çoad-
ing policy
Latency
[104]
Dynamically control the local processing and transmission using MDP
[105]
Optimize local computing and transmission using semi-MDP and
propose a one-dimensional heuristic search algorithm
Energy and Latency
[106]
Jointly control the local CPU frequency, modulation scheme as well
as the data rates under a semi-MDP framework
[107]
Propose a Lyapunov optimization-based algorithm to decide the of-
Ô¨Çoading policy, task allocation, CPU clock speed, and selected network
interface
[108]
Propose a Lyapunov optimization-based scheme for cloud ofÔ¨Çoading
scheduling, as well as download scheduling for cloud execution output
resource allocation, MEC server scheduling, and multiuser
cooperative edge computing.
1) Joint Radio-and-Computational Resource Allocation:
Compared with the central cloud, the MEC servers have much
less computational resources. Therefore, one key issue in
designing a multiuser MEC system is how to allocate the
Ô¨Ånite radio-and-computational resources to multiple mobiles
for achieving a system-level objective, e.g., the minimum
sum mobile-energy consumption. Both the centralized and
distributed resource allocation schemes have been studied for
different MEC systems as reviewed in the following..
For centralized resource allocation [84], [86], [101], [109]‚Äì
[114], the MEC server obtains all the mobile information, in-
cluding the CSI and computation requests, makes the resource-
allocation decisions, and informs the mobile devices about
the decisions. In [84], mobile users time-share a single edge
server and have different computation workloads and local-
computation capacities. A convex optimization problem was
formulated to minimize the sum mobile-energy consumption.
The key Ô¨Ånding is that the optimal policy for controlling
ofÔ¨Çoading data size and time allocation has a simple threshold-
based structure. SpeciÔ¨Åcally, an ofÔ¨Çoading priority function
was Ô¨Årstly derived according to mobile users‚Äô channel condi-
tions and local computing energy consumption. Then, the users
with priorities above and below a given threshold will perform
full and minimum ofÔ¨Çoading (so as to meet a given compu-
tation deadline), respectively. This result was also extended
to the OFDMA-based MEC systems for designing a close-
to-optimal computation ofÔ¨Çoading policy. In [86], instead
of controlling the ofÔ¨Çoading data size and time, the MEC
server determined the mobile-transmission power and assigned
server CPU cycles to different users in order to reduce the
sum mobile-energy consumption. The optimal solution shows
that, there exists an optimal one-to-one mapping between the
transmission power and the number of allocated CPU cycles
for each mobile device. This work was further extended in
[101] to account for the optimal binary ofÔ¨Çoading based on
the model of task-call graphs. In [112], the authors con-
sidered the multiuser video compression ofÔ¨Çoading in MEC
and minimized the latency in local compression, edge cloud
compression and partial compression ofÔ¨Çoading scenarios.
Besides, in order to minimize the energy and delay cost for
multi-user MEC systems where each user has multiple tasks,
Chen et al. jointly optimized the ofÔ¨Çoading decisions and the
allocation of communication resource via a separable semidef-
inite relaxation approach in [113], which was later extended
in [114] by taking the computational resource allocation and
processing cost into account. Different from [84], [86], [101],

----- Page 14 (native) -----
14
[112]‚Äì[114], the revenue of service providers was maximized
in [109] under constraints of quality of service (QoS) require-
ments for all mobile devices. The assumed Ô¨Åxed resource
usage of each user results in a semi-MDP problem, which
was transformed into a linear programming (LP) model and
efÔ¨Åciently solved. In [110], assuming a stochastic task arrival
model, the energy-latency tradeoff in multiuser MEC systems
was investigated via a Lyapunov optimization-based online
algorithm, which jointly manages the available radio-and-
computational resources. Centralized resource management for
multiuser MEC system based on cloud radio access network
(C-RAN) has also been investigated in [111].
Another thrust of research targets distributed resource allo-
cation for multiuser MEC systems which were designed using
game theory and decomposition techniques [87], [88], [115]‚Äì
[119]. In [115] and [87], the computation tasks were assumed
to be either locally executed or fully ofÔ¨Çoaded via single
and multiple interference channels, respectively. With Ô¨Åxed
mobile-transmission power, an integer optimization problem
was formulated to minimize the total energy consumption and
ofÔ¨Çoading latency, which was proved to be NP-hard. Instead of
designing a centralized solution, the game-theoretic techniques
were applied to develop a distributed algorithm that is able
to achieve a Nash equilibrium. Moreover, it was shown that
for each user, ofÔ¨Çoading is beneÔ¨Åcial only when the received
interference power is lower than a threshold. Furthermore, this
work was extended in [116] and [117], where each mobile has
multiple tasks and can ofÔ¨Çoad computation to multiple APs
connected by a common edge-server, respectively. For the of-
Ô¨Çoading process, in addition to transmission energy, this work
has also accounted for the scanning energy of the APs and the
Ô¨Åxed circuit power. The proposed distributed ofÔ¨Çoading policy
showed that a mobile device should handover the computation
to a different AP only when a new user choosing the same
AP achieves a larger beneÔ¨Åt. Building on the system model
in [87], the joint optimization for the mobile-transmission
power and the CPU-cycle allocation of the edge server was
investigated in [88]. To solve the formulated mixed-integer
problem, the decomposition technique was utilized to optimize
the resource allocation and ofÔ¨Çoading decision sequentially.
SpeciÔ¨Åcally, the ofÔ¨Çoading decision problem was reduced to a
sub-modular maximization problem and solved by designing
a heuristic greedy algorithm. Similar decomposition technique
and successive convex approximation technique were utilized
in [118] and [119] respectively to design distributed resource
allocation algorithm for MEC systems.
2) MEC Server Scheduling: The works discussed earlier
[84], [86]‚Äì[88], [109], [117] are based on the assumptions of
user synchronization and the feasibility of parallel local-and-
edge computation. However, studying practical MEC server
scheduling requires relaxation of these assumptions as dis-
cussed below together with the resultant designs. First, the
arrival times of different users are in general asynchronous so
that it is desirable for the edge server with Ô¨Ånite computational
resource to buffer and compute the tasks sequentially, which
incurs the queuing delay. In [120], to cope with the bursty
task arrivals, the server scheduling was integrated with uplink-
downlink transmission scheduling to minimize the average
latency using queuing theory. Second, even for synchronized
task arrivals, the latency requirements can differ signiÔ¨Åcantly
over users running different types of applications ranging from
latency-sensitive to latency-tolerant applications. This fact
calls for the server scheduling assigning users different levels
of priorities based on their latency requirements. In [121], after
the pre-resource allocation, the MEC server will check the
deadline of different tasks during the server computing process
and adaptively adjust the task execution order to satisfy the
heterogeneous latency requirements. Last, some computation
tasks each consists of several dependent sub-tasks such that the
scheduling of these modules must satisfy the task-dependency
requirements. The task model with a sequential sub-task
arrangement was considered in [122] that jointly optimizes
the program partitioning for multiple users and the server-
computation scheduling to minimize the average completion
time. As a result, a heuristic algorithm was proposed to
solve the formulated mixed-integer problem. SpeciÔ¨Åcally, it
Ô¨Årst optimizes the computation partition for each user. Under
these partitions, it will search the time intervals violating the
resource constraint and adjust them accordingly. Furthermore,
the general dependency-task model as shown in Fig. 4(c) was
considered for multiple users in [118]. This model drastically
complicates the computing time characterization. To address
this challenge, a measure of ready time was deÔ¨Åned for each
sub-task as the earliest time when all the predecessors have
been computed. Then, the ofÔ¨Çoading decision, mobile CPU-
cycle frequency and mobile-transmission power were jointly
optimized to reduce the sum mobile-energy consumption and
computation latencies with a proposed distributed algorithm.
3) Multiuser Cooperative Edge Computing:
Multiuser
cooperative computing is envisioned as a promising technique
to improve the MEC performance by providing two advantages
[123]‚Äì[129]. First, MEC servers with limited computational
resources may be overloaded when they have to serve a
large number of ofÔ¨Çoading mobile users. In such cases, the
burdens on the servers can be lightened via peer-to-peer mobile
cooperative computing. Second, sharing the computational
resources among the users can balance the uneven distribution
of the computation workloads and computation capabilities
over users. In [123], D2D communication was proposed to
enable multiuser cooperative computing. In particular, this
work studied how to detect and utilize computational resources
on other users. This idea was adopted in [124] to propose
a D2D-based heterogeneous MCC networks. Such a novel
framework was shown to enhance the network capacity and
ofÔ¨Çoading probability. Moreover, for wireless sensor networks,
cooperative computing was proposed in [125] to enhance
its computation capability. First, the optimal computation
partition for minimizing the total energy consumption of
two cooperative nodes was investigated. This result was then
utilized to design the fairness-aware energy-efÔ¨Åcient cooper-
ative node selection. Furthermore, Song et al. showed that
sharing computation results among the peer users can sig-
niÔ¨Åcantly reduce the communication trafÔ¨Åc for a multiuser
MEC system [126]. Assuming the task can either be ofÔ¨Çoaded
or computed locally, a mixed-integer optimization problem
was formulated to minimize the total energy consumption

----- Page 15 (native) -----
15
TABLE V
THE COMPARISON OF PAPERS FOCUSING ON MULTIUSER MEC SYSTEMS.
Theme
Design
Type/Motivation
Design Objective
Reference
Proposed Solution
Centralized
Energy
[84]
Design the optimal threshold-based resource allocation policy
based on deÔ¨Åned ofÔ¨Çoading priority function for TDMA and
OFDMA systems
[86]
Jointly optimize the allocation of communication and com-
putation resources
[101]
Design the optimal resource allocation and code partitioning
by call-graph selection approach
[111]
Solve the non-convex resource allocation problem for C-RAN
using iterative algorithms
Latency
[112]
Minimize the latency in multiuser video compression via
resource allocation
Energy and latency
[110]
Propose a Lyapunov optimization-based dynamic computa-
tion ofÔ¨Çoading policy
[113], [114]
Jointly optimize the ofÔ¨Çoading decisions and the allocation
of resource via semideÔ¨Ånite relaxation
Joint
radio-and-
computational
Revenue
[109]
Design the optimal resource allocation based on semi-MDP
resource
allocation
Distributed
Energy
[119]
Propose a distributed iterative algorithm using successive
convex approximation technique
Energy and latency
[87], [115]
Develop a distributed algorithm that is able to achieve a Nash
equilibrium
[116]
Propose a distributed algorithm for multi-user MEC systems
where each user has multiple tasks
[117]
Consider multiple servers and develop a distributed algorithm
admitting the Nash equilibrium
[118]
Propose a decomposition algorithm to control the computation
ofÔ¨Çoading selection, clock frequency control and transmission
power allocation iteratively
Utility
[88]
Propose a decomposition algorithm to optimize the resource
allocation and ofÔ¨Çoading decisions
MEC server
Bursty
data
arrivals
Latency
[120]
Optimize the uplink and downlink scheduling using queuing
theory
Heterogeneous
deadlines
Energy
[121]
Propose a pre-resource allocation and joint scheduling scheme
scheduling
Task dependency
Latency
[122]
Propose heuristic algorithm with searching and adjusting
phases based on constraint relaxation
Energy and latency
[118]
Propose a decomposition algorithm to control the computation
ofÔ¨Çoading selection, clock frequency control and transmission
power allocation iteratively
Cooperative
D2D
Task success rate
[123]
Propose the optimal and periodic mobile cloud access scheme
communication
Network capacity and
ofÔ¨Çoading probability
[124]
Propose D2D communication techniques in heterogeneous
MEC systems
Cooperation
Energy
[125]
Propose a fairness-aware energy-efÔ¨Åcient cooperative node
selection scheme
[127]
Propose a four-slot protocol to enable joint computation and
communication cooperation
computing
Share
computation
results
Energy
[126]
Propose a Lyapunov optimization-based cooperative comput-
ing policy
Share
computational
resource
Energy
[128]
Propose a ‚Äústring-pulling‚Äù ofÔ¨Çoading policy based on con-
structed ofÔ¨Çoading feasibility tunnel
Small BSs cooper-
ation
Delay cost
[129]
Propose a peer ofÔ¨Çoading framework that allows both cen-
tralized and autonomous decision making
under the constraint of the system communication trafÔ¨Åc. To
tackle this challenging problem, two online task scheduling
algorithms were proposed based on pricing and Lyapunov
optimization theories. In addition, by employing a helper,
a four-slot joint computation-and-communication cooperation
protocol was proposed in [127], where the helper not only
computes part of the tasks ofÔ¨Çoaded from the user, but also
acts as a relay node to forward the tasks to the MEC server.
Another recent work [128] investigated the optimal ofÔ¨Çoading
policies in a peer-to-peer cooperative computing system where
the computing helper has time-varying computation resources.
SpeciÔ¨Åcally, an ofÔ¨Çoading feasibility tunnel was constructed
based on the helper‚Äôs CPU proÔ¨Åle and buffer size. Given the
tunnel, the optimal ofÔ¨Çoading was shown to be achieved by
the well-known ‚Äústring-pulling‚Äù strategy, graphically referring
to pulling a string across the tunnel. Last, Chen et al. proposed
an online peer ofÔ¨Çoading framework based on Lyapunov
optimization and game theoretic approaches in [129], which
enables small BSs cooperation to handle the spatially uneven
computation workloads in the network.
4) Summary and Insight: The comparison of resource man-
agement schemes for multiuser MEC systems is provided in

----- Page 16 (native) -----
16
Table V. We draw several conclusions on resource allocation,
MEC server scheduling and mobile cooperative computing as
follows.
‚Ä¢ Consider multiuser MEC systems with Ô¨Ånite radio-and-
computational resources. For system-lever objectives,
e.g., to minimize the sum mobile energy consumption, the
users with large channel gains and low local-computation
energy consumption have higher priorities for ofÔ¨Çoading
computation since they can contribute to larger energy
savings. Too many ofÔ¨Çoading users, however, will cause
severe inter-user interference of communication and com-
putation, which will, in turn, reduce the system revenue.
‚Ä¢ To effectively reduce the sum computation latency of
multiple users, the scheduling design for a MEC server
should assign higher priorities to the users with more
stringent latency requirements and heavy computation
loads. Moreover, parallel computing can further boost the
computation speed at the server.
‚Ä¢ Scavenging the enormous amount of distributed computa-
tion resources can not only alleviate the network conges-
tion, but also improves resource utilization and enables
ubiquitous computing. This vision can be materialized
by peer-to-peer mobile cooperative edge computing. The
key advantages include short-range transmission via D2D
techniques and computation resource and result sharing.
C. MEC Systems with Heterogeneous Servers
To enable ubiquitous edge computing, heterogeneous MEC
(Het-MEC) systems were proposed in [130] comprising one
central cloud and multiple edge servers. The coordination
and interaction of multi-level central/edge clouds introduce
many interesting new research challenges and recently have
attracted extensive relevant investigations on server selection,
cooperation and computation migration, as discussed in the
sequel.
1) Server Selection:
For users served by a Het-MEC
system, a key design issue is to determine the destination of
computation ofÔ¨Çoading, i.e., either the edge or central cloud
server. In [131], the server selection problem was studied
for a multiuser system comprising a single edge server and
a single central cloud. To maximize the total successful
ofÔ¨Çoading probability, a heuristic scheduling algorithm was
proposed to leverage both the low communication latency due
to the proximity of the MEC server and the low computation
latency arising from abundant computational resources at the
central-cloud server. SpeciÔ¨Åcally, when the computation load
of the MEC server exceeds a given threshold, latency-tolerant
tasks are ofÔ¨Çoaded to the central cloud to spare enough
computational resources at the edge server for processing
latency-sensitive tasks. In addition, [132] explored the problem
of server selection over multiple MEC servers. The major
challenge arises from the correlation between the amounts
of the ofÔ¨Çoaded computation and selected edge servers for
multiple users. To cope with this issue, a congestion game
was formulated and solved to minimize the sum energy
consumption of mobile users and edge servers. Most recently,
a computation ofÔ¨Çoading framework that allows a mobile
device to ofÔ¨Çoad tasks to multiple MEC servers was proposed
in [133], and semideÔ¨Ånite relaxation-based algorithms were
proposed to determine the task allocation decisions and CPU
frequency scaling.
2) Server Cooperation: Resource sharing via server co-
operation can not only improve the resource utilization and
increase the revenue of computing service providers, but also
provide more resources for mobile users to enhance their
user experience. This framework was originally proposed in
[134], which includes components such as resource allocation,
revenue management and service provider cooperation. First,
resource allocation was optimized for cases with deterministic
and random user information to maximize the total revenues.
Second, considering self-interested cloud service providers, a
distributed algorithm based on game theory was proposed to
maximize service providers‚Äô own proÔ¨Åts, which was shown
to achieve the Nash equilibrium. This study was further
extended in [135], which considered both the local and remote
resource sharing. The former refers to resource sharing among
different service providers within the same data center, while
the latter one means the cooperation across different data
centers. To realize the resource sharing and cooperation among
different servers, a coalition game was formulated and solved
by a game-theoretic algorithm with stability and convergence
guarantees. Moreover, the recent work [136] proposed a new
server cooperation scheme where edge servers exploit both the
computational and storage resources by proactively caching
computation results to minimize the computation latency. The
corresponding task distributing problem was formulated as a
matching game and solved by an efÔ¨Åcient algorithm based on
a proposed deferred-acceptance algorithm.
3) Computation Migration: In [137]‚Äì[139], apart from
optimizing the ofÔ¨Çoading decisions, the authors also inves-
tigated the computation migration among different remote
servers. SpeciÔ¨Åcally, the computation migration over MEC
servers was motivated by the mobility of ofÔ¨Çoading users.
When a user moves closer to a new MEC server, the network
controller can choose to migrate the computation to this
server, or compute the task in the original server and then
forward the results back to the user via the new server. The
computation migration problem was formulated as an MDP
problem based on a random-walk mobility model in [137].
It was shown that the optimal policy has a threshold-based
structure, i.e., the migration should be selected only when the
distance of two servers is bounded by two given thresholds.
This work was further extended in [138] where the workload
scheduling in edge servers was integrated with the service
migration to minimize the average overall transmission and
reconÔ¨Åguration costs using Lyapunov optimization techniques.
Another computation migration framework was proposed in
[139], where the MEC server can either process ofÔ¨Çoaded
computation tasks locally or migrate them to the central cloud
server. An optimization problem was formulated to minimize
the sum mobile-energy consumption and computation latency.
This problem was solved by a heuristic two-stage algorithm,
which Ô¨Årst determines the ofÔ¨Çoading decision for each user
by the semi-deÔ¨Ånite relaxation and randomization techniques,
and then performs the resource allocation optimization for all

----- Page 17 (native) -----
17
TABLE VI
THE COMPARISON OF PAPERS FOCUSING ON MEC SYSTEMS WITH HETEROGENEOUS SERVERS.
Theme
Design Type
Design Objective
Reference
Proposed Solution
Server selection
Edge/central
server selection
Successful ofÔ¨Çoad-
ing probability
[131]
Propose a heuristic server selection algorithm according to
the deadline requirements
Edge server selec-
tion
Energy
[132]
Formulate a congestion game and propose a distributed algo-
rithm admitting the Nash equilibrium
Multiple
edge
servers
Energy and latency
[133]
Propose semideÔ¨Ånite relaxation-based algorithms for task
allocation decisions and frequency scaling
Server cooperation
Edge server coop-
eration
Revenue
[134]
Propose a distributed resource allocation algorithm admitting
the Nash equilibrium
Edge/remote
server cooperation
Utility
[135]
Formulate a coalition game and propose a game-theoretic
algorithm
Edge
server
proactive caching
Latency
[136]
Study the distribution and proactive caching of computing
tasks in MEC
Computation
Edge server
Cost
[137]
Propose a threshold-based computation migration scheme
according to the distance
migration
migration
[138]
Propose online workload scheduling and migration algorithms
using Lyapunov optimization techniques
Remote server mi-
gration
Energy and latency
[139]
Propose a heuristic two-stage algorithm including migration
decision and resource allocation
the users.
4) Summary and Insight: Table VI provides the summary
of resource management schemes for MEC systems with
heterogeneous servers. The literature provides a set of insights
on server selection, cooperation, and computation migration,
described as follows.
‚Ä¢ Consider MEC systems with multiple computation tasks
and heterogeneous servers. To reduce the sum computa-
tion latency, it is desirable to ofÔ¨Çoad latency-insensitive
but computation-intensive tasks to remote central cloud
server and latency-sensitive ones to the edge servers.
‚Ä¢ Server cooperation can signiÔ¨Åcantly improve the compu-
tation efÔ¨Åciency and resource utilization at MEC servers.
More importantly, it can balance the computation load
distribution over the networks so as to reduce sum com-
putation latency while the resources are better utilized.
Moreover, the server cooperation design should con-
sider temporal-and-spatial computation task arrivals and
server‚Äôs computation capacities, time-varying channels,
and servers‚Äô individual revenue.
‚Ä¢ Computation migration is an effective approach for mo-
bility management in MEC. The decision of migrate-or-
not depends on the migration overhead, distances between
users and servers, channel conditions, and servers‚Äô com-
putation capacities. SpeciÔ¨Åcally, when a user moves far
away from its original MEC server, it is preferred to
migrate the computation to nearby servers.
D. Challenges
In the preceding subsections, we have conducted a compre-
hensive survey on the state-of-the-art resource management
techniques for MEC systems. However, the progress is still
in the infancy stage and many critical factors have been
overlooked for simplicity, which need to be addressed in future
research efforts. In the following, we identify three critical
research challenges for resource management in MEC that
remain to be solved.
1) Two-Timescale Resource Management: In most exist-
ing works, e.g., [87], [88], [96], [119], [121], [140], wireless
channels were assumed to remain static during the whole task
execution process for simplicity. Nevertheless, this assumption
may be unreasonable when the channel coherence time is
much shorter than the latency requirement. For instance, at a
carrier frequency of 2GHz, the channel coherence time can be
as small as 2.5ms when the speed is 100km/h. For some mobile
applications such as the MMORPG game PlaneShift4, the
acceptable response time is 440ms and the excellent latency
is 120ms [141]. In such scenarios, the task ofÔ¨Çoading process
may be across multiple channel blocks, necessitating the two-
timescale resource management for MEC. This problem is
very challenging even for a single-user MEC system with
deterministic task arrivals [81].
2) Online Task Partitioning: For ease of optimization,
existing literature tackling the task partitioning problems ig-
nores the Ô¨Çuctuation of the wireless channels, and obtain the
task partitioning decision before the start of the execution
process. With such an ofÔ¨Çine task partitioning decision, the
change of the channel condition may lead to inefÔ¨Åcient or
even infeasible ofÔ¨Çoading, which shall severely degrade the
computation performance. To develop online task partitioning
policies, one should incorporate the channel statistics into the
formulated task partitioning problem, which may easily belong
to an NP-hard problem even under a static channel. In [99] and
[142], approximate online task partitioning algorithms were
derived for applications with serial and tree-topology task-
call graphs, respective, while solutions for general task models
remain unexploited.
3) Large-Scale Optimization: The collaboration of multi-
ple MEC servers allows their resources to be jointly managed
for serving a large number of mobile devices simultaneously.
However, the increase of the network size renders the re-
source management a large-scale optimization problem with
respect to a large number of ofÔ¨Çoading decisions as well as
radio-and-computational resource allocation variables. Con-
ventional centralized joint radio-and-computational resource
4http://www.planeshift.it/

----- Page 18 (native) -----
18
Mobility Management 
for MEC 
  1. Mobility-Aware Online Prefetching
  2. Mobility-Aware OfÔ¨Çoading Using D2D Communications
  3. Mobility-Aware Fault-Tolerant MEC 
  
  4. Mobility-Aware Server Scheduling 
Deployment of MEC 
Systems 
  1. Site Selection for MEC Servers
  2. MEC Network Architecture
  3. Server Density Planning 
Cache-Enabled MEC
  1. Service Caching for MEC Resource Allocation 
  2. Data Caching for MEC Data Analytics
Green MEC 
  1. Dynamic Right-Sizing for Energy-Proportional MEC 
  2. Geographical Load Balancing for MEC
  3. Renewable Energy-Powered MEC Systems 
Security and Privacy 
Issues in MEC 
  1. Trust and Authentication Mechanisms 
  2. Networking Security 
  3. Secure and Private Computation  
Future Research 
Directions for MEC
Fig. 7. Future research directions for MEC.
management algorithms require a huge amount of information
and computation when applied to large-scale MEC systems,
which will inevitably incur a signiÔ¨Åcant execution delay and
may whittle away the potential performance improvement,
e.g., latency reduction, brought by the MEC paradigm. To
achieve efÔ¨Åcient resource management, it is required to design
distributed low-complexity large-scale optimization algorithms
with light signaling and computation overhead. Although
the recent advancements in large-scale convex optimization
[143] provide powerful tools for radio resource management,
they cannot be directly applied to optimize the computation
ofÔ¨Çoading decision due to its combinatorial and non-convex
nature, which calls for new algorithmic techniques.
IV. ISSUES, CHALLENGES, AND FUTURE RESEARCH
DIRECTIONS
Recent years have witnessed substantial research efforts on
resource management for MEC as surveyed in the preceding
section. However, there are lots of emerging research direc-
tions of MEC that are still largely uncharted. In this section,
technical issues, challenges and research opportunities will be
identiÔ¨Åed and discussed as summarized in Fig. 7, including
the large-scale MEC system deployment, cache-enabled MEC,
mobility management, green MEC and security-and-privacy
issues in MEC.
A. Deployment of MEC Systems
The primary motivation of MEC is to shift the Cloud
Computing capability to the network edges in order to reduce
the latency caused by congestion and propagation delays in
the core network. However, there is no formal deÔ¨Ånition of
what an MEC server should be, and the server locations
in the system are not speciÔ¨Åed. These invoke the site se-
lection problems for MEC servers, which are signiÔ¨Åcantly
different from the conventional BS site selection problems,
as the optimal placement of edge servers is coupled with the
computational resource provisioning, and both of them are
constrained by the deployment budget. Besides, the efÔ¨Åciency
of an MEC system relies heavily on its architecture, which
should account for various aspects such as workload intensity
and communication rate statistics. In addition, it is critical
for MEC vendors to determine the required server density
for catering the service demand, which is closely related to
the infrastructure deployment cost and marketing strategies.
Nonetheless, the large-scale nature of MEC systems makes
traditional simulation-based methods inapplicable, and thus
solutions based on network-scale analysis are preferred. In this
subsection, we will discuss three research problems related
to MEC deployment, including the site selection for MEC
servers, the MEC network architecture, and server density
planning.
1) Site Selection for MEC Servers: Selecting the sites
for MEC infrastructures, especially MEC servers, is the Ô¨Årst
step towards building up the MEC system. To make the
cost-effective server-site selection, the system planners and
administrators should account for two important factors: site
rentals and computation demands. In general, given the system

----- Page 19 (native) -----
19
deployment budget, more MEC servers should be installed at
regions with higher computation demands, such as business
districts, commercial areas and densely populated areas. This,
however, contradicts the cost requirement as such areas are
likely to have high site rentals. Fortunately, thanks to the well-
deployed telecom networks, it is a promising idea to install the
MEC servers co-located with the existing infrastructures such
as macro BSs, which is even more attractive for the telecom
operators who would like to participate in the MEC market.
However, this would not solve all the problems. On one
hand, due to the ever-increasing computation-quality require-
ment and ubiquitous smart devices, satisfactory user experi-
ence cannot be guaranteed due to the poor signal quality and
congestion in the macro cells. For some applications, e.g.,
smart home [144], it is desirable to move the computation
capability even closer to the end users. This can be achieved
by injecting some computational resources at small-cell BSs
[72], [73], which are low-cost and small-size BSs. Despite the
potential beneÔ¨Åts, there are still obstacles on the way:
‚Ä¢ First, due to physical limitations, the computation ca-
pabilities of such kind of MEC servers will be much
smaller than those at macro BSs, making it challenging to
handle computation-intensive tasks. One feasible solution
is to build a hierarchical network architecture for MEC
systems comprising MEC servers with heterogeneous
communication-and-computation capabilities as detailed
in the sequel.
‚Ä¢ Second, some of the small-cell BSs may be self-deployed
by the home users, and many femto BS owners may not
have the motivation to collaborate with MEC vendors.
To overcome this issue, MEC vendors need to design
a proper incentive mechanism in order to stimulate the
owners of small-cell BSs for renting the sites.
‚Ä¢ Moreover, deploying MEC servers at small-cell BSs may
incur security problems as they are easy-to-reach and
vulnerable to external attacks, which shall degrade the
levels of reliability.
On the other hand, the computation hot spots do not always
coincide with the communication hot spots. In other words, for
some of the computation hot spots, there exists no available
communication infrastructure (either macro or small-cell BS).
For these circumstances, we need to deploy edge servers with
wireless transceivers by properly choosing new locations.
Besides, the site selection for MEC servers is dependent
on the computational resource-allocation strategy, which poses
extra challenges compared to the conventional BS site selec-
tion. Intuitively, concentrating the computational resources at
a few MEC servers can help save the site rentals. However,
this comes at the prices of potential degradation of the service
coverage and communication quality. In addition, the optimal
computational resource allocation should take into account
both site rentals and computation demands. For example, for
an MEC server at a site with a high site rental, it is preferred
to allocate huge computational resource and thus serve a large
number of users, for achieving the high revenue. Hence, a
joint site selection and computational resource provisioning
problem needs to be solved before deploying MEC systems.
'DWD&HQWHU
/7(%6
6PDOOFHOO%6
:L)L5RXWHU
$GKRF&ORXG
'RZQORDG
8SORDG
7LHU
7LHU
7LHU
(QG8VHUV
Fig. 8. A 3-tier heterogeneous MEC system. Tier-1 servers are located in close
proximity to the end users, such as at WiFi routers and small-cell BSs, which
are of relatively small computation capabilities. Tier-2 servers are deployed
at LTE BSs with moderate computation capabilities. Tier-3 servers are the
existing Cloud Computing infrastructures, such as data centers.
2) MEC Network Architecture: The promotion of MEC
does not mean the extinction of the data-center networks
(DCNs). Instead, future mobile computing networks are en-
visioned to be consisted of three layers as shown in Fig. 8,
i.e., cloud, edge (a.k.a. fog layer), and the service subscriber
layer [130], [145]. While the cloud layer is mature and well-
deployed, there is still some Ô¨Çexibility and uncertainty in
designing the edge layer.
By analogy to the heterogeneous networks (HetNets) in
cellular systems, it is intuitive to design the Het-MEC systems,
which consist of multiple tiers. SpeciÔ¨Åcally, the MEC servers
in different tiers have distinct computation and communication
capabilities. Such kinds of hierarchical MEC system structures
can not only preserve the advantage of efÔ¨Åcient transmission
offered by HetNets, but also possess strong ability to handle
the peak computation workloads by distributing them across
different tiers [146]. However, the computation capacity provi-
sioning problem is highly challenging and remains unsolved,
as it should account for many different factors, such as
the workload intensity, communication cost between different
tiers, workload distribution strategies, etc.
Another thrust of research efforts focuses on exploiting
the potential of the service subscriber layer, and utilizing
the undedicated computational resources, e.g., laptops, smart
phones, and vehicles, overlaid with dedicated edge nodes.
This paradigm is termed as the Ad-hoc mobile cloud in
literature [147]‚Äì[150]. The ad-hoc mobile cloud enjoys the
beneÔ¨Åts of amortizing the stress of MEC systems, increasing
the utilization of the computational resources, and reducing
the deployment cost. However, it also brings difÔ¨Åculties in
resource management and security issues due to its ad-hoc
and self-organized nature.
3) Server
Density
Planning:
As mentioned in Sec-
tion IV-A2, the MEC infrastructure may be a combination

----- Page 20 (native) -----
20
‚àí500
‚àí400
‚àí300
‚àí200
‚àí100
0
100
200
300
400
500
‚àí500
‚àí400
‚àí300
‚àí200
‚àí100
0
100
200
300
400
500
Meter
Meter
 
 
MEC server
Mobile device
Building A
Building B
Building C
Building D
Fig. 9.
Illustration of the clustering behavior of the computation demands.
The mobile devices requesting for MEC services will be more concentrated
around the MEC servers.
of different types of edge servers, which provides various
levels of computation experience and contributes different
deployment costs. Hence, it is critical to determine the number
of edge nodes as well as the optimal combination of different
types of MEC servers with a given deployment budget and
computation demand statistics. Conventionally, this problem
can only be addressed by numerical simulations, which is
time-consuming and has poor scalability. Fortunately, owing
to the recent development of stochastic geometry theory and
its successful applications in performance analysis for wireless
networks [151]‚Äì[154], as well as the similarity between Het-
MEC systems and HetNets, it is feasible to conduct per-
formance analysis for MEC systems using techniques from
stochastic geometry theory. Such analysis of MEC systems
should address the following challenges: 1) The timescales
of computation and wireless channel coherence time may
be different [81], [104], which makes existing results for
wireless networks not readily applicable for MEC systems.
One possible solution is to combine the Markov chain and
stochastic geometry theories to capture the steady behavior
of computations. 2) The computation ofÔ¨Çoading policy will
affect the radio resource management policy, which should
be taken into consideration. 3) The computation demands are
normally non-uniformly distributed and clustered (see Fig. 9),
prohibiting the use of the homogeneous Poisson point process
(HPPP) model for edge servers and service subscribers. It thus
calls for the investigation of more advanced point processes,
e.g., the Ginibre Œ±-determinantal point process (DPP), to
capture the clustering behaviors of edge nodes [155].
B. Cache-Enabled MEC
It has been predicted by Cisco that mobile video streaming
will occupy up to 72% of the entire mobile data trafÔ¨Åc by 2019
[156]. One unique property of such services is that the content
requests are highly concentrated and some popular contents
will be asynchronously and repeatedly requested. Motivated
Fig. 10. Cache-enabled MEC systems.
by this fact, wireless content caching or FemtoCaching was
proposed in [157]‚Äì[160] to avoid frequent replication for the
same contents by caching them at BSs. This technology has
attracted extensive attention from both academia and industry
due to its striking advantages on reducing content acquisition
latency, as well as relieving heavy overhead burden of the
network backhaul. While caching is to move popular contents
close to end users, MEC is to deploy edge servers to handle
computation-intensive tasks for edge users to enhance user
experience. Note that these two techniques seem to target
for diverse research directions, i.e., one for popular content
delivery and the other for individual computation ofÔ¨Çoading.
However, they will be integrated seamlessly in this subsection
and envisioned to create a new research area, namely, the
cache-enabled MEC.
Consider the novel cache-enabled MEC system shown in
Fig. 10. In such systems, the MEC server can cache several
application services and their related database, called service
caching (or service placement [161]) and data caching, respec-
tively, and handle the ofÔ¨Çoaded computation from multiple
users. To efÔ¨Åciently reduce the computation latency, several
key and interesting problems need to be solved, which are
described in the following with potential solutions.
1) Service Caching for MEC Resource Allocation: Unlike
the central cloud server that is always assumed with huge and
diverse resources (e.g., computing, memory and storage), the
current edge server has much less resources, making it unable
to accommodate all users‚Äô computation requests. On the other
hand, different mobile services require different resources,
based on which, they can be classiÔ¨Åed into CPU-hungry (e.g.,
cloud chess and VR), memory-hungry (e.g., online Matlab),
and storage-hungry (e.g., VR) applications. Such a mismatch
between resource and demand introduces a key challenge on
how to allocate heterogeneous resources for service caching.
Note that similar problems have been investigated in con-
ventional Cloud Computing systems [162]‚Äì[165], termed as
VM placement, as well as MCC systems [161]. SpeciÔ¨Åcally, the
authors in [162] proposed a novel architecture for VM manage-
ment and optimized the VM placement over multiple clouds
to reduce the deployment costs and improve user experience,

----- Page 21 (native) -----
21
given constraints on hardware conÔ¨Åguration, the number of
VMs as well as load balancing. Similar VM-placement prob-
lems were also investigated in [163], [164] for maximizing the
energy savings of cloud servers and in [165] for different cloud
scheduling strategies. Recently, the authors in [161] extended
the VM placement idea to MCC systems and studied the
joint optimization of service caching/placement over multiple
clouds and load dispatching for end users‚Äô requests. As a
result, one efÔ¨Åcient algorithm was proposed to minimize both
the computation latency and service placement transition cost.
These works, however, cannot be directly applied to design
efÔ¨Åcient service caching policies for MEC systems, since it
should take into account more reÔ¨Åned information including
users‚Äô location, preference, experience as well as edge servers‚Äô
capacities in terms of the memory, storage and VM instance.
To this end, two possible approaches are described as follows.
The Ô¨Årst one is spatial popularity-driven service caching,
referring to caching different combinations and amounts of
services in different MEC servers according to their speciÔ¨Åc
locations and surrounding users‚Äô common interests. This idea
is motivated by the fact that users in one small region are likely
to request similar computing services. For example, visitors in
a museum tend to use AR for better sensational experience.
Thus, it is desirable to cache multiple AR services at the MEC
server of this region for providing the real-time service. To
achieve the optimal spatial service caching, it is essential to
construct a spatial-application popularity distribution model
for characterizing the popularity of each application over
different locations. Based on this, we can design resource-
allocation policies using various optimization algorithms, e.g.,
the game theory and convex optimization techniques.
An alternative approach is temporal popularity-driven ser-
vice caching. The main idea is similar to that of the spatial
counterpart, but it exploits the popularity information in the
temporal domain, since the computation requests also depend
on the time period. One example is that users are apt to play
mobile cloud gaming after dinner. This kind of information
will suggest MEC operators to cache several gaming services
during this typical period for handling the huge computation
loads. One disadvantage of this temporal-based approach is
the additional server cost resulted from frequent cache-and-
tear operations since popularity information is time-varying
and MEC servers possess Ô¨Ånite resources.
2) Data Caching for MEC Data Analytics: Many modern
mobile applications involve intensive computation based on
data analytics, e.g., ranking and classiÔ¨Åcation. Take VR as an
instance. It creates an imaginary environment similar to the
real world by generating realistic images, sounds and other
sensations for enhancing users‚Äô experience. Achieving this end
is nontrivial as it requires the MEC server to Ô¨Ånish multiple
complicated processes within the ultra-short duration (e.g.,
1ms), such as recognizing users‚Äô actions via pattern recog-
nition, ‚Äúunderstanding‚Äù users‚Äô requests via data mining, as
well as rendering virtual settings via video streaming or other
sensation techniques [166]. All the above data-analytics based
techniques should be supported by comprehensive database,
which, however, imposes extremely heavy burden on the edge
server storage. This challenge can be relieved by intelligent
data caching that only reserves frequently-used database. From
another perspective, caching parts of computation-result data
that is likely to be reused by others can further boost the
computation performance of the entire MEC system. One
typical example is mobile cloud gaming, which enables fast
and energy-efÔ¨Åcient gaming by shifting game computing
engines from mobiles to edge servers and supporting real-
time gaming by game video streaming. Thus, it emerges as
a leading technique for next generation mobile computing
infrastructures [167]. Since certain game rendered videos, e.g.,
gaming scenes, can be reused by other players, caching these
computation results would not only signiÔ¨Åcantly reduce the
computation latency of the players with the same computation
request, but also ease the computation burden for edge servers.
Similar idea has been proposed in [168], which investigated
collaborative multi-bitrate video caching and processing in
MEC.
For MEC data caching at a single edge server, one key
problem is how to balance the tradeoff between massive
database and Ô¨Ånite storage capacity. Unlike FemtoCaching
networks where content (data) caching mainly introduces
a new multiple-access mechanism termed as cache-enabled
access [169], data caching in MEC systems brings about
manifold effects on the computation accuracy, latency and
edge server-energy consumption, which, however, have not
been characterized in existing literature. This calls for model
building research efforts for accurately quantifying the men-
tioned effects for various MEC applications. Furthermore, it
is also essential to establish a practical database popularity
distribution model that is able to statistically characterize the
usage of each database set for different MEC applications.
Based on the above models, the said tradeoff can be achieved
by solving an optimization problem that maximizes the achiev-
able QoS and minimizes the storage cost in MEC systems
simultaneously.
The above framework can be further extended to MEC
systems with multiple servers where each server can serve
multiple users and each user can ofÔ¨Çoad computation to mul-
tiple edge servers. The fundamental problem is similar to that
of the cache-enabled HetNets [170], that is, how to spatially
distribute the database over heterogeneous edge servers under
both storage and computation-load constraints on each of
them, for increasing network-wide revenue. Intuitively, for
each MEC server, it is desirable to spare more storage to cache
the database of the most popular applications in its cell, and
it also needs to utilize partial storage to accommodate less
popular ones, whose computation performance will be further
improved by cooperative caching in different MEC servers.
Moreover, the performance of large-scale cache-enabled MEC
networks can be analyzed using stochastic geometry by mod-
eling nearby users as clusters [171].
C. Mobility Management for MEC
Mobility is an intrinsic trait of many MEC applications,
such as VR assisted museum tour to enhance experience of
visitors. In these applications, the movement and trajectory of
users provide location and personal preference information for

----- Page 22 (native) -----
22
Mobile Device‚Äô Trajectory 
Fig. 11. Mobility management for MEC.
the edge servers to improve the efÔ¨Åciency of handling users‚Äô
computation requests. On the other hand, mobility also poses
signiÔ¨Åcant challenges for realizing ubiquitous and reliable
computing (i.e., without interruptions and errors) due to the
following reasons. First, MEC will be typically implemented
in the HetNet architecture comprising of multiple macro,
small-cell BSs and WiFi APs. Thus, users‚Äô movement will
call for frequent handovers among the small-coverage edge
servers as shown in Fig. 11, which is highly complicated
due to the diverse system conÔ¨Ågurations and user-server as-
sociation policies. Next, users moving among different cells
will incur severe interference and pilot contamination, which
shall greatly degrade the communication performance. Last,
frequent handovers will increase the computation latency and
thus deteriorate users‚Äô experience.
Mobility management has been extensively studied for tra-
ditional heterogeneous cellular networks [172]‚Äì[174]. In these
prior works, users‚Äô mobility is modeled by the connectivity
probability or the link reliability according to such information
as the users‚Äô moving speeds. Based on such models, dynamic
mobility management has been proposed to achieve high data
rate and low bit-error rate. However, these policies cannot
be directly applied for MEC systems with moving users,
since they neglect the effects of the computation resources
at edge servers on the handover policies. Recent works in
[175]‚Äì[178] have made initial efforts to design mobility-aware
MEC systems. SpeciÔ¨Åcally, the inter-contact time and contact
rate were deÔ¨Åned in [175] to model users‚Äô mobility. An
opportunistic ofÔ¨Çoading policy was then designed by solving
a convex optimization problem for maximizing the successful
task ofÔ¨Çoading probability. Alternatively, to account for the
mobility, the number of edge servers that users can access was
modeled by an HPPP in [176]. Then, the ofÔ¨Çoading decision
was optimized by addressing the formulated MDP problem
to minimize the ofÔ¨Çoading cost including mobile-energy con-
sumption, latency and failure penalty. Other mobility models
were also proposed in [177], [178], which characterize the
mobility by a sequence of networks that users can connect to
and a two-dimensional location-time workÔ¨Çow, respectively.
In addition, mobility management for MEC was integrated
with trafÔ¨Åc control in [179] to provide better experience for
users with latency-tolerant tasks via designing intelligent cell
association mechanisms. In [160], edge caching was integrated
with mobility prediction in Follow-Me Cloud for enhancing
the content-caches migration located at the edges. Recent
proposals on mobility-aware wireless caching in [180] also
provided valuable guidelines on mobility management in MEC
systems.
Note that most of the existing works focused on optimizing
mobility-aware server selection. However, to achieve better
user experience and higher network-wide proÔ¨Åt, the ofÔ¨Çoading
techniques at mobile devices and scheduling policies at MEC
servers should be jointly considered. This introduces a set
of interesting research opportunities with some described as
follows.
1) Mobility-Aware Online Prefetching: In practice, the
full information of the user trajectory may be unavailable.
Conventional design for mobile computation ofÔ¨Çoading will
fetch a computation task to another server only when it is
handoverred. This mechanism requires excessive fetching of
a large volume of data for handover and thus brings long
fetching latency. Moreover, it also causes heavy loads on the
MEC network. One promising solution to handle this issue is
to leverage the statistical information of the user trajectory and
prefetch parts of future computation data to potential servers
during the server-computation time, referred to as online
prefetching [181]. This technique can not only signiÔ¨Åcantly
reduce the handover latency via mobility prediction, but also
enable energy-efÔ¨Åcient computation ofÔ¨Çoading by enlarging
the transmission time. However, it also encounters several
challenges with two most critical ones described as follows.
The Ô¨Årst challenge arises from the trajectory prediction. Ac-
curate prediction can allow seamless handovers among edge
servers and reduce the prefetching redundancy. Achieving it,
however, requires precise modeling and high-complexity ML
techniques, e.g., Bayesian, reinforcement and deep learning.
For example, the trajectory of a typical visitor in a museum
can be predicted according to his own interest-information
and statistical route-information of some previous visitors
with similar interests that can be obtained by ML algorithms.
Therefore, it is important to balance the tradeoff between the
modeling accuracy and computation complexity. The second

----- Page 23 (native) -----
23
challenge lies in the selection of the prefetched computation
data. To maximize the successful ofÔ¨Çoading probability of
edge users, the computation-intensive components should be
prefetched earlier with adaptive transmission power control in
dynamic fading channels.
2) Mobility-Aware OfÔ¨Çoading Using D2D Communica-
tions: D2D communications was Ô¨Årst proposed in [182] to
improve the network capacity and alleviate the data trafÔ¨Åc
burden in cellular systems. This paradigm can also be used
to handle the user mobility problems in MEC systems [123],
which creates numerous D2D communication links. These
links allow the computation of a user to be ofÔ¨Çoaded to its
nearby users which have more powerful computation capabil-
ities. The short-range communication offered by D2D links
reduces energy consumption of data transmission as well.
However, user mobility brings new design issues as follows.
The Ô¨Årst one is how to exploit the advantages of both D2D
and cellular communications. One possible approach is to
ofÔ¨Çoad the computation-intensive data to the edge servers
at BSs that have huge computation capabilities in order to
reduce the server-computing time; while the components of
large data sizes and strict computation requirements should
be fetched to nearby users via D2D communications for
higher energy efÔ¨Åciency. Next, the selection of surrounding
users for ofÔ¨Çoading should be optimized to account for users‚Äô
mobility information, dynamic channels and heterogeneous
users‚Äô computation capabilities. Last, massive D2D links will
introduce severe interference for reliable communications.
This issue is more complicated in the mobility-based MEC
systems due to the fast-changing wireless fading environments.
Hence, advanced interference cancellation and cognitive radio
techniques can be applied for MEC systems, together with
mobility prediction to increase the ofÔ¨Çoading rate and reduce
the service latency.
3) Mobility-Aware Fault-Tolerant MEC: User mobility
poses signiÔ¨Åcant challenges for providing reliable MEC ser-
vices due to dynamic environments. Computation ofÔ¨Çoading
may fail due to intermittent connections and rapid-changing
wireless channels. The induced failure is catastrophic for
the latency-sensitive and resource-demanding applications. For
instance, AR-based museum video guide aims to provide Ô¨Çuent
and fancy virtual sensations for visitors, and the disruption
or failure of video streaming due to intermittent connections
would upset visitors. Another example is the military operation
which always requires fast and ultra-reliable computation,
even in high-mobility environments. Any computation failure
would bring serious consequences. These facts necessitate the
design for mobility-aware fault-tolerant MEC systems [183]‚Äì
[185], with three major and interesting problems illustrated as
follows, including fault prevention, fault detection and fault
recovery. Fault prevention is to avoid or prevent MEC fault
by backing up extra stable ofÔ¨Çoading links. Macro BSs or
central clouds can be chosen as protection-clouds, since they
have large network coverage that allows continuous MEC
service. The key design challenges lie in how to balance the
tradeoff between QoS (i.e., the failure probability) and energy
consumption due to extra ofÔ¨Çoading links for the single-
user case, and how to allocate protection-clouds for multiuser
MEC applications. Next, fault detection is to collect fault
information, which can be realized by setting intelligent timing
checks or receiving feedbacks for MEC services. In addition,
channel and mobility estimation techniques can also be applied
to estimate the fault so as to reduce the detection time.
Last, for detected MEC faults, recovery approaches should be
performed to continue and accelerate the MEC service. The
suspended service can be switched to more reliable backup
wireless links with adaptive power control for higher-speed
ofÔ¨Çoading. Alternative recovery approaches include migrating
the workloads to neighboring MEC systems directly or through
ad-hoc relay nodes as proposed in [185].
4) Mobility-Aware Server Scheduling: For multiuser MEC
systems, traditional MEC server scheduling servers users
according to the ofÔ¨Çoading priority order that depends on
users‚Äô distinct local computing information, channel gains
and latency requirements [84]. However, this static scheduling
design cannot be directly applied for the multiuser MEC
systems with mobility due to dynamic environments, e.g.,
time-varying channels and intermittent connectivities. Such
dynamics motivate the design of adaptive server scheduling
that regenerates the scheduling order from time to time,
incorporating the real-time user information. In such adaptive
scheduling mechanisms, users with worse conditions will
be allocated with higher ofÔ¨Çoading priorities to meet their
computing deadlines. Another potential approach is to design
mobility-aware ofÔ¨Çoading priority function by the following
two steps. The Ô¨Årst step is to accurately predict users‚Äô mobility
proÔ¨Åles and channels, where the major challenge is how
to reÔ¨Çect the mobility effects and re-deÔ¨Åne the ofÔ¨Çoading
priority function. The second step is resource reservation that
can enhance the server scheduling performance [186], [187].
SpeciÔ¨Åcally, to guarantee the QoS of latency-sensitive and
high-mobility users, MEC servers can reserve some dedicated
computational resources and provide reliable computing ser-
vice for such users. While for other latency-tolerant users, the
MEC server can perform on-demand provisioning. For such a
hybrid MEC server provisioning scheme, the server scheduling
can be optimized for serving the maximum number of users
with QoS guarantees, as well as maximizing MEC servers‚Äô
revenue.
D. Green MEC
MEC servers are small-scale data centers, each of which
consumes substantially less energy than the conventional cloud
data center. However, their dense deployment pattern raises a
big concern on the system-wide energy consumption. There-
fore, it is unquestionably important to develop innovative tech-
niques for achieving green MEC [188], [189]. Unfortunately,
designing green MEC is much more challenging compared
to green communication systems or green DCNs. Compared
to green communication systems, the computational resource
needs to be managed to guarantee satisfactory computation
performance, making the traditional green radio techniques not
readily applicable. On the other hand, the previous research
efforts on green DCNs have not considered the radio resource
management, which makes them not suitable for green MEC.

----- Page 24 (native) -----
24
Besides, the highly unpredictable computation workload pat-
tern in MEC servers poses another big challenge for resource
management in MEC systems, calling for advanced estimation
and optimization techniques. In this subsection, we will intro-
duce different approaches on designing green MEC systems,
including dynamic right-sizing for energy-proportional MEC,
geographical load balancing (GLB) for MEC, and MEC
systems powered by renewable energy.
1) Dynamic Right-Sizing for Energy-Proportional MEC:
The energy consumption of an MEC server highly depends
the utilization radio [see Eq. (5)]. Even when the server is
idling, it still consumes around 70% of the energy as it
operates at the full speed. This fact motivates the design
of energy-proportional (or power-proportional) servers, i.e.,
the energy consumption of a server should be proportional
to its computation load [190]. One way to realize energy-
proportional servers is to switch off/slow down the processing
speeds of some edge servers with light computation loads.
Such an operation is termed as dynamic right-sizing in the
literature on green DCNs [191]. However, along with the
potential energy savings, toggling servers between the active
and sleep modes could bring detrimental effects. First of all,
it will incur the switching energy cost and application data-
migration latency. Also, user experience may be degraded
due to the less amount of allocated computational resources,
which may, in turn, reduce the operator‚Äôs revenue. Besides,
the risk associated with server toggling as well as the wear-
and-tear cost of the servers might be increased, which can in
turn increase the maintenance costs of MEC vendors. As a
result, switching off the edge servers in a myopic manner is
not always beneÔ¨Åcial.
In order to make an effective decision on dynamic right-
sizing, the proÔ¨Åle of computation workload at each edge server
should be accurately forecasted. In conventional DCNs, this
can be achieved rather easily as the workload at each data
center is an aggregation of the computation requests across
a large physical region, e.g., several states in the United
States, which is relatively stable so that it can be estimated
by referring to the readily available historical data at the
data centers. However, for MEC systems, the serving area
of each edge server is much smaller, and hence its workload
pattern is affected by many factors, such as the location of the
server, time, weather, the number of nearby edge servers, and
user mobility. This leads to a fast-changing workload pattern,
and requires more advanced prediction techniques. Moreover,
online dynamic right-sizing algorithms that require less future
information need to be developed.
2) Geographical Load Balancing for MEC: GLB is an-
other key technique for green DCNs [192], [193], which
leverages the spatial diversities of the workload patterns,
temperatures, and electricity prices, to make workload routing
decision among different data centers. This technique can also
be applied to MEC systems. For instance, a cluster of MEC
servers can coordinate together to serve a mobile user, i.e.,
the tasks can be routed from the edge server located in a
hot spot (such as a restaurant) to a nearby edge server with
light workload (such as the one in a park). On one hand, this
helps to improve the energy efÔ¨Åciency of the lightly-loaded
edge servers as well as user experience. On the other hand, it
can prolong the battery lives of mobile devices, as ofÔ¨Çoading
the tasks through the nearby server could save transmission
energy. It is worthwhile to note that the implementation of
GLB requires efÔ¨Åcient resource management techniques at
edge servers, such as dynamic right-sizing and VM manage-
ment [194]‚Äì[197].
Meanwhile, there are many factors to be incorporated when
applying GLB in MEC environments. Firstly, since the mi-
grated tasks should go through the cellular core network, the
network congestion state should be monitored and considered
when making the GLB decisions. Secondly, to enable seamless
task migration, a VM should be migrated/set up in another
edge server beforehand, which may cause additional energy
consumption. Thirdly, the mutual interests of MEC operators
and edge computing service subscribers should be carefully
considered when performing GLB, due to the tradeoff between
the energy savings and latency reduction. Last but not least,
the existence of conventional Cloud Computing infrastructures
endows the edge servers with an extra option of ofÔ¨Çoading
the latency-critical and computation-intensive tasks to remote
cloud data centers, creating a new design dimension and
further complicating the optimization.
3) Renewable Energy-Powered MEC Systems: Traditional
grid energy is normally generated by coal-Ô¨Åred power plants.
Hence, powering mobile systems with grid energy inevitably
causes a huge amount of carbon emission, which opposes the
target of green computing. Off-grid renewable energy, such
as solar radiation and wind energy, recently, has emerged as
a viable and promising power source for various IT systems
thanks to the recent advancements of energy harvesting (EH)
techniques [198], [199]. This fact motivates the design of
innovative MEC systems, called renewable energy-powered
MEC systems, which are shown in Fig. 12 comprising both
EH-powered MEC servers and mobile devices. On one hand,
as the MEC servers are expected to be densely-deployed
and have low power consumption similar to that of small-
cell BSs [200], it is reasonable and feasible to power the
MEC infrastructures with the state-of-the-art EH techniques.
On the other hand, the mobile devices can also get beneÔ¨Åts
from using renewable energy as EH is able to prolong their
battery lives, which is one of the most favorable features for
mobile phones [201]. Besides, the use of renewable energy
sources eliminates the need of human intervention such as
replacing/recharging the batteries, which is difÔ¨Åcult if not
impossible for certain types of application scenarios where
the devices are hard and dangerous to reach. Meanwhile, these
advantages of using renewable energy are accompanied with
new design challenges.
A fundamental problem to be addressed for renewable
energy-powered MEC systems is the green energy-aware
resource allocation and computation ofÔ¨Çoading. Instead of
minimizing the energy consumption subject to satisfactory
user experience, the design principle for the renewable energy-
powered MEC systems should be changed to optimizing the
achievable performance given the renewable energy constraint,
as the renewable energy almost comes for free. Also, with
renewable energy supplies, the energy side information (ESI),

----- Page 25 (native) -----
25
Fig. 12. Renewable energy-powered MEC systems.
which indicates the amount of available renewable energy, will
play a key role in the decision making. Initial investigations
on renewable energy-powered MEC systems were conducted
in [202] and [203], which focused on EH-powered MEC
servers and EH-powered mobile devices, respectively. For EH-
powered MEC servers, the system operator should decide
the amount of workload required to be ofÔ¨Çoaded from the
edge server to the central cloud, as well as the processing
speed of the edge server, according to the information of
the core network congestion state, computation workload, and
ESI. This problem was solved by a learning-based online
algorithm in [202]. While for EH-powered mobile devices, a
dynamic computation ofÔ¨Çoading policy has been proposed in
[203] using Lyapunov optimization techniques based on both
the CSI and ESI. However, these two works only considered
small-scale MEC systems that consist of either one edge
server (in [202]) or one mobile device (in [203]). Thus, they
cannot provide a comprehensive solution for large-scale MEC
systems.
For large-scale MEC systems where multiple MEC servers
are deployed across a large geographic region, the concept
of GLB could be modiÔ¨Åed as the green energy-aware GLB
to optimize the MEC systems by further utilizing the spatial
diversity of the available renewable energy. This idea was
originally proposed for green DCNs, where the ‚Äúfollow the
renewables‚Äù routing scheme offers a huge opportunity in
reducing the grid energy consumption [192], [204]‚Äì[207].
Moreover, as mentioned before, there exist signiÔ¨Åcant differ-
ences between MEC systems and conventional DCNs in terms
of the wireless channel Ô¨Çuctuation and resource-management
design freedom of system operators. These factors make the
ofÔ¨Çoading decision making for the green energy-aware GLB in
MEC systems much more complicated, as it needs to consider
the CSI and ESI in the whole system.
The randomness of renewable energy may introduce the
ofÔ¨Çoading unreliability and risks of failure, bringing about
a major concern for using renewable energy to power MEC
systems. Fortunately, there are several potential solutions to
circumvent this issue as described below.
‚Ä¢ First, thanks to the low deployment cost, renewable
energy-powered edge servers can be densely deployed
over the system to provide more ofÔ¨Çoading opportunities
for the users. The resultant overlapping serving areas
offer the ofÔ¨Çoading diversity in the available energy to
avoid performance degradation. A similar idea has been
proposed for EH cooperative communication systems in
[208].
‚Ä¢ Second, the chance of energy shortage can be reduced
by properly selecting the renewable energy sources. It
was found in [192] that solar energy is more suitable
for workloads with a high peak-to-mean ratio (PMR),
while wind energy Ô¨Åts better for workloads with a small
PMR. This provides guidelines for renewable energy
provisioning for edge servers.
‚Ä¢ Third, MEC servers can be powered by hybrid energy
sources to improve reliability [209]‚Äì[211], i.e., powered
by both the electric grid and the harvested energy. Also,
equipping uninterrupted power supply (UPS) units at the
edge servers can provide a short period of stable energy
supply when green energy is in deÔ¨Åcit, and it can be
recharged when the surrounding energy condition returns
to a good state.
‚Ä¢ Moreover, wireless power transfer (WPT), which charges
mobile devices using RF wave [212], [213], is a newly-
emerged solution that enables wireless charging and
extends the battery life. This technique has been provided
in modern mobile phones such as Samsung Galaxy S6.
In renewable energy-powered MEC systems, the edge
servers can be powered by WPT when the renewable
energy is insufÔ¨Åcient for reliability [214]. This technology
also applies to the computation ofÔ¨Çoading for mobile
devices in MEC systems [83] and data ofÔ¨Çoading for
collaborate mobile clouds [215]. However, novel en-
ergy beamforming techniques are needed to increase the
charging efÔ¨Åciency. Moreover, due to the double near-
far problem in wireless powered systems, it requires a
delicate scheduling to guarantee fairness among multiple
mobile devices.

----- Page 26 (native) -----
26
E. Security and Privacy Issues in MEC
There are increasing demands for secure and privacy-
preserving mobile services. While MEC enables new types
of services, its unique features also bring new security and
privacy issues. First of all, the innate heterogeneity of MEC
systems makes the conventional trust and authentication mech-
anisms inapplicable. Second, the diversity of communication
technologies that support MEC and the software nature of
the networking management mechanisms bring new security
threats. Besides, secure and private computation mechanisms
become highly desirable as the edge servers may be an
eavesdropper or an attacker. These motivate us to develop
effective mechanisms as described in the following.
1) Trust and Authentication Mechanisms: Trust is an
important security mechanism in almost every mobile system,
behind which, the basic idea is to know the identity of the entity
that the system is interacting with. Authentication management
provides a possible solution to ensure ‚Äútrust‚Äù [216]. However,
the inherent heterogeneity of MEC systems, i.e., different
types of edge servers may be deployed by multiple vendors
and different kinds of mobile devices coexist, makes the
conventional trust and authentication mechanisms designed
for Cloud Computing systems inapplicable. For example, the
reputation-based trust model will lead to severe trust threats
in MEC systems, as demonstrated in [217]. This fact calls
for a uniÔ¨Åed trust and authentication mechanism that is able
to assess the reliability of edge servers and identify the
camouÔ¨Çaged edge servers. Besides, within the mobile network,
there will be a large number of edge servers serving mas-
sive mobile devices. This makes the trust and authentication
mechanism design much more complicated compared with
that in conventional Cloud Computing systems, since edge
servers are of small computation capabilities and designed to
enable latency-sensitive applications. Therefore, it is critical
to minimize the overhead of authentication mechanisms and
design distributed policies [218], [219].
2) Networking Security: The communication technologies
to support MEC systems, e.g., WiFi, LTE and 5G, have their
own security protocols to protect the system from attacks and
intrusions. However, these protocols inevitably create different
trust domains. The Ô¨Årst challenge of networking security in
MEC systems comes from the difÔ¨Åculties in the distribution
of credentials, which can be used to negotiate session keys
among different trust domains [216]. In existing solutions,
the certiÔ¨Åcation authority can only distribute the credentials
to all the elements located within its own trust domain [216],
making it hard to guarantee the privacy and data integrity for
communications among different trust domains. To address
this problem, we can use the cryptographic attributes as
credentials in order to exchange session keys [220], [221].
Also, the concept of federated content networks, which deÔ¨Ånes
how multiple trust domains can negotiate and maintain inter-
domain credentials [222], can be utilized.
Besides, techniques such as SDN and NFV are introduced
to MEC systems to simplify the networking management as
well as to provide isolation [5]. However, these techniques
are softwares by nature and thus vulnerable [223], [224].
Moreover, the large number of devices and entities in MEC
systems increase the chance of successfully attacking a single
device, which provides means to launch an attack to the
whole system [225]. Therefore, novel and robust security
mechanisms, such as hypervisor introspection, run-time mem-
ory analysis, and centralized security management [226], are
needed to guarantee a secured networking environment for
MEC systems.
3) Secure
and
Private
Computation:
Migrating
computation-intensive applications to the edge servers is
the most important function and motivation of building MEC
systems. In practice, the task input data commonly contains
sensitive and private information such as personal clinical
data and business Ô¨Ånancial records. Therefore, such data
should be properly pre-processed before being ofÔ¨Çoaded to
edge servers, especially the untrusted ones, in order to avoid
information leakage. In addition to information leakage,
the edge servers may return inaccurate and even incorrect
computation results due to either software bugs or Ô¨Ånancial
incentives,
especially
for
tasks
with
huge
computation
demands [227]. To achieve secure and private computation,
it is highly preferred that the edge platforms can execute the
computation tasks without the need of knowing the original
user data and the correctness of the computation results can
be veriÔ¨Åed, which can be realized by encryption algorithms
and veriÔ¨Åable computing techniques [228]. An interesting
example of secure computation mechanisms for LP problems
was developed in [227], where the LP problem is decomposed
into the public-owned solvers and the private-owned data.
By using a privacy-preserving transformation, the customer
ofÔ¨Çoads the encrypted private data for cloud execution, and
the server returns the results for the transformed LP problem.
A set of necessary and sufÔ¨Åcient conditions for verifying the
correctness of the results were developed based on duality
theory. Upon receiving the correct result, the clients can
map back the desired solution for the original problem using
the secret transformation. This method of result validation
achieves a big improvement in computation efÔ¨Åciency via
high-level LP computation compared to the generic circuit
representation, and it incurs close-to-zero additional overhead
on both the client and cloud server, which provides hints to
develop secure and private computation mechanisms for other
cloud applications.
V. STANDARDIZATION EFFORTS AND USE SCENARIOS OF
MEC
Standardization is an indispensable step for successful pro-
motion of a new technology, which documents the consensus
among multiple players and deÔ¨Ånes voluntary characteristics
and rules in a speciÔ¨Åc industry. Due to the availability of
structured methods and reliable data, standardization helps to
promote innovation and disseminate groupbreaking ideas and
knowledge about cutting-edge techniques. More importantly,
standardization can build customer trust in products, services
and systems, which helps to develop favorable market condi-
tion. The technical standards for MEC are being developed
by ETSI, and a new industry speciÔ¨Åcation group (ISG) was

----- Page 27 (native) -----
27
0(&9LUWXDOL]DWLRQ/D\HU
0(&+RVWLQJ,QIUDVWUXFWXUH
0(&+DUGZDUH5HVRXUFHV
0(&9LUWXDOL]DWLRQ0DQDJHU,DD6
0(&$SSOLFDWLRQ3ODWIRUP
0(&$SSOLFDWLRQ3ODWIRUP6HUYLFHV
7UDIILFRIIORDGLQJ
IXQFWLRQ72)
5DGLR1HWZRUN
,QIRUPDWLRQ
6HUYLFH51,6
&RPPXQLFDWLRQ
6HUYLFHV
6HUYLFH5HJLVWU\
0(&$SS
90
0(&$SS
90
0(&$SS
90
0(&$SS
90
0(&$SS
90
$3,
$3,
$3,
$3,
$SSOLFDWLRQ0DQDJHPHQW
6\VWHPV
0(&3ODWIRUPV
0DQDJHPHQW6\VWHP
0(&+RVWLQJ
,QIUDVWUXFWXUH
0DQDJHPHQW6\VWHP
*335DGLR1HWZRUN(OHPHQW
Fig. 13. MEC platform overview [5].
established within ETSI by Huawei, IBM, Nokia Networks,
NTT docomo and Vodafone. The aim of the ISG is to build
up a standardized and open environment, which will allow the
efÔ¨Åcient and seamless integration of applications from vendors,
service providers, and third-parties across multi-vendor MEC
platforms [229]. In September 2014, an introductory technical
white paper on MEC was published by ETSI, which deÔ¨Åned
the concept of MEC, proposed the referenced MEC platform,
as well as pointed out a set of technical requirements and
challenges for MEC [5]. Also, typical use scenarios and their
relationships with MEC have been discussed. These aspects
have also been documented in the ETSI speciÔ¨Åcations in 2015
[47], [230]‚Äì[232]. Most recently, ETSI has announced six
Proofs of Concepts (PoCs) that were accepted by the MEC ISG
in MEC World Congress 2016, which will assist the strategic
planning and decision-making of organizations, as well as
help to identify which MEC solutions may be viable in the
network [233]. This provides the community with conÔ¨Ådence
in MEC and will accelerate the pace of the standardization. It
is interesting to note that, in this congress, the ETSI MEC ISG
has renamed Mobile Edge Computing as Multi-access Edge
Computing in order to reÔ¨Çect the growing interest in MEC
from non-cellular operators, which will take effects starting
from 2017 [234]. Most recently, the 3rd Generation Partner-
ship Project (3GPP) shows a growing interest in including
MEC into its 5G standard, and functionality supports for
edge computing has been identiÔ¨Åed and reported in a recent
technical speciÔ¨Åcation document [235]. In this section, we
will Ô¨Årst introduce the recent standardization efforts from the
industry, including the referenced MEC server framework as
well as the technical challenges and requirements of MEC
systems. Typical use scenarios of MEC will be then elaborated.
In addition, we will discuss MEC-related issues in 5G stan-
dardizations, including the functionality supports for MEC,
and the innovative features in 5G systems with the potential
to help realize MEC.
A. Referenced MEC Server Framework
In the MEC introductory technical white paper [5], the
ETSI MEC ISG has deÔ¨Åned a referenced framework for MEC
servers (a.k.a. MEC platforms), where each server consists of a
hosting infrastructure and an application platform as shown in
Fig. 13. The hosting infrastructure includes the hardware com-
ponents (such as the computation, memory, and networking
resources) and an MEC virtualization layer (which abstracts
the detailed hardware implementation to the MEC application
platform). Also, the MEC host infrastructure provides the
interface to the host infrastructure management system as well
as the radio network elements, which, however, are beyond the
scope of the MEC initiative due to the availability of multiple
implementation options.
The MEC application platform includes an MEC virtual-
ization manager together with an Infrastructure as a Service
(IaaS) controller, and provides multiple MEC application
platform services. The MEC virtualization manager supports
a hosting environment by providing IaaS facilities, while the
IaaS controller provides a security and resource sandbox (i.e.,
a virtual environment) for both the applications and MEC
platform. The MEC application platform offers four main
categories of services, i.e., trafÔ¨Åc ofÔ¨Çoading function (TOF),

----- Page 28 (native) -----
28
radio network information services (RNIS), communication
services, and service registry. An MEC application platform
management interface is used by the operators for MEC
application platform management, supporting the application
conÔ¨Åguration and life cycle control, as well as VM operation
management.
On top of the MEC application platform, the MEC appli-
cations are deployed and executed within the VMs, which
are managed by their related application management systems
and agnostic to the MEC server/platform and other MEC
applications.
B. Technical Challenges and Requirements
In this subsection, we will brieÔ¨Çy summarize the technical
challenges and requirements speciÔ¨Åed in [5], [232].
1) Network Integration: As MEC is a new type of service
deployed on top of the communication networks, the MEC
platform is supposed to be transparent to the 3GPP network
architectures, i.e., the existing 3GPP speciÔ¨Åcations should not
be largely affected by the introduction of MEC.
2) Application Portability: Application portability requires
MEC applications to be seamlessly loaded and executed by the
MEC servers deployed by multiple vendors. This eliminates
the need for dedicated development or integration efforts for
each MEC platform, and provides more freedom on optimizing
the location and execution of MEC applications. It requires
the consistency of the MEC application platform management
systems, as well as mechanisms used to package, deploy and
manage applications from different platforms and vendors.
3) Security: The MEC systems face more security chal-
lenges than communication networks due to the integration
of computing and IT services. Hence, the security require-
ments for the 3GPP networks and the IT applications (e.g.,
isolating different applications as much as possible) should
be simultaneously satisÔ¨Åed. Besides, because of the nature
of proximity, the physical security of the MEC servers is
more vulnerable compared to conventional data centers. Thus,
the MEC platforms need to be designed in a way that both
logical intrusions and physical intrusions are well protected.
Moreover, authorization is an important aspect to prevent the
unauthorized/untrusted third-party applications from destroy-
ing MEC hosts as well as the valued radio access network.
4) Performance: As mentioned previously, the telecom
operators expect that introducing MEC will have minimal
impacts on the network performance, e.g., the throughput,
latency, and packet loss. Thus, sufÔ¨Åcient capacity should be
provisioned to process the user trafÔ¨Åc in the system deploy-
ment stage. Also, because of the highly-virtualized nature, the
provided performance may be impaired especially for those
applications that require intensive use of hardware resources
or have low latency requirements. As a result, how to improve
the efÔ¨Åciency of virtualized environments becomes a big
challenge.
5) Resilience:
The MEC systems should offer certain
level of resilience and meet the high-availability requirements
demanded by their network operators. The MEC platforms
and applications should have fault-tolerant abilities to prevent
them from adversely affecting other normal operations of the
network.
6) Operation: The virtualization and Cloud technologies
make it possible for various parties to participate in the
management of MEC systems. Thus, the implementation of
the management framework should also consider the diversity
of potential deployments.
7) Regulatory and Legal Considerations: The develop-
ment of MEC systems should meet the regulatory and legal
requirements, e.g., the privacy and charging.
Besides the aforementioned challenges and requirements,
there still exist more aspects that should be considered in the
Ô¨Ånal MEC standards, such as the support for user mobility,
applications/trafÔ¨Åc migration, and requirements on the con-
nectivity and storage. However, currently, the standardization
efforts and even efforts from the research communities are still
on their infant stages.
C. Use Scenarios
MEC will enable numerous mobile applications. In this
subsection, we will introduce four typical use scenarios that
have been documented by ETSI MEC ISG in [47].
1) Video Stream Analysis Service: Video stream analysis
has a broad range of applications such as the vehicular
license plate recognition, face recognition, and home security
surveillance, for which, the basic operations include object
detection and classiÔ¨Åcation. The video analysis algorithms
normally have a high computation complexity, and thus it is
preferable to move the analysis jobs away from the video-
capturing devices (e.g., the camera) to simplify the device
design and reduce the cost. If these processing tasks are
handled in the central cloud, the video stream should be routed
to the core network [236], which will consume a great amount
of network bandwidth due to the nature of video stream.
By performing the video analysis in the place close to edge
devices, the system can not only enjoy the beneÔ¨Åts of low
latency, but also avoid the problem of network congestion
caused by the video stream uploading. The MEC-based video
analysis system is shown in Fig. 14, where the edge server
should have the ability to conduct video management and
analysis, and only the valuable video clips (screenshots) will
be backed up to the cloud data centers.
2) Augmented Reality Service: AR is a live direct or
indirect view of a physical, real-world environment whose
elements are augmented (or supplemented) by computer-
generated sensory inputs such as sound, video, graphics,
or GPS data5. Upon analyzing such information, the AR
applications can provide additional information in real-time.
The AR applications are highly localized and require low
latency as well as intensive data processing. One of the
most popular applications is the museum video guides, i.e., a
handheld mobile device that provides the detailed information
of some exhibits that cannot be easily shown on the scene.
Online games, such as the Pok¬¥emon Go6, is another important
5https://en.wikipedia.org/wiki/Augmented reality
6http://www.pokemongo.com/

----- Page 29 (native) -----
29
9LGHR
0DQDJHPHQW
9LGHR
$QDO\WLFV
&RUH1HWZRUN
9LGHR6WRUDJH
9LGHR6WUHDP
9LGHR&OLSV6QDSVKRWV
0(&6HUYHU
Fig. 14. MEC for video stream analysis [5].
$52EMHFW
'DWD&DFKH
0(&6HUYHU
&HQWUDO
$5&DFKH
,QWHUQHW&RQWHQW6HUYHU
2EMHFW,'
&RUH1HWZRUN
Tracker
Tracker
Mapper
Mapper
Object
Recognizer
Object
Recognizer
9LGHR
0RELOH'HYLFH
Fig. 15. MEC for AR services [5].
application that AR techniques play a critical role. An MEC-
based AR application system is shown in Fig. 15, where
the MEC server should be able to distinguish the requested
contents by accurately analyzing the input data, and then
transmit the AR data back to the end user. Much attention
has been paid on the MEC-enabled AR systems recently, and
one demo has been implemented by Intel and roadshowed in
the Mobile World Congress 2016 [237].
3) IoT Applications: To simplify the hardware complexity
of IoT devices and prolong their battery lives, it is promising to
ofÔ¨Çoad the computation-intensive tasks for remote processing
and retrieve the results (required action) once the processing
is completed. Also, some IoT applications need to obtain
distributed information for computation, which might be dif-
Ô¨Åcult for an IoT device without the aid of an external entity.
Since the MEC servers host high-performance computation
capabilities and are able to collect distributed information,
their deployment will signiÔ¨Åcantly simplify the design of IoT
devices, without the need to have strong processing power
and capability to receive information from multiple sources
for performing meaningful computation. Another important
feature of IoT is the heterogeneity of the devices running
different forms of protocols, and their management should be
accomplished by a low-latency aggregation point (gateway),
which could be the MEC server.
4) Connected Vehicles: The connected vehicle technology
can enhance safety, reduce trafÔ¨Åc congestion, sense vehicles‚Äô
behaviors, as well as provide opportunities for numerous
value-added services such as the car Ô¨Ånder and parking lo-
cation [238]‚Äì[240]. However, the maturity of such technology
is yet to come as the latency requirement cannot be met with
the existing connected car clouds, which contributes to an end-
to-end latency between 100ms to 1s. MEC is a key enabling
technique for connected vehicles by adding computation and
geo-distributed services to roadside BSs. By receiving and
analyzing the messages from proximate vehicles and roadside
sensors, the connected vehicle cloudlets are able to propagate
the hazard warnings and latency-sensitive messages within
a 20ms end-to-end delay, allowing the drivers to react im-
mediately (as shown in Fig. 16) and make it possible for
autonomous driving. The connected vehicle technology has
already attracted extensive attention from the automobile man-
ufacturers (e.g., Volvo, Peugeot), automotive supplier (e.g.,
BOSCH), telecom operators (e.g., Orange, Vodafone, NTT
docomo), telecom vendors (e.g., QualComm, Nokia, Huawei),
as well as many research institutes. In November 9 2015,
Nokia7 presented two use cases for connected vehicles on
an automotive driving testbed, including the emergency brake
light and cooperative passing assistance.
In addition to connected vehicle systems with automobiles,
MEC will also be applicable for enabling connected unmanned
aerial vehicles (UAVs), which play an increasingly important
role in various scenarios such as photography, disaster re-
sponse, inspection and monitoring, precision agriculture, etc.
In 2016, Nokia proposed the UAV trafÔ¨Åc management (UTM)
based MEC architecture for connected UAVs in [241], where
the UTM unit provides functions of Ô¨Çeet management, auto-
mated UAV missions, 3D navigation, and collision avoidance.
However, as existing mobile networks are mainly designed for
7https://networks.nokia.com/solutions/mobile-edge-computing

----- Page 30 (native) -----
30
Fig. 16. MEC for connected vehicles.
users on the ground, UAVs will have very limited connectivity
and bandwidth. Therefore, reconÔ¨Åguring the mobile networks
to guarantee the connectivity and low latency between the
UAVs and the infrastructure becomes a critical task for de-
signing MEC systems for connected UAVs.
Due to limited space, we omit the description of some other
interesting application scenarios, such as active device track-
ing, RAN-aware content optimization, distributed content and
Domain Name System (DNS) caching, enterprise networks, as
well as safe-and-smart cities. Interested readers may refer to
the white papers on MEC [5], [21], [242] for details.
D. MEC in 5G Standardizations
The 5G standard is currently under development, which is to
enable the connectivity of a broad range of applications with
new functionality, characteristics, and requirements [77]. To
achieve these visions, the network features and functionality
in 5G networks are foreseen to be migrated from hardware to
software, thanks to the recent development of SDN and NFV
techniques. Since 2015, MEC (together with SDN and VFN) is
recognized by the European 5G infrastructure Public Private
Partnership (5GPPP) research body as one of the key emerging
technologies for 5G networks as it is a natural development
in the evolution of mobile BSs and the convergence of IT and
telecommunication networking [15]. In April 2017, 3GPP has
included supporting edge computing as one of the high level
features in 5G systems in the technical speciÔ¨Åcation document
[235], which will be introduced in this subsection. We have
also identiÔ¨Åed some innovative features of 5G systems, which
would pave the way for the realization, standardization and
commercialization of MEC.
1) Functionality Supports Offered by 5G Networks: From
the 5G network operators‚Äô point of view, reducing the end-
to-end latency and load on the transport networks are two
dominant design targets, which could possibly be achieved
with MEC as operators and third part applications could
be hosted close to the user equipment‚Äôs (UE‚Äôs) associated
wireless AP. To integrate MEC in 5G systems, the recent 5G
technical speciÔ¨Åcations have explicitly pointed out necessary
functionality supports that should be offered by 5G networks
for edge computing, as listed below:
‚Ä¢ The 5G core network should select the trafÔ¨Åc to be routed
to the applications in the local data networks.
‚Ä¢ The 5G core network selects a user plane function (UPF)
in proximity to the UE to route and execute the trafÔ¨Åc
steering from the local data networks via the interface,
which should be based on the UE‚Äôs subscription data,
UE location, and the data from the application function
(AF).
‚Ä¢ The 5G network should guarantee the session and service
continuity to enable UE and application mobility.
‚Ä¢ The 5G core network and AF should provide information
to each other via the network exposure function (NEF)8.
‚Ä¢ The policy control function (PCF)9 provides rules for QoS
control and charging for the trafÔ¨Åc routed to the local data
network.
8The NEF supports external exposure of capabilities of network functions,
which can be categorized into monitoring capability, provisioning capability,
and policy/charging capability [235].
9The PCF was deÔ¨Åned as a stand-alone functional part of the 5G core
network that allows to shape the network behaviour based on the operator
policies [243].

----- Page 31 (native) -----
31
2) Innovative Features in 5G to Facilitate MEC: Compared
to previous generations of wireless networks, 5G networks
possess various innovative features that are beneÔ¨Åcial to the
realization, standardization, and commercialization of MEC.
Three of them will be detailed in this subsection, including the
support service requirement, mobility management strategy,
and capability of network slicing.
‚Ä¢ Support Service Requirement: In 5G systems, the
QoS characteristics (in terms of resource type, priority
level, packet delay budget, and packet error rate), which
describe the packet forwarding treatment that a QoS Ô¨Çow
receives edge-to-edge between the UE and the UPF, are
associated with the 5G QoS Indicator (5QI). In [235],
a standardized 5QI to QoS mapping table is provided,
showing a broad range of services that can be supported
in 5G systems. In particular, 5G systems are able to cater
the requirements of latency-sensitive applications (e.g.,
real-time gaming and vehicular-to-everything (V2X) mes-
sages, which have a stringent packet budget delay require-
ment, i.e., <50ms, and a relatively small packet error
rate < 10‚àí3), and mission-critical services (e.g., push-
to-talk signaling that has both low delay (<60ms) and
small packet error rate (< 10‚àí6) requirements). These
applications coincide with typical MEC applications as
mentioned in Section V-C, i.e., 5G network is a viable
choice for wireless communications in MEC systems.
‚Ä¢ Advanced Mobility Management Strategy: The con-
cept of mobility pattern was introduced for designing mo-
bility management strategy for 5G systems. Such strate-
gies may be used by the 5G core network to characterize
and optimize UE mobility. SpeciÔ¨Åcally, the mobility
pattern could be determined, monitored, and updated by
the 5G core network based on the subscription of the UE,
statistics of UE mobility, network local policy, and UE
assisted information [235]. The mobility pattern not only
plays a central role on designing advanced transmission
schemes in wireless communication systems, but also
becomes a non-negligible design consideration for many
MEC applications discussed in Section V-C, e.g., the AR
services and connected vehicular applications. Thus, inte-
gration of advanced mobility management strategies that
make full use of the mobility pattern in 5G network can
help to develop an efÔ¨Åcient wireless interface for MEC
systems. Besides, the mobility pattern obtained from the
5G core network can be further leveraged to design joint
radio-and-computational resource management strategies
for MEC systems.
‚Ä¢ Capability of Network Slicing: Network slicing is a
form of agile and virtual network architecture that allows
multiple network instances to be created on top of a
common shared physical infrastructure10. Each of the
network instances is optimized for a speciÔ¨Åc service,
enabling resource isolation and customized network oper-
ations [244]. Due to the heterogeneous types of services
that 5G systems need to support (different requirements in
terms of functionality and performance), network slicing
10https://5g.co.uk/guides/what-is-network-slicing/
is regarded as an indispensable feature in 5G systems to
support different services running across a single radio
access network. Existing studies found that network slic-
ing is of supreme need for three use scenarios, including
ultra-reliable and low latency communication (URLLC),
massive machine type communication (mMTC), and en-
hanced mobile broadband (eMBB) [245]. With the capa-
bility of network slicing in 5G systems, MEC applications
could be provisioned with optimized and dedicated net-
work resources, which could help to reduce the latency
incurred by the access networks substantially and support
intense access of MEC service subscribers.
VI. CONCLUSION
MEC is an innovative network paradigm to cater for the
unprecedented growth of computation demands and the ever-
increasing computation quality of user experience require-
ments. It aims at enabling Cloud Computing capabilities and
IT services in close proximity to end users, by pushing
abundant computational and storage resources towards the
network edges. The direct interaction between mobile devices
and edge servers through wireless communications brings the
possibility of supporting applications with ultra-low latency
requirement, prolonging device battery lives and facilitating
highly-efÔ¨Åcient network operations. However, they come along
with various new design considerations and unique challenges
due to reasons such as the complex wireless environments and
the inherent limited computation capacities of MEC servers.
In this survey, we presented a comprehensive overview and
research outlook of MEC from the communication perspective.
To this end, we Ô¨Årst summarized the modeling methodologies
on key components of MEC systems such as the computation
tasks, communications, as well as mobile devices and MEC
servers computation. This help characterize the latency and
energy performance of MEC systems. Based upon the system
modeling, we conducted a comprehensive literature review
on recent research efforts on resource management for MEC
under various system architectures, which exploit the concepts
of computation ofÔ¨Çoading, joint radio-and-computational re-
source allocation, MEC server scheduling, as well as multi-
server selection and cooperation. A number of potential re-
search directions were then identiÔ¨Åed, including MEC de-
ployment issues, cache-enabled MEC, mobility management
for MEC, green MEC, as well as security-and-privacy issues
in MEC. Key research problems and preliminary solutions
for each of these directions were elaborated. Finally, we
introduced the recent standardization efforts from industry,
along with several typical use scenarios. The comprehensive
overview and research outlook on MEC provided in this
survey hopefully can serve as useful references and valuable
guidelines for further in-depth investigations of MEC.
REFERENCES
[1] M. Armbrust, R. G. A. Fox, A. D. Joseph, R. H. Katz, A. Konwinski,
G. Lee, D. A. Patterson, A. Rabkin, I. Stoica, and M. Zaharia,
‚ÄúAbove the clouds: A berkeley view of cloud computing,‚Äù Feb. 2012.
[Online].
Available:
https://www2.eecs.berkeley.edu/Pubs/TechRpts/
2009/EECS-2009-28.pdf

----- Page 32 (native) -----
32
[2] Q. Zhang, L. Cheng, and R. Boutaba, ‚ÄúCloud computing: State-of-the-
art and research challenges,‚Äù Journal Internet Services appl., vol. 1,
no. 1, pp. 7‚Äì18, 2010.
[3] N. WingÔ¨Åeld, ‚ÄúAmazon‚Äôs proÔ¨Åts grow more than 800 percent,
lifted
by
cloud
services,‚Äù
The
New
York
Times,
Jul.
2016.
[Online]. Available: http://www.nytimes.com/2016/07/29/technology/
amazon-earnings-proÔ¨Åt.html? r=0
[4] M. Chiang and T. Zhang, ‚ÄúFog and IoT: An overview of research
opportunities,‚Äù IEEE Internet Things J., vol. PP, no. 99, pp. 1‚Äì1, 2016.
[5] ETSI,
‚ÄúMobile-edge
computing
introductory
technical
white
paper,‚Äù White Paper, Mobile-edge Computing Industry Initiative.
[Online]. Available: https://portal.etsi.org/portals/0/tbpages/mec/docs/
mobile-edge computing - introductory technical white paper v1
[6] G. P. Fettweis, ‚ÄúThe tactile Internet: Applications and challenges,‚Äù
IEEE Veh. Techn. Mag., vol. 9, no. 1, pp. 64‚Äì70, Mar. 2014.
[7] A. A. Fuqaha, M. Guizani, M. Mohammadi, M. Aledhari, and
M. Ayyash, ‚ÄúInternet of Things: A survey on enabling technologies,
protocols, and applications,‚Äù IEEE Commun. Surveys Tuts., vol. 17,
no. 4, pp. 2347‚Äì2376, 4th Quarter 2015.
[8] Juniper,
‚ÄúSmart
wireless
devices
and
the
Inter-
net
of
me,‚Äù
White
paper,
Mar.
2015.
[Online].
Available:
http://itersnews.com/wp-content/uploads/experts/2015/03/
96079Smart-Wireless-Devices-and-the-Internet-of-Me.pdf
[9] J. G. Andrews, S. Buzzi, W. Choi, S. V. Hanly, A. Lozano, A. C. Soong,
and J. C. Zhang, ‚ÄúWhat will 5G be?‚Äù IEEE J. Sel. Areas Commun.,
vol. 32, no. 6, pp. 1065‚Äì1082, 2014.
[10] CISCO, ‚ÄúThe Internet of Things how the next evolution of the
Internet is changing everything,‚Äù White paper, Apr. 2011. [Online].
Available:
http://www.cisco.com/c/dam/en us/about/ac79/docs/innov/
IoT IBSG 0411FINAL.pdf
[11] F. Bonomi, R. Milito, J. Zhu, and S. Addepalli, ‚ÄúFog computing and its
role in the Internet of Things,‚Äù in Proc. ACM 1st edition of the MCC
workshop on Mobile cloud computing, 2012, pp. 13‚Äì16.
[12] S. Yi, C. Li, and Q. Li, ‚ÄúA survey of fog computing: Concepts,
applications and issues,‚Äù in Proc. ACM Workshop on Mobile Big Data,
2015, pp. 37‚Äì42.
[13] G. I. Klas, ‚ÄúFog computing and mobile edge cloud gain momentum
open fog consortium, ETSI MEC and Cloudlets,‚Äù 2015. [Online].
Available: http://www.engpaper.com/mobile-computing-2015.htm
[14] R. P. Goldberg, ‚ÄúSurvey of virtual machine research,‚Äù Computer, vol. 7,
no. 6, pp. 34‚Äì45, 1974.
[15] Y. C. Hu, M. Patel, D. Sabella, N. Sprecher, and V. Young, ‚ÄúMobile
edge computing‚ÄîA key technology towards 5G,‚Äù ETSI White Paper,
vol. 11, 2015.
[16] C.-Y. Chang, K. Alexandris, N. Nikaein, K. Katsalis, and T. Spyropou-
los, ‚ÄúMEC architectural implications for LTE/LTE-A networks,‚Äù in
Proc. ACM Workshop on Mobility in the Evolving Internet Architecture
(MobiArch), New York, NY, Oct. 2016, pp. 13‚Äì18.
[17] Z. Q. Jaber and M. I. Younis, ‚ÄúDesign and implementation of real time
face recognition system (RTFRS),‚Äù Int. J. Compt. Appl., vol. 94, no. 12,
pp. 15‚Äì22, May 2014.
[18] T. Verbelen, P. Simoens, F. D. Turck, and B. Dhoedt, ‚ÄúLeveraging
cloudlets for immersive collaborative applications,‚Äù IEEE Pervasive
Comput., vol. 12, no. 4, pp. 30‚Äì38, Oct.-Dec. 2013.
[19] A. A. Shuwaili and O. Simeone, ‚ÄúEnergy-efÔ¨Åcient resource allocation
for mobile edge computing-based augmented reality applications,‚Äù
IEEE Wireless Commun. Lett., vol. PP, no. 99, Apr. 2017.
[20] A.-S. Ali and O. Simeone, ‚ÄúEnergy-efÔ¨Åcient resource allocation for
mobile edge computing-based augmented reality applications,‚Äù IEEE
Wireless Commun. Lett., to appear.
[21] Juniper,
‚ÄúWhite
paper:
Mobile
edge
computing
use
cases
&
deployment options.‚Äù [Online]. Available: https://www.juniper.net/
assets/us/en/local/pdf/whitepapers/2000642-en.pdf
[22] M. Armbrust, A. Fox, R. GrifÔ¨Åth, A. D. Joseph, R. Katz, A. Konwinski,
G. Lee, D. Patterson, A. Rabkin, I. Stoica, and M. Zaharia, ‚ÄúA overview
of cloud computing,‚Äù Commun. ACM, vol. 53, no. 4, pp. 52‚Äì58, Apr.
2010.
[23] M. Othman, S. A. Madani, S. U. Khan et al., ‚ÄúA survey of mobile
cloud computing application models,‚Äù IEEE Commun. Surveys Tuts.,
vol. 16, no. 1, pp. 393‚Äì413, 1st Quater 2014.
[24] M. F. Bari, R. Boutaba, R. Esteves, L. Z. Granville, M. Podlesny,
M. G. Rabbani, Q. Zhang, and M. F. Zhani, ‚ÄúData center network
virtualization: A survey,‚Äù IEEE Commun. Surveys Tuts., vol. 15, no. 2,
pp. 909‚Äì928, 2nd Quarter 2013.
[25] A. Ghiasi and R. Baca, ‚ÄúOverview of largest data centers,‚Äù IEEE
802.3bs Task Force Interim Meeting, May 2014. [Online]. Available:
http://www.ieee802.org/3/bs/public/14 05/ghiasi 3bs 01b 0514.pdf
[26] S. Clinch, J. Harkes, A. Friday, N. Davies, and M. Satyanarayanan,
‚ÄúHow close is close enough? Understanding the role of cloudlets in
supporting display appropriation by mobile users,‚Äù in Proc. IEEE Int.
Conf. Pervasive Comput. Commun. (PerCom), Lugano, Switzerland,
Mar. 2012, pp. 122‚Äì127.
[27] T. X. Tran, A. Hajisami, P. Pandey, and D. Pompili, ‚ÄúCollaborative
mobile edge computing in 5G networks: New paradigms, scenarios,
and challenges,‚Äù IEEE Commun. Mag., vol. 55, no. 4, Apr. 2017.
[28] S. Wang, X. Zhang, Y. Zhang, L. Wang, J. Yang, and W. Wang, ‚ÄúA
survey on mobile edge networks: Convergence of computing, caching
and communications,‚Äù IEEE Access, to appear.
[29] J. Zhang, W. Xie, F. Yang, and Q. Bi, ‚ÄúMobile edge computing and
Ô¨Åeld trial results for 5G low latency scenario,‚Äù China Commun., vol. 13,
no. 2 (Supplement), pp. 174‚Äì182, 2016.
[30] E. Cuervo, A. Balasubramanian, D.-k. Cho, A. Wolman, S. Saroiu,
R. Chandra, and P. Bahl, ‚ÄúMaui: Making smartphones last longer
with code ofÔ¨Çoad,‚Äù in Proc. ACM Int. Conf. Mobile Syst. Appl. Serv.
(MobiSys), San Francisco, California, USA, Jun. 2010, pp. 49‚Äì62.
[31] M. Satyanarayanan, P. Bahl, R. Caceres, and N. Davies, ‚ÄúThe case for
VM-based cloudlets in mobile computing,‚Äù IEEE Pervasive Comput.,
vol. 8, no. 4, pp. 14‚Äì23, 2009.
[32] 5GPPP,
‚Äú5g
automotive
vision,‚Äù
White
Paper.
[On-
line].
Available:
https://5g-ppp.eu/wp-content/uploads/2014/02/
5G-PPP-White-Paper-on-Automotive-Vertical-Sectors.pdf
[33] O. Khalid, M. Khan, S. Khan, and A. Zomaya, ‚ÄúOmniSuggest: A
ubiquitous cloud based context aware recommendation system for
mobile social networks,‚Äù IEEE Trans. Serv. Comput., vol. 7, no. 3,
pp. 401‚Äì414, Dec. 2014.
[34] K. Goel and M. Goel, ‚ÄúCloud computing based e-commerce model,‚Äù
in Proc. IEEE Int. Conf. Recent Trends in Electron., Info. & Commun.
Techn. (RTEICT), Banglore, India, May 2016, pp. 27‚Äì30.
[35] G. Riah, ‚ÄúE-learning systems based on cloud computing: A review,‚Äù
ELSEVIER Proc. Comput. Sci., vol. 62, pp. 352‚Äì359, Sep. 2015.
[36] A. Abbas and S. U. Khan, ‚ÄúA review on the state-of-the-art privacy-
preserving approaches in the e-health clouds,‚Äù IEEE J. Biomed. Health
Inform., vol. 18, no. 4, pp. 1431‚Äì1441, Apr. 2014.
[37] G. Intelligence, ‚ÄúUnderstanding 5G: Perspectives on future technolog-
ical advancements in mobile,‚Äù London, UK, 2014.
[38] A. Somov and R. Giaffreda, ‚ÄúPowering IoT devices: Technologies
and opportunities,‚Äù Available: http://iot.ieee.org/newsletter/november-
2015/powering-iot-devices-technologies-and-opportunities.html.
[39] R. Kemp, N. Palmer, T. Kielmann, F. Seinstra, N. Drost, J. Maassen,
and H. Bal, ‚ÄúEyeDentify: Multimedia cyber foraging from a smart-
phone,‚Äù in Proc. IEEE Int. Symp. Multimedia, San Diego, CA, USA,
Dec. 2009, pp. 392‚Äì399.
[40] B. Shi, J. Yang, Z. Huang, and P. Hui, ‚ÄúOfÔ¨Çoading guidelines for
augmented reality applications on wearable devices,‚Äù in Proc. ACM
Int. Symp. Multimedia, Brisbane, Australia, Oct. 2015, pp. 1271‚Äì1274.
[41] W. N. Schilit, ‚ÄúA system architecture for context-aware mobile com-
puting,‚Äù Ph.D. dissertation, Columbia University, 1995.
[42] C. Perera, A. Zaslavsky, P. Christen, and D. Georgakopoulos, ‚ÄúContext
aware computing for the Internet of Things: A survey,‚Äù IEEE Commun.
Surveys Tuts., vol. 16, no. 1, pp. 414‚Äì454, 1st Quater 2014.
[43] S. Nunna, A. Kousaridas, M. Ibrahim, M. Dillinger, C. Thuemmler,
H. Feussner, and A. Schneider, ‚ÄúEnabling real-time context-aware
collaboration through 5G and mobile edge computing,‚Äù in Proc. IEEE
Int. Conf. Inf. Techn. New Generations (ITNG), Las Vegas, NV, Apr.
2015, pp. 601‚Äì605.
[44] X. Luo, ‚ÄúFrom augmented reality to augmented computing: A look
at cloud-mobile convergence,‚Äù in Proc. IEEE Int. Symp. Ubiquitous
Virtual Reality, Gwangju, South Korea, Jul. 2009, pp. 29‚Äì32.
[45] A. Thiagarajan, L. Ravindranath, H. Balakrishnan, S. Madden, and
L. Girod, ‚ÄúAccurate, low-energy trajectory mapping for mobile de-
vices.‚Äù in Proc. USENIX Symp. Networked Systems Design and Imple-
mentation (NSDI), Boston, MA, Mar. 2011, pp. 1‚Äì14.
[46] H. Suo, Z. Liu, J. Wan, and K. Zhou, ‚ÄúSecurity and privacy in
mobile cloud computing,‚Äù in Proc. IEEE Int. Wireless Commun. Mobile
Comput. Conf. (IWCMC), Cagliari, Italy, Jul. 2013, pp. 655‚Äì659.
[47] ETSI, ‚ÄúMobile-edge computing (MEC): Service scenarios.‚Äù [Online].
Available: http://www.etsi.org/deliver/etsi gs/MEC-IEG/001 099/004/
01.01.01 60/gs mec-ieg004v010101p.pdf
[48] W. Shi and S. Dustdar, ‚ÄúThe promise of edge computing,‚Äù Comput,
vol. 49, no. 5, pp. 78‚Äì81, May 2016.
[49] O. Salman, I. Elhajj, A. Kayssi, and A. Chehab, ‚ÄúEdge computing
enabling the Internet of Things,‚Äù in Proc. IEEE World Forum Internet
of Things (WFIOT), Dec. 2015, pp. 603‚Äì608.

----- Page 33 (native) -----
33
[50] A. Ahmed and E. Ahmed, ‚ÄúA survey on mobile edge computing,‚Äù in
Proc. IEEE Int. Conf. Intell. Syst. Control (ISCO), Coimbatore, India,
Jan. 2016, pp. 1‚Äì8.
[51] T. Taleb, K. Samdanis, B. Mada, H. Flinck, S. Dutta, and D. Sabella,
‚ÄúOn multi-access edge computing: A survey of the emerging 5g net-
work edge architecture &amp; orchestration,‚Äù IEEE Commun. Surveys
Tuts., to appear.
[52] H. Liu, F. Eldarrat, H. Alqahtani, A. Reznik, X. de Foy, and
Y. Zhang, ‚ÄúMobile edge cloud system: Architectures, challenges, and
approaches,‚Äù IEEE Syst. J., to appear.
[53] M. T. Beck, M. Werner, S. Feld, and S. Schimper, ‚ÄúMobile edge
computing: A taxonomy,‚Äù in Proc. Int. Conf. Advances Future Internet
(AFIN), Lisbon, Portugal, Nov 2014, pp. 48‚Äì54.
[54] P. Mach and Z. Becvar, ‚ÄúMobile edge computing: A survey on archi-
tecture and computation ofÔ¨Çoading,‚Äù IEEE Commun. Surveys Tuts., to
appear.
[55] D. Sabella, A. Vaillant, P. Kuure, U. Rauschenbach, and F. Giust,
‚ÄúMobile-edge computing architecture: The role of MEC in the Internet
of Things.‚Äù IEEE Consum. Electron. Mag., vol. 5, no. 4, pp. 84‚Äì91,
Oct. 2016.
[56] E. Ahmed and M. H. Rehmani, ‚ÄúMobile edge computing: Opportu-
nities, solutions, and challenges,‚Äù Future Generation Comput. Syst.,
vol. 70, pp. 59‚Äì63, May 2017.
[57] A. u. R. Khan, M. Othman, S. A. Madani, and S. U. Khan, ‚ÄúA survey of
mobile cloud computing application models,‚Äù IEEE Commun. Surveys
Tuts., vol. 16, no. 1, pp. 393‚Äì413, 1st Quater 2014.
[58] A. P. Miettinen and J. K. Nurminen, ‚ÄúEnergy efÔ¨Åciency of mobile
clients in cloud computing,‚Äù in Proc. USENIX Conf. Hot Topics Cloud
Comput. (HotCloud), Boston, MA, Jun. 2010, pp. 1‚Äì7.
[59] S. Melendez and M. P. McGarry, ‚ÄúComputation ofÔ¨Çoading decisions
for reducing completion time,‚Äù 2016. [Online]. Available: http:
//arxiv.org/pdf/1608.05839.pdf
[60] W. Yuan and K. Nahrstedt, ‚ÄúEnergy-efÔ¨Åcient soft real-time CPU
scheduling for mobile multimedia systems,‚Äù in Proc. ACM Symp.
Operat. Syst. Principles (SOSP), Bolton Landing, NY, USA, Oct. 2003,
pp. 149‚Äì163.
[61] M. Jia, J. Cao, and L. Yang, ‚ÄúHeuristic ofÔ¨Çoading of concurrent tasks
for computation-intensive applications in mobile cloud computing,‚Äù
in Proc. IEEE Int. Conf. Comput. Commun. (INFOCOM WKSHPS),
Toronto, Canada, Apr. 2014, pp. 352‚Äì357.
[62] S. E. Mahmoodi, R. N. Uma, and K. P. Subbalakshmi, ‚ÄúOptimal joint
scheduling and cloud ofÔ¨Çoading for mobile applications,‚Äù IEEE Trans.
Cloud Comput., vol. PP, no. 99, pp. 1‚Äì13, 2016.
[63] A. Goldsmith, Wireless Communications.
New York, NY, USA:
Cambridge University Press, 2005.
[64] D. Gesbert, S. Hanly, H. Huang, S. S. Shitz, O. Simeone, and W. Yu,
‚ÄúMulti-cell MIMO cooperative networks: A new look at interference,‚Äù
IEEE J. Sel. Areas Commun., vol. 28, no. 9, pp. 1380‚Äì1408, Dec. 2010.
[65] S. A. Jafar, ‚ÄúTopological interference management through index
coding,‚Äù IEEE Trans. Inf. Theory, vol. 60, no. 1, pp. 529‚Äì568, Jan
2014.
[66] C. Li, J. Zhang, M. Haenggi, and K. B. Letaief, ‚ÄúUser-centric intercell
interference nulling for downlink small cell networks,‚Äù IEEE Trans.
Commun., vol. 63, no. 4, pp. 1419‚Äì1431, Apr. 2015.
[67] E. Torkildson, U. Madhow, and M. Rodwell, ‚ÄúIndoor millimeter wave
MIMO: Feasibility and performance,‚Äù IEEE Trans. Wireless Commun.,
vol. 10, no. 12, pp. 4150‚Äì4160, Dec. 2011.
[68] X. Yu, J. C. Shen, J. Zhang, and K. B. Letaief, ‚ÄúAlternating mini-
mization algorithms for hybrid precoding in millimeter wave MIMO
systems,‚Äù IEEE J. Sel. Topics Signal Process., vol. 10, no. 3, pp. 485‚Äì
500, Apr. 2016.
[69] S. M. Alamouti, ‚ÄúA simple transmit diversity technique for wireless
communications,‚Äù IEEE J. Sel. Areas Commun., vol. 16, no. 8, pp.
1451‚Äì1458, Aug. 1998.
[70] A. Goldsmith, S. A. Jafar, N. Jindal, and S. Vishwanath, ‚ÄúCapacity
limits of MIMO channels,‚Äù IEEE J. Sel. Areas Commun., vol. 51, no. 6,
pp. 684‚Äì195, Jun. 2003.
[71] E. Larsson, O. Edfors, F. Tufvesson, and T. Marzetta, ‚ÄúMassive MIMO
for next generation wireless systems,‚Äù IEEE Commun. Mag., vol. 52,
no. 2, pp. 186‚Äì195, Feb. 2014.
[72] J. G. Andrews, H. Claussen, M. Dohler, S. Rangan, and M. C. Reed,
‚ÄúFemtocells: Past, present, and future,‚Äù IEEE Commun. Mag., vol. 30,
no. 3, pp. 497‚Äì508, Mar. 2012.
[73] H. S. Dhillon, R. K. Ganti, F. Baccelli, and J. G. Andrews, ‚ÄúModeling
and analysis of K-tier downlink heterogeneous cellular networks,‚Äù IEEE
Trans. Commun., vol. 30, no. 3, pp. 550‚Äì560, Mar. 2012.
[74] S. Han, Y.-C. Liang, and B.-H. Soong, ‚ÄúSpectrum refarming: A new
paradigm of spectrum sharing for cellular networks,‚Äù IEEE Trans.
Commun., vol. 63, no. 5, pp. 1895‚Äì1906, May 2016.
[75] Q. Chen, G. Yu, and Z. Ding, ‚ÄúOptimizing unlicensed spectrum
sharing for LTE-U and WiFi network coexistence,‚Äù IEEE J. Sel. Areas
Commun., vol. 34, no. 10, pp. 2562‚Äì2574, Oct. 2016.
[76] P. Kryszkiewicz, A. Kliks, and H. Bogucka, ‚ÄúSmall-scale spectrum
aggregation and sharing,‚Äù IEEE J. Sel. Areas Commun., vol. 34, no. 10,
pp. 2630‚Äì2641, Oct. 2016.
[77] ERICSSON, ‚Äú5G radio access - Capabilities and technologies,‚Äù
White paper, Apr. 2016. [Online]. Available: https://www.ericsson.
com/assets/local/publications/white-papers/wp-5g.pdf
[78] T. Burd and R. Broderson, ‚ÄúProcessor design for portable systems,‚Äù
Kluwer J. VLSI Signal Process. Syst., vol. 13, no. 2/3, pp. 203‚Äì221,
Aug. 1996.
[79] W. Yuan and K. Nahrstedt, ‚ÄúEnergy-efÔ¨Åcient CPU scheduling for
multimedia applications,‚Äù ACM Trans. Compt. Syst., vol. 24, no. 3,
pp. 292‚Äì331, Aug 2006.
[80] K. D. Vogeleer, G. Memmi, P. Jouvelot, and F. Coelho, ‚ÄúThe en-
ergy/frequency convexity rule: Modeling and experimental validation
on mobile devices,‚Äù in Proc. Springer Int. Conf. Parallel Process. Appl.
Mathematics (PPAM), Warsaw, Poland, Sep. 2013, pp. 793‚Äì803.
[81] W. Zhang, Y. Wen, K. Guan, D. Kilper, H. Luo, and D. O. Wu, ‚ÄúEnergy-
optimal mobile cloud computing under stochastic wireless channel,‚Äù
IEEE Trans. Wireless Commun., vol. 12, no. 9, pp. 4569‚Äì4581, Sep.
2013.
[82] A. Carroll and G. Heiser, ‚ÄúAn analysis of power consumption in a
smartphone,‚Äù in Proc. USENIX Annual Technical Conf., Boston, MA,
Jun. 2010, pp. 1‚Äì14.
[83] C. You, K. Huang, and H. Chae, ‚ÄúEnergy efÔ¨Åcient mobile cloud
computing powered by wireless energy transfer,‚Äù IEEE J. Sel. Areas
Commun., vol. 34, no. 5, pp. 1757‚Äì1771, May 2016.
[84] C. You, K. Huang, H. Chae, and B.-H. Kim, ‚ÄúEnergy-efÔ¨Åcient resource
allocation for mobile-edge computation ofÔ¨Çoading,‚Äù IEEE Trans. Wire-
less Commun., vol. PP, no. 99, 2016.
[85] P. Barham, B. Dragovic, K. Fraser, S. Hand, T. Harris, A. Ho,
R. Neugebauer, I. Pratt, and A. WarÔ¨Åeld, ‚ÄúXen and the art of virtual-
ization,‚Äù in Proc. ACM Symp. Operat. Syst. Principles (SOSP), Bolton
Landing, NY, Oct. 2003, pp. 164‚Äì177.
[86] S. Barbarossa, S. Sardellitti, and P. Di Lorenzo, ‚ÄúJoint allocation of
computation and communication resources in multiuser mobile cloud
computing,‚Äù in Proc. IEEE Int. Workshop Signal Process. Advances
Wireless Commun. (SPAWC), Darmstadt, Germany, Jun. 2013, pp. 26‚Äì
30.
[87] X. Chen, L. Jiao, W. Li, and X. Fu, ‚ÄúEfÔ¨Åcient multi-user computation
ofÔ¨Çoading for mobile-edge cloud computing,‚Äù IEEE Trans. Netw.,
vol. 24, pp. 2795‚Äì2808, Oct. 2016.
[88] X. Lyu, H. Tian, P. Zhang, and C. Sengul, ‚ÄúMulti-user joint task
ofÔ¨Çoading and resources optimization in proximate clouds,‚Äù IEEE
Trans. Veh. Techn., vol. PP, no. 99, pp. 1‚Äì13, Jul. 2016.
[89] S. Vakilinia, M. M. Ali, and D. Qiu, ‚ÄúModeling of the resource
allocation in cloud computing centers,‚Äù Elsevier Comput. Netw., vol. 91,
pp. 453‚Äì470, Nov. 2015.
[90] D. Bruneo, ‚ÄúA stochastic model to investigate data center performance
and QoS in IaaS cloud computing systems,‚Äù IEEE Trans. Parallel
Distrib. Syst., vol. 25, no. 3, pp. 560‚Äì569, 2014.
[91] X. Fan, W.-D. Weber, and L. A. Barroso, ‚ÄúPower provisioning for a
warehouse-sized computer,‚Äù in ACM SIGARCH Comput. Archit. News,
vol. 35, no. 2, 2007, pp. 13‚Äì23.
[92] C.-C. Lin, P. Liu, and J.-J. Wu, ‚ÄúEnergy-efÔ¨Åcient virtual machine
provision algorithms for cloud systems,‚Äù in Proc. IEEE Utility and
Cloud Computing (UCC), Melbourne, Australia, Dec. 2011, pp. 81‚Äì
88.
[93] A. Beloglazov, J. Abawajy, and R. Buyya, ‚ÄúEnergy-aware resource
allocation heuristics for efÔ¨Åcient management of data centers for cloud
computing,‚Äù Elsevier Future Generation Comput. Syst., vol. 28, no. 5,
pp. 755‚Äì768, May 2012.
[94] K. Kumar and Y. H. Lu, ‚ÄúCloud computing for mobile users: Can
ofÔ¨Çoading computation save energy?‚Äù Comput., vol. 43, no. 4, pp. 51‚Äì
56, Apr. 2010.
[95] K. Kumar, J. Liu, Y.-H. Lu, and B. Bhargava, ‚ÄúA survey of computation
ofÔ¨Çoading for mobile systems,‚Äù Mobile Netw. Appl., vol. 18, no. 1, pp.
129‚Äì140, Feb. 2013.
[96] S. Barbarossa, S. Sardellitti, and P. D. Lorenzo, ‚ÄúCommunicating while
computing: Distributed mobile cloud computing over 5G heterogeneous
networks,‚Äù IEEE Signal Process. Mag., vol. 31, no. 6, pp. 45‚Äì55, Nov.
2014.

----- Page 34 (native) -----
34
[97] Y. Wang, M. Sheng, X. Wang, L. Wang, and J. Li, ‚ÄúMobile-edge com-
puting: Partial computation ofÔ¨Çoading using dynamic voltage scaling,‚Äù
IEEE Trans. Commun., vol. 64, no. 10, pp. 4268‚Äì4282, Oct. 2016.
[98] Y. H. Kao, B. Krishnamachari, M. R. Ra, and F. Bai, ‚ÄúHermes: Latency
optimal task assignment for resource-constrained mobile computing,‚Äù
in Proc. IEEE Int. Conf. Comput. Commun. (INFOCOM), Hong Kong,
China, Apr. 2015, pp. 1894‚Äì1902.
[99] W. Zhang, Y. Wen, and D. O. Wu, ‚ÄúCollaborative task execution in
mobile cloud computing under a stochastic wireless channel,‚Äù IEEE
Trans. Wireless Commun., vol. 14, no. 1, pp. 81‚Äì93, Jan. 2015.
[100] S. Khalili and O. Simeone, ‚ÄúInter-layer per-mobile optimization of
cloud mobile computing: A message-passing approach.‚Äù [Online].
Available: http://arxiv.org/abs/1509.01596
[101] P. D. Lorenzo, S. Barbarossa, and S. Sardellitti, ‚ÄúJoint optimization
of radio resources and code partitioning in mobile edge computing.‚Äù
[Online]. Available: http://arxiv.org/abs/1307.3835v3
[102] S. E. Mahmoodi, K. P. Subbalakshmi, and V. Sagar, ‚ÄúCloud ofÔ¨Çoading
for multi-radio enabled mobile devices,‚Äù in Proc. IEEE Int. Conf.
Commun. (ICC), London, UK, Jun. 2015, pp. 5473‚Äì5478.
[103] D. Huang, P. Wang, and D. Niyato, ‚ÄúA dynamic ofÔ¨Çoading algorithm
for mobile computing,‚Äù IEEE Trans. Wireless Commun., vol. 11, no. 6,
pp. 1991‚Äì1995, Jun. 2012.
[104] J. Liu, Y. Mao, J. Zhang, and K. B. Letaief, ‚ÄúDelay-optimal compu-
tation task scheduling for mobile-edge computing systems,‚Äù in Proc.
IEEE Int. Symp. Inf. Theory (ISIT), Barcelona, Spain, Jul 2016, pp.
1451‚Äì1455.
[105] S. Chen, Y. Wang, and M. Pedram, ‚ÄúA semi-Markovian decision
process based control method for ofÔ¨Çoading tasks from mobile devices
to the cloud,‚Äù in Proc. IEEE Global Commun. Conf. (GLOBECOM),
Atlanta, GA, Dec 2013, pp. 2885‚Äì2890.
[106] S.-T. Hong and H. Kim, ‚ÄúQoE-aware computation ofÔ¨Çoading schedul-
ing to capture energy-latency tradeoff in mobile clouds,‚Äù in Proc. IEEE
Int. Conf. Sensing, Commun. Netw. (SECON), London, UK, Jun. 2016,
pp. 1‚Äì9.
[107] J. Kwak, Y. Kim, J. Lee, and S. Chong, ‚ÄúDream: Dynamic resource
and task allocation for energy minimization in mobile cloud systems,‚Äù
IEEE J. Sel. Areas Commun., vol. 33, no. 12, pp. 2510‚Äì2523, Dec
2015.
[108] Z. Jiang and S. Mao, ‚ÄúEnergy delay tradeoff in cloud ofÔ¨Çoading for
multi-core mobile devices,‚Äù IEEE Access, vol. 3, pp. 2306‚Äì2316, Nov.
2015.
[109] D. T. Hoang, D. Niyato, and P. Wang, ‚ÄúOptimal admission control
policy for mobile cloud computing hotspot with cloudlet,‚Äù in Proc.
IEEE Wireless Commun. Networking Conf. (WCNC), Paris, France,
Apr. 2012, pp. 3145‚Äì3149.
[110] Y. Mao, J. Zhang, S. Song, and K. B. Letaief, ‚ÄúPower-delay tradeoff
in multi-user mobile-edge computing systems,‚Äù in Proc. IEEE Global
Commun. Conf. (GLOBECOM), Washington, DC, Dec. 2016, pp. 1‚Äì6.
[111] K. Wang, K. Yang, and C. Magurawalage, ‚ÄúJoint energy minimization
and resource allocation in C-RAN with mobile cloud,‚Äù IEEE Trans.
Cloud Comput., vol. PP, no. 99, pp. 1‚Äì11, Jan. 2016.
[112] J. Ren, G. Yu, Y. Cai, and Y. He, ‚ÄúLatency optimization for
resource allocation in mobile-edge computation ofÔ¨Çoading.‚Äù [Online].
Available: https://arxiv.org/pdf/1704.00163.pdf
[113] M.-H. Chen, B. Liang, and M. Dong, ‚ÄúJoint ofÔ¨Çoading decision and
resource allocation for multi-user multi-task mobile cloud,‚Äù in Proc.
IEEE Int. Conf. Commun. (ICC), Kuala Lumpur, Malaysia, May 2016,
pp. 1‚Äì6.
[114] M.-H. Chen, B. Liang, and D. Ming, ‚ÄúJoint ofÔ¨Çoading and resource
allocation for computation and communication in mobile cloud with
computing access point,‚Äù in Proc. IEEE Int. Conf. Comput. Commun.
(INFOCOM), Atlanta, GA, USA, Apr. 2017, pp. 1863‚Äì1871.
[115] X. Chen, ‚ÄúDecentralized computation ofÔ¨Çoading game for mobile cloud
computing,‚Äù IEEE Trans. Parallel Distrib. Syst., vol. 26, no. 4, pp. 974‚Äì
983, Apr. 2016.
[116] M.-H. Chen, B. Liang, and M. Dong, ‚ÄúMulti-user mobile cloud
ofÔ¨Çoading game with computing access point,‚Äù in Proc. IEEE Int. Conf.
Cloud Networking (Cloudnet), Pisa, Italy, Oct. 2016, pp. 64‚Äì69.
[117] X. Ma, C. Lin, X. Xiang, and C. Chen, ‚ÄúGame-theoretic analysis of
computation ofÔ¨Çoading for cloudlet-based mobile cloud computing,‚Äù in
Proc. ACM Int. Conf. Modeling, Anal. and Simulation of Wireless and
Mobile Syst. (MSWiM), Cancun, Mexico, Nov. 2015, pp. 271‚Äì278.
[118] S. Guo, B. Xiao, Y. Yang, and Y. Yang, ‚ÄúEnergy-efÔ¨Åcient dynamic
ofÔ¨Çoading and resource scheduling in mobile cloud computing,‚Äù in
Proc. IEEE Int. Conf. Comput. Commun. (INFOCOM), San Francisco,
CA, Apr. 2016, pp. 1‚Äì9.
[119] S. Sardellitti, G. Scutari, and S. Barbarossa, ‚ÄúJoint optimization of radio
and computational resources for multicell mobile-edge computing,‚Äù
IEEE Trans. Signal Info. Process. Over Networks, vol. 1, no. 2, pp.
89‚Äì103, Jun. 2015.
[120] M. Molina, O. MuÀúnoz, A. Pascual-Iserte, and J. Vidal, ‚ÄúJoint scheduling
of communication and computation resources in multiuser wireless
application ofÔ¨Çoading,‚Äù in Proc. IEEE Int. Symp. on Personal Indoor
and Mobile Radio Comm. (PIMRC), Washington, DC, Sep. 2014, pp.
1093‚Äì1098.
[121] Y. Yu, J. Zhang, and K. B. Letaief, ‚ÄúJoint subcarrier and CPU time
allocation for mobile edge computing,‚Äù in Proc. IEEE Global Commun.
Conf. (GLOBECOM), Washington, DC, Dec. 2016, pp. 1‚Äì6.
[122] L. Yang, J. Cao, H. Cheng, and Y. Ji, ‚ÄúMulti-user computation
partitioning for latency sensitive mobile cloud applications,‚Äù IEEE
Trans. Comput., vol. 64, no. 8, pp. 2253‚Äì2266, Aug. 2015.
[123] Y. Li, L. Sun, and W. Wang, ‚ÄúExploring device-to-device communica-
tion for mobile cloud computing,‚Äù in Proc. IEEE Int. Conf. Commun.
(ICC), Sydney, Australia, Jun. 2014, pp. 2239‚Äì2244.
[124] M. Jo, T. Maksymyuk, B. Strykhalyuk, and C.-H. Cho, ‚ÄúDevice-
to-device-based heterogeneous radio access network architecture for
mobile cloud computing,‚Äù IEEE Wireless Commun., vol. 22, no. 3, pp.
50‚Äì58, Mar. 2015.
[125] Z. Sheng, C. Mahapatra, V. Leung, M. Chen, and P. Sahu, ‚ÄúEnergy
efÔ¨Åcient cooperative computing in mobile wireless sensor networks,‚Äù
IEEE Trans. Cloud Comput., vol. PP, no. 99, pp. 1‚Äì13, Jul. 2015.
[126] J. Song, Y. Cui, M. Li, J. Qiu, and R. Buyya, ‚ÄúEnergy-trafÔ¨Åc trade-
off cooperative ofÔ¨Çoading for mobile cloud computing,‚Äù in Proc.
IEEE/ACM Int. Symp. Quality of Service (IWQoS), Hong Kong, China,
May 2014, pp. 284‚Äì289.
[127] X. Cao, F. Wang, J. Xu, R. Zhang, and S. Cui, ‚ÄúJoint computation
and communication cooperation for mobile edge computing,‚Äù Apr.
2017. [Online]. Available: https://arxiv.org/pdf/1704.06777.pdf
[128] C. You and K. Huang, ‚ÄúMobile cooperative computing: Energy-efÔ¨Åcient
peer-to-peer
computation
ofÔ¨Çoading,‚Äù
2017.
[Online].
Available:
https://arxiv.org/abs/1704.04595
[129] L. Chen, S. Zhou, and J. Xu, ‚ÄúComputation peer ofÔ¨Çoading for
energy-constrained mobile edge computing in small-cell networks,‚Äù
Mar. 2017. [Online]. Available: https://arxiv.org/pdf/1703.06058.pdf
[130] L. Lei, Z. Zhong, K. Zheng, J. Chen, and H. Meng, ‚ÄúChallenges on
wireless heterogeneous networks for mobile cloud computing,‚Äù IEEE
Wireless Commun., vol. 20, no. 3, pp. 34‚Äì44, 2013.
[131] T. Zhao, S. Zhou, X. Guo, Y. Zhao, and Z. Niu, ‚ÄúA cooperative
scheduling scheme of local cloud and Internet cloud for delay-aware
mobile cloud computing,‚Äù in Proc. IEEE Global Commun. Conf.
Worshops (GC WKSHPS), San Diego, CA, Dec. 2015, pp. 1‚Äì6.
[132] Y. Ge, Y. Zhang, Q. Qiu, and Y.-H. Lu, ‚ÄúA game theoretic resource
allocation for overall energy minimization in mobile cloud computing
system,‚Äù in Proc. ACM/IEEE Int. Symp. Low Power Electron. Design,
Redondo Beach, CA, Jul.-Aug. 2012, pp. 279‚Äì284.
[133] T. Q. Dinh, J. Tang, Q. D. La, and T. Q. Quek, ‚ÄúOfÔ¨Çoading in mobile
edge computing: Task allocation and computational frequency scaling,‚Äù
Commun. ACM, vol. PP, no. 99, pp. 1‚Äì14, Apr. 2017.
[134] R. Kaewpuang, D. Niyato, P. Wang, and E. Hossain, ‚ÄúA framework for
cooperative resource management in mobile cloud computing,‚Äù IEEE
J. Sel. Areas Commun., vol. 31, no. 12, pp. 2685‚Äì2700, Dec. 2013.
[135] R. Yu, J. Ding, S. Maharjan, S. Gjessing, Y. Zhang, and D. Tsang,
‚ÄúDecentralized and optimal resource cooperation in geo-distributed
mobile cloud computing,‚Äù IEEE Trans. Emerg. Topics Comput., vol. PP,
no. 99, pp. 1‚Äì13, Sep. 2015.
[136] M.
S.
Elbamby,
M.
Bennis,
and
W.
Saad,
‚ÄúProactive
edge
computing in latency-constrained fog networks.‚Äù [Online]. Available:
https://arxiv.org/pdf/1704.06749.pdf
[137] S. Wang, R. Urgaonkar, T. He, M. Zafer, K. Chan, and K. K. Leung,
‚ÄúMobility-induced service migration in mobile micro-clouds,‚Äù in Proc.
IEEE Military Commun. Conf. (MILCOM), Baltimore, MD, Oct. 2014,
pp. 835‚Äì840.
[138] R. Urgaonkar, S. Wang, T. He, M. Zafer, K. Chan, and K. K. Leung,
‚ÄúDynamic service migration and workload scheduling in edge-clouds,‚Äù
Performance Evaluation, vol. 91, pp. 205‚Äì228, 2015.
[139] M.-H. Chen, M. Dong, and B. Liang, ‚ÄúJoint ofÔ¨Çoading decision and
resource allocation for mobile cloud with computing access point,‚Äù
in Proc. IEEE Int. Conf. Accoustic, Speech, and Signal Processing
(ICASSP), Shanghai, China, Mar. 2016, pp. 3516‚Äì3520.
[140] O. Munoz, A. P-Iserte, and J. Vidal, ‚ÄúOptimization of radio and
computational resources for energy efÔ¨Åciency in latency-constrained
application ofÔ¨Çoading,‚Äù IEEE Trans. Veh. Techn., vol. 64, no. 10, pp.
497‚Äì508, Oct. 2015.

----- Page 35 (native) -----
35
[141] S. Wang and S. Dey, ‚ÄúModeling and characterizing user experience in
a cloud server based mobile gaming approach,‚Äù in Proc. IEEE Global
Commun. Conf. (GLOBECOM), Honolulu, HI, Nov.-Dec. 2009, pp.
1‚Äì7.
[142] S. Wang, M. Zafer, and K. K. Leung, ‚ÄúOnline placement of multi-
component applications in edge computing environments,‚Äù IEEE Ac-
cess, vol. 5, Feb. 2017.
[143] Y. Shi, J. Zhang, B. O‚ÄôDonoghue, and K. B. Letaief, ‚ÄúLarge-scale
convex optimization for dense wireless cooperative networks,‚Äù IEEE
Trans. Signal Process., vol. 63, no. 18, pp. 4729‚Äì4743, Sep. 2013.
[144] C. Vallati, A. Virdis, E. Mingozzi, and G. Stea, ‚ÄúMobile-edge com-
puting come home connecting things in future smart homes using
LTE device-to-device communications,‚Äù IEEE Consum. Electron. Mag.,
vol. 5, no. 4, pp. 77‚Äì83, Oct. 2016.
[145] T. H. Luan, L. Gao, Z. Li, Y. Xiang, G. Wei, and L. Sun, ‚ÄúFog
computing: Focusing on mobile users at the edge.‚Äù [Online]. Available:
https://arxiv.org/pdf/1502.01815v3.pdf
[146] L. Tong, Y. Li, and W. Gao, ‚ÄúA hierarchical edge cloud architecture
for mobile computing,‚Äù in Proc. IEEE Int. Conf. Comput. Commun.
(INFOCOM), San Francisco, CA, USA, Apr. 2016, pp. 1‚Äì9.
[147] G.
Kirby,
A.
Dearle,
A.
Macdonald,
and
A.
Fernandes,
‚ÄúAn
approach to ad hoc cloud computing.‚Äù [Online]. Available: https:
//arxiv.org/pdf/1002.4738v1.pdf
[148] T. T. Huu, C. K. Tham, and D. Niyato, ‚ÄúA stochastic workload
distribution approach for an ad-hoc mobile cloud,‚Äù in Proc. IEEE Int.
Conf. Cloud Comput. Techn. Sci. (CloudCom), Singapore, Dec. 2014,
pp. 174‚Äì181.
[149] D. M. Shila, W. Shen, Y. Cheng, X. Tian, and X. Shen, ‚ÄúAMCloud:
Toward a secure autonomic mobile ad hoc cloud computing system,‚Äù
IEEE Wireless Commun., vol. PP, no. 99, pp. 1‚Äì8, Oct. 2016.
[150] X. Hou, Y. Li, M. Chen, D. Wu, D. Jin, and S. Chen, ‚ÄúVehicular fog
computing: A viewpoint of vehicles as the infrastructures,‚Äù IEEE Trans.
Veh. Techn., vol. 65, no. 6, pp. 3860‚Äì3873, Jun. 2016.
[151] M.
Haenggi,
J.
G.
Andrews,
F.
Baccelli,
O.
Dousse,
and
M. Franceschetti, ‚ÄúStochastic geometry and random graphs for the
analysis and design of wireless networks,‚Äù IEEE J. Sel. Areas Commun.,
vol. 27, no. 7, pp. 1029‚Äì1046, Sep. 2009.
[152] J. G. Andrews, F. Baccelli, and R. K. Ganti, ‚ÄúA tractable approach to
coverage and rate in cellular networks,‚Äù IEEE Trans. Commun., vol. 59,
no. 11, pp. 3122‚Äì3134, Nov. 2011.
[153] M. Haenggi, Stochastic Geometry for Wireless Networks.
New York,
NY, USA: Cambridge University Press, 2012.
[154] C. Li, J. Zhang, J. G. Andrews, and K. B. Letaief, ‚ÄúSuccess probability
and area spectral efÔ¨Åciency in multiuser MIMO HetNets,‚Äù IEEE Trans.
Commun., vol. 64, no. 4, pp. 1544‚Äì1556, Apr. 2016.
[155] N. Vastardis and K. Yang, ‚ÄúAn enhanced community-based mobility
model for distributed mobile social networks,‚Äù J. Ambient Intelligence
and Humanized Comput., vol. 5, no. 1, pp. 65‚Äì75, Feb. 2014.
[156] CISCO,
‚ÄúCisco
visual
networking
index:
Global
mobile
data
trafÔ¨Åc
forecast
update,
2015-2020,‚Äù
White
paper,
2016.
[Online]. Available: http://www.cisco.com/c/en/us/solutions/collateral/
service-provider/visual-networking-index-vni/vni-forecast-qa.pdf
[157] X. Wang, M. Chen, T. Taleb, A. Ksentini, and V. C. Leung, ‚ÄúCache
in the air: Exploiting content caching and delivery techniques for 5G
systems,‚Äù IEEE Commun. Mag., vol. 52, no. 2, pp. 131‚Äì139, Feb. 2014.
[158] E. Bastug, M. Bennis, and M. Debbah, ‚ÄúLiving on the edge: The role
of proactive caching in 5G wireless networks,‚Äù IEEE Commun. Mag.,
vol. 52, no. 8, pp. 82‚Äì89, Aug. 2014.
[159] N. Golrezaei, K. Shanmugam, A. G. Dimakis, A. F. Molisch, and
G. Caire, ‚ÄúFemtocaching: Wireless video content delivery through
distributed caching helpers,‚Äù in Proc. IEEE Int. Conf. Compt. Commun.
(INFOCOM), Orlando, FL, Mar. 2012, pp. 1107‚Äì1115.
[160] A. S. Gomes, B. Sousa, D. Palma, V. Fonseca, Z. Zhao, E. Monteiro,
T. Braun, P. Simoes, and L. Cordeiro, ‚ÄúEdge caching with mobility
prediction in virtualized LTE mobile networks,‚Äù Future Generation
Comput. Syst., vol. 70, pp. 148‚Äì162, 2017.
[161] L. Yang, J. Cao, G. Liang, and X. Han, ‚ÄúCost aware service placement
and load dispatching in mobile cloud systems,‚Äù IEEE Trans. Comput.,
vol. 65, no. 5, pp. 1440‚Äì1452, May 2016.
[162] J. Tordsson, R. S. Montero, R. Moreno-Vozmediano, and I. M. Llorente,
‚ÄúCloud brokering mechanisms for optimized placement of virtual
machines across multiple providers,‚Äù Future Generation Comput. Syst.,
vol. 28, no. 2, pp. 358‚Äì367, Feb. 2012.
[163] B. Li, J. Li, J. Huai, T. Wo, Q. Li, and L. Zhong, ‚ÄúEnaCloud: An
energy-saving application live placement approach for cloud computing
environments,‚Äù in Proc. IEEE Int. Conf. Cloud Comput. (CLOUD),
Bangalore, India, Sep. 2009, pp. 17‚Äì24.
[164] Y. Gao, H. Guan, Z. Qi, Y. Hou, and L. Liu, ‚ÄúA multi-objective
ant colony system algorithm for virtual machine placement in cloud
computing,‚Äù J. Comput. Syst. Sci., vol. 79, no. 8, pp. 1230‚Äì1242, Dec.
2013.
[165] J. L. Lucas-Simarro, R. Moreno-Vozmediano, R. S. Montero, and I. M.
Llorente, ‚ÄúScheduling strategies for optimal service deployment across
multiple clouds,‚Äù Future Generation Comput. Syst., vol. 29, no. 6, pp.
1431‚Äì1441, Aug. 2013.
[166] H. Rheingold, Virtual Reality: Exploring the Brave New Technologies.
New York, NY, USA: Simon & Schuster Adult Publishing Group, 1991.
[167] S. Wang and S. Dey, ‚ÄúModeling and characterizing user experience in
a cloud server based mobile gaming approach,‚Äù in Proc. IEEE Global
Commun. Conf. (GLOBECOM), Honolulu, HI, Nov. 2009, pp. 1‚Äì7.
[168] T. X. Tran, P. Pandey, A. Hajisami, and D. Pompili, ‚ÄúCollaborative
multi-bitrate video caching and processing in mobile-edge computing
networks,‚Äù in Proc. IEEE/IFIP Conf. Wireless On-demand Network
Systems and Services (WONS), Jackson Hole, WY, USA, Feb. 2017,
pp. 1‚Äì8. [Online]. Available: https://arxiv.org/pdf/1612.01436v2.pdf
[169] E. Bas¬∏tuÀág, M. Bennis, M. Kountouris, and M. Debbah, ‚ÄúCache-enabled
small cell networks: Modeling and tradeoffs,‚Äù EURASIP J. Wireless
Commun. Networking, vol. 2015, no. 1, pp. 1‚Äì11, Feb. 2015.
[170] Y. Cui, Y. Wu, and D. Jiang, ‚ÄúAnalysis and optimization of caching
and multicasting in large-scale cache-enabled information-centric net-
works,‚Äù in Proc. IEEE Global Commun. Conf. (GLOBECOM), San
Diego, CA, Dec. 2015, pp. 1‚Äì7.
[171] V. Suryaprakash, J. M√∏ller, and G. Fettweis, ‚ÄúOn the modeling and
analysis of heterogeneous radio access networks using a poisson cluster
process,‚Äù IEEE Trans. Wireless Commun., vol. 14, no. 2, pp. 1035‚Äì
1047, Feb. 2015.
[172] D. Lopez-Perez, I. Guvenc, and X. Chu, ‚ÄúMobility management
challenges in 3GPP heterogeneous networks,‚Äù IEEE Commun. Mag.,
vol. 50, no. 12, pp. 70‚Äì78, 2012.
[173] A. Damnjanovic, J. Montojo, Y. Wei, T. Ji, T. Luo, M. Vajapeyam,
T. Yoo, O. Song, and D. Malladi, ‚ÄúA survey on 3GPP heterogeneous
networks,‚Äù IEEE Wireless Commun., vol. 18, no. 3, pp. 10‚Äì21, Mar.
2011.
[174] M. Kassar, B. Kervella, and G. Pujolle, ‚ÄúAn overview of vertical
handover decision strategies in heterogeneous wireless networks,‚Äù
ELSEVIER Comput. Commun., vol. 31, no. 10, pp. 2607‚Äì2620, Oct.
2008.
[175] C. Wang, Y. Li, and D. Jin, ‚ÄúMobility-assisted opportunistic computa-
tion ofÔ¨Çoading,‚Äù IEEE Commun. Lett., vol. 18, no. 10, pp. 1779‚Äì1782,
Oct. 2014.
[176] Y. Zhang, D. Niyato, and P. Wang, ‚ÄúOfÔ¨Çoading in mobile cloudlet
systems with intermittent connectivity,‚Äù IEEE Trans. Mobile Comput.,
vol. 14, no. 12, pp. 2516‚Äì2529, Dec. 2015.
[177] K. Lee and I. Shin, ‚ÄúUser mobility model based computation ofÔ¨Çoading
decision for mobile cloud,‚Äù J. Comput. Sci. Eng., vol. 9, no. 3, pp. 155‚Äì
162, Sep. 2015.
[178] M. R. Rahimi, N. Venkatasubramanian, and A. V. Vasilakos, ‚ÄúMusic:
Mobility-aware optimal service allocation in mobile cloud computing,‚Äù
in Proc. IEEE Int. Conf. Cloud Comput. (CLOUD), Santa Clara
Marriott, CA, Jun. 2013, pp. 75‚Äì82.
[179] A. Prasad, P. Lund¬¥en, M. Moisio, M. A. Uusitalo, and Z. Li, ‚ÄúEfÔ¨Åcient
mobility and trafÔ¨Åc management for delay tolerant cloud data in 5G
networks networks,‚Äù in Proc. IEEE Int. Symp. on Personal Indoor and
Mobile Radio Comm. (PIMRC), 2015, pp. 1740‚Äì1745.
[180] R. Wang, X. Peng, J. Zhang, and K. B. Letaief, ‚ÄúMobility-aware
caching for content-centric wireless networks: Modeling and method-
ology,‚Äù IEEE Commun. Mag., vol. 54, no. 8, pp. 77‚Äì83, Aug. 2016.
[181] S.-W. Ko, K. Huang, S.-L. Kim, and H. Chae, ‚ÄúOnline prefetching
for
mobile
computation
ofÔ¨Çoading,‚Äù
2016.
[Online].
Available:
https://arxiv.org/abs/1608.04878
[182] K. Doppler, M. Rinne, C. Wijting, C. B. Ribeiro, and K. Hugl, ‚ÄúDevice-
to-device communication as an underlay to LTE-advanced networks,‚Äù
IEEE Commun. Mag., vol. 47, no. 12, pp. 42‚Äì49, Dec 2009.
[183] C.-A. Chen, M. Won, R. Stoleru, and G. G. Xie, ‚ÄúEnergy-efÔ¨Åcient fault-
tolerant data storage and processing in mobile cloud,‚Äù IEEE Trans.
Cloud Comput., vol. 3, no. 1, pp. 28‚Äì41, Jan. 2015.
[184] C. A. Chen, R. Stoleru, and G. G. Xie, ‚ÄúEnergy-efÔ¨Åcient and fault-
tolerant mobile cloud storage,‚Äù in Proc. IEEE Int. Conf. Could Net-
working (Cloudnet), Pisa, Italy, Oct. 2016, pp. 51‚Äì57.
[185] D. Satria, D. Park, and M. Jo, ‚ÄúRecovery for overloaded mobile edge
computing,‚Äù Future Generation Comput. Syst., vol. 70, pp. 138‚Äì147,
2017.

----- Page 36 (native) -----
36
[186] S. Chaisiri, B.-S. Lee, and D. Niyato, ‚ÄúOptimization of resource
provisioning cost in cloud computing,‚Äù IEEE Trans. Serv. Comput.,
vol. 5, no. 2, pp. 164‚Äì177, Apr. 2012.
[187] Y. Zhang, J. Yan, and X. Fu, ‚ÄúReservation-based resource scheduling
and code partition in mobile cloud computing,‚Äù in Proc. IEEE Int. Conf.
Compt. Commun. Workshops (INFOCOM WKSHPS), San Francisco,
CA, Apr. 2016, pp. 962‚Äì967.
[188] X. Jin, F. Zhang, A. V. Vasilakos, and Z. Liu, ‚ÄúGreen data centers:
A survey, perspectives, and future directions.‚Äù [Online]. Available:
http://arxiv.org/abs/1608.00687
[189] X. Sun and N. Ansari, ‚ÄúGreen cloudlet network: A distributed green
mobile cloud network,‚Äù IEEE Netw., to appear.
[190] L. A. Barroso and U. Holzle, ‚ÄúThe case for energy-proportional
computing,‚Äù Comput., vol. 40, no. 12, pp. 651‚Äì664, Dec 2007.
[191] M. Lin, A. Wierman, L. L. H. Andrew, and E. Thereska, ‚ÄúDynamic
right-sizing for power-proportional data centers,‚Äù IEEE/ACM Trans.
Netw., vol. 21, no. 5, pp. 1378‚Äì1391, Oct. 2013.
[192] M. Lin, Z. Liu, A. Wierman, and L. L. H. Andrew, ‚ÄúOnline algorithms
for geographical load balancing,‚Äù in Proc. IEEE Int. Green Comput.
Conf. (IGCC), San Jose, CA, Jun 2012, pp. 1‚Äì10.
[193] H. Xu, C. Feng, and B. Li, ‚ÄúTemperature aware workload management
in geo-distributed data centers,‚Äù IEEE Trans. Parallel Distrib. Syst.,
vol. 26, no. 6, pp. 1743‚Äì1753, Jun. 2015.
[194] A. Beloglazov and R. Buyya, ‚ÄúEnergy efÔ¨Åcient resource management in
virtualized cloud data centers,‚Äù in Proc. IEEE/ACM Int. Conf. Cluster,
Cloud and Grid Computing (CCGrid), Melbourne, Australia, May
2010, pp. 826‚Äì831.
[195] X. Li, J. Wu, S. Tang, and S. Lu, ‚ÄúLet‚Äôs stay together: Towards trafÔ¨Åc
aware virtual machine placement in data centers,‚Äù in Proc. IEEE Int.
Conf. Comput. Commun. (INFOCOM), Toronto, Canada, Apr. 2014,
pp. 1842‚Äì1850.
[196] L. Chen and H. Shen, ‚ÄúConsolidating complementary VMs with
spatial/temporal-awareness in cloud datacenters,‚Äù in Proc. IEEE Int.
Conf. Comput. Commun. (INFOCOM), Apr. 2014, pp. 1033‚Äì1041.
[197] Z. Han, H. Tan, G. Chen, R. Wang, Y. Chen, and F. C. M. Lau, ‚ÄúDy-
namic virtual machine management via approximate Markov decision
process,‚Äù in Proc. IEEE Int. Conf. Comput. Commun. (INFOCOM),
San Francisco, CA, Apr. 2016, pp. 1‚Äì9.
[198] S. Sudevalayam and P. Kulkarni, ‚ÄúEnergy harvesting sensor nodes:
Survey and implications,‚Äù IEEE Commun. Surveys Tuts., vol. 13, no. 3,
pp. 443‚Äì461, 3rd Quater 2011.
[199] S. Ulukus, A. Yener, E. Erkip, O. Simeone, M. Zorzi, P. Grover, and
K. Huang, ‚ÄúEnergy harvesting wireless communications: A review of
recent advances,‚Äù IEEE J. Sel. Areas Commun., vol. 33, no. 3, pp.
360‚Äì381, Mar. 2015.
[200] Y. Mao, Y. Luo, J. Zhang, and K. B. Letaief, ‚ÄúEnergy harvesting small
cell networks: Feasibility, deployment, and operation,‚Äù IEEE Commun.
Mag., vol. 53, no. 6, pp. 94‚Äì101, Jun 2015.
[201] CNN, ‚ÄúBattery life concerns mobile users,‚Äù Sep. 2005. [Online]. Avail-
able: http://edition.cnn.com/2005/TECH/ptech/09/22/phone.study/
[202] J. Xu and S. Ren, ‚ÄúOnline learning for ofÔ¨Çoading and autoscaling in
renewable-powered mobile edge computing,‚Äù in Proc. IEEE Global
Commun. Conf. (GLOBECOM), Washington, DC, Dec. 2016, pp. 1‚Äì6.
[203] Y. Mao, J. Zhang, and K. B. Letaief, ‚ÄúDynamic computation ofÔ¨Çoading
for mobile-edge computing with energy harvesting devices,‚Äù IEEE J.
Sel. Areas Commun., vol. 34, no. 12, pp. 3590‚Äì3605, Dec. 2016.
[204] C. Chen, B. He, and X. Tang, ‚ÄúGreen-aware workload scheduling in
geographically distributed data centers,‚Äù in Proc. IEEE Int. Conf. Cloud
Comput. Tech. Sci. (CloudCom), Taipei, Taiwan, Nov. 2012, pp. 82‚Äì89.
[205] C. Dong, F. Kong, X. Liu, and H. Zeng, ‚ÄúGreen power analysis for
geographical load balancing based datacenters,‚Äù in Proc. IEEE Int.
Green Comput. Conf. (IGCC), Arlington, VA, Jun. 2013, pp. 1‚Äì8.
[206] X. Sun, N. Ansari, and Q. Fan, ‚ÄúGreen energy aware avatar migration
strategy in green cloudlet networks,‚Äù in Proc. IEEE Int. Conf. Cloud
Comput. Tech. Sci. (CloudCom), Vancouver, Canada, Nov. 2015, pp.
139‚Äì146.
[207] T. Chen, Y. Zhang, X. Wang, and G. B. Giannakis, ‚ÄúRobust workload
and energy management for sustainable data centers,‚Äù IEEE J. Sel.
Areas Commun., vol. 34, no. 3, pp. 651‚Äì664, Mar. 2016.
[208] Y. Luo, J. Zhang, and K. B. Letaief, ‚ÄúTransmit power minimization
for wireless networks with energy harvesting relays,‚Äù IEEE Trans.
Commun., vol. 64, no. 3, pp. 987‚Äì1000, Mar. 2016.
[209] J. Gong, S. Zhou, and Z. Niu, ‚ÄúOptimal power allocation for energy
harvesting and power grid coexisting wireless communication systems,‚Äù
IEEE Trans. Commun., vol. 61, no. 7, pp. 3040 ‚Äì 3049, Jul. 2013.
[210] T. Han and N. Ansari, ‚ÄúOn optimizing green energy utilization for
cellular networks with hybrid energy supplies,‚Äù IEEE Trans. Wireless
Commun., vol. 12, no. 8, pp. 3872‚Äì3882, 2013.
[211] Y. Mao, J. Zhang, and K. B. Letaief, ‚ÄúGrid energy consumption and
QoS tradeoff in hybrid energy supply wireless networks,‚Äù IEEE Trans.
Wireless Commun., vol. 15, no. 5, pp. 3573 ‚Äì 3586, May 2016.
[212] W. C. Brown, ‚ÄúThe history of power transmission by radio waves,‚Äù
IEEE Trans. Microw. Theory Techn., vol. 32, no. 9, pp. 1230‚Äì1242,
Sep. 1984.
[213] H. Ju and R. Zhang, ‚ÄúThroughput maximization in wireless powered
communication networks,‚Äù IEEE Trans. Wireless Commun., vol. 13,
no. 1, pp. 418‚Äì428, Jan. 2014.
[214] K. Huang and V. K. N. Lau, ‚ÄúEnabling wireless power transfer
in cellular networks: Architecture, modeling and deployment,‚Äù IEEE
Trans. Wireless Commun., vol. 13, no. 2, pp. 902‚Äì912, May 2014.
[215] Z. Chang, J. Gong, Y. Li, Z. Zhou, T. Ristaniemi, G. Shi, Z. Han, and
Z. Niu, ‚ÄúEnergy efÔ¨Åcient resource allocation for wireless power transfer
enabled collaborative mobile clouds,‚Äù IEEE J. Sel. Areas Commun.,
vol. 34, no. 12, pp. 3438‚Äì3450, Dec. 2016.
[216] R. Roman, J. Lopez, and M. Mambo, ‚ÄúMobile edge computing, fog et
al.: A survey and analysis of security threats and challenges,‚Äù Elsevier
Future Generation Comput. Syst., vol. PP, no. 99, Nov. 2016.
[217] S. Yi, Z. Qin, and Q. Li, ‚ÄúSecurity and privacy issues of fog computing:
A survey,‚Äù in Proc. Int. Conf. Wireless Algorithms, Systems, and
Applications (WASA), Qufu, China, Aug. 2015, pp. 1‚Äì10.
[218] M. M. Fouda, Z. M. Fadlullah, N. Kato, R. Lu, and X. S. Shen, ‚ÄúA
lightweight message authentication scheme for smart grid communi-
cations,‚Äù IEEE Trans. Smart Grid, vol. 2, no. 4, pp. 675‚Äì685, Dec.
2011.
[219] A. M. Y. Ahmed and D. Qian, ‚ÄúAn optimization of security and
trust management in distributed systems,‚Äù in Proc. IEEE Int. Advance
Computing Conf. (IACC), Ghaziabad, India, Feb. 2013, pp. 120‚Äì126.
[220] X. Huang, Y. Xiang, E. Bertino, J. Zhou, and L. Xu, ‚ÄúRobust multi-
factor authentication for fragile communications,‚Äù IEEE Trans. De-
pendable Secure Comput., vol. 11, no. 6, pp. 568‚Äì581, Nov.-Dec. 2014.
[221] M. C. Gorantla, C. Boyd, and J. M. G. Nieto, ‚ÄúAttribute-based
authenticated key exchange,‚Äù in Proc. Australian Conf. Info. Security
and Privacy (ACISP), Sydney, Australia, Jul. 2010, pp. 1‚Äì25.
[222] H. M. Pimentel, S. Kopp, M. A. S. Jr., R. M. Silveira, and G. Bressan,
‚ÄúOCP: A protocol for secure communication in federated content
networks,‚Äù Compt. Commun., vol. 68, pp. 47‚Äì60, Sep. 2015.
[223] M. Liyanage, A. B. Abro, M. Ylianttila, and A. Gurtov, ‚ÄúOpportuni-
ties and challenges of software-deÔ¨Åned mobile networks in network
security,‚Äù IEEE Security Privacy, vol. 14, no. 4, pp. 34‚Äì44, Jul. 2016.
[224] W. Yang and C. Fung, ‚ÄúA survey on security in network functions
virtualization,‚Äù in Proc. IEEE NetSoft Conf. Workshops (NetSoft),
Seoul, Korea, Jun. 2016, pp. 15‚Äì19.
[225] B. Liang, ‚ÄúMobile edge computing,‚Äù in Key Technologies for 5G
Wireless Systems, V. W. S. Wong, R. Schober, D. W. K. Ng, and
L.-C. Wang, Eds.
Cambridge University Press, 2017. [Online].
Available: http://www.comm.utoronto.ca/‚àºliang/publications/Chapter
MEC 2016.pdf
[226] Alcatel-Lucent, ‚ÄúProviding security in NFV: Challenges and opportu-
nities.‚Äù [Online]. Available: http://www.tmcnet.com/tmc/whitepapers/
documents/whitepapers/2014/10172-providing-security-nfv.pdf
[227] C. Wang, K. Ren, and J. Wang, ‚ÄúSecure optimization computation
outsourcing in cloud computing: A case study of linear programming,‚Äù
IEEE Trans. Comput., vol. 65, no. 1, pp. 216‚Äì229, Jan. 2016.
[228] R. Gennaro, G. Craig, and P. Bryan, ‚ÄúNon-interactive veriÔ¨Åable com-
puting: Outsourcing computation to untrusted workers,‚Äù in Annu. Conf.
Adv. Cryptol., Santa Barbara, CA, USA, Aug. 2010, pp. 465‚Äì482.
[229] ETSI, ‚ÄúExecutive brieÔ¨Ång - mobile edge computing (MEC) initiative.‚Äù
[Online]. Available: https://portal.etsi.org/portals/0/tbpages/mec/docs/
mec%20executive%20brief%20v1%2028-09-14.pdf
[230] ‚Äî‚Äî,
‚ÄúMobile-edge
computing
(MEC):
Terminology.‚Äù
[Online].
Available:
http://www.etsi.org/deliver/etsi gs/MEC/001 099/001/01.
01.01 60/gs MEC001v010101p.pdf
[231] ‚Äî‚Äî, ‚ÄúMobile-edge computing (MEC): Framework and reference
architecture.‚Äù [Online]. Available: http://www.etsi.org/deliver/etsi gs/
MEC/001 099/003/01.01.01 60/gs MEC003v010101p.pdf
[232] ‚Äî‚Äî,
‚ÄúMobile-edge
computing
(MEC):
Service
scenarios.‚Äù
[Online]. Available: http://www.etsi.org/deliver/etsi gs/MEC/001 099/
002/01.01.01 60/gs MEC002v010101p.pdf
[233] S. Antipolis, ‚ÄúETSI Ô¨Årst mobile edge computing proof of concepts at
MEC World Congress,‚Äù Sep. 2016.

----- Page 37 (native) -----
37
[234] N.
Sprecher,
J.
Friis,
R.
Dolby,
and
J.
Reister,
‚ÄúEdge
computing
prepares
for
a
multi-access
future,‚Äù
Sep.
2016.
[Online].
Available:
http://www.telecomtv.com/articles/mec/
edge-computing-prepares-for-a-multi-access-future-13986/
[235] 3GPP,
‚ÄúTechnical
speciÔ¨Åcation
group
services
and
system
aspects;
system
architecture
for
the
5g
systems;
stage
2
(release
15),‚Äù
3GPP
TS
23.501
V0.4.0,
Apr.
2017.
[On-
line]. Available: https://portal.3gpp.org/desktopmodules/SpeciÔ¨Åcations/
SpeciÔ¨ÅcationDetails.aspx?speciÔ¨ÅcationId=3144
[236] A. Anjum, T. Abdullah, M. Tariq, Y. Baltaci, and N. Antonopoulos,
‚ÄúVideo stream analysis in clouds: An object detection and classiÔ¨Åcation
framework for high performance video analytics,‚Äù IEEE Trans. Cloud
Comput., vol. PP, no. 99, pp. 1‚Äì1, Jan. 2016.
[237] Intel,
‚ÄúIntel
mobile
edge
computing
technology
improves
the
augmented
reality
experience,‚Äù
Sep.
2016.
[Online].
Available:
https://www.youtube.com
[238] P. Papadimitratos, A. L. Fortelle, K. Evenssen, R. Brignolo, and
S. Cosenza, ‚ÄúVehicular communication systems: Enabling technologies,
applications, and future outlook on intelligent transportation,‚Äù IEEE
Commun. Mag., vol. 47, no. 11, pp. 84‚Äì95, Nov. 2009.
[239] N. Lu, N.Cheng, N. Zhang, X. Shen, and J. W. Mark, ‚ÄúConnected
vehicles: Solutions and challenges,‚Äù IEEE Internet Things J., vol. 1,
no. 4, pp. 289‚Äì299, Apr. 2015.
[240] E. Uhlemann, ‚ÄúIntroducing connected vehicles,‚Äù IEEE Veh. Techn.
Mag., vol. 10, no. 1, pp. 23‚Äì31, Jan. 2015.
[241] NOKIA,
‚ÄúUTM
infrastructure
and
connected
society,‚Äù
2016.
[Online]. Available: http://rpas-civops.com/wp-content/uploads/2016/
11/S7.2 Nokia DE V1.pdf
[242] Saguna,
‚ÄúExecutive
brieÔ¨Ång
-
mobile
edge
computing
(MEC)
initiative.‚Äù
[Online].
Available:
http://www.saguna.net/site/assets/
Ô¨Åles/1723/saguna intel mec wp.pdf?utm source=homepage?utm
medium=button3?utm campaign=Q1-2016
[243] Ericsson,
‚ÄúPolicy
control
function
in
5G,‚Äù
Jan.
2017.
[Online]. Available: http://portal.3gpp.org/ngppapp/CreateTdoc.aspx?
mode=view&contributionId=756820#
[244] N. Alliance, ‚ÄúDescription of network slicing concept,‚Äù Jan. 2016.
[Online].
Available:
https://www.ngmn.org/uploads/media/160113
Network Slicing v1 0.pdf
[245] A. Nakao, ‚ÄúNetwork softwarization and slicing: Ongoing developments
in standard developing organizations,‚Äù Oct.-Nov. 2016. [Online].
Available: http://cscn2016.ieee-cscn.org/document.pdf