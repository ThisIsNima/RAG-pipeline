

----- Page 1 (native) -----
Journal
of
Articial
In
telligence
Researc
h

(			)
	-0
Submitted
/	;
published
/		
Seman
tic
Similari
t
y
in
a
T
axonom
y:
An
Information-Based
Measure
and
its
Application
to
Problems
of
Am
biguit
y
in
Natural
Language
Philip
Resnik
resnik@umia
cs.umd.edu
Dep
artment
of
Linguistics
and
Institute
for
A
dvanc
e
d
Computer
Studies
University
of
Maryland
Col
le
ge
Park,
MD
0
USA
Abstract
This
article
presen
ts
a
measure
of
seman
tic
similarit
y
in
an
is-a
taxonom
y
based
on
the
notion
of
shared
information
con
ten
t.
Exp
erimen
tal
ev
aluation
against
a
b
enc
hmark
set
of
h
uman
similarit
y
judgmen
ts
demonstrates
that
the
measure
p
erforms
b
etter
than
the
traditional
edge-coun
ting
approac
h.
The
article
presen
ts
algorithms
that
tak
e
adv
an-
tage
of
taxonomic
similarit
y
in
resolving
syn
tactic
and
seman
tic
am
biguit
y
,
along
with
exp
erimen
tal
results
demonstrating
their
eectiv
eness.
.
In
tro
duction
Ev
aluating
seman
tic
relatedness
using
net
w
ork
represen
tations
is
a
problem
with
a
long
history
in
articial
in
telligence
and
psyc
hology
,
dating
bac
k
to
the
spreading
activ
ation
approac
h
of
Quillian
(	)
and
Collins
and
Loftus
(	).
Seman
tic
similarit
y
represen
ts
a
sp
ecial
case
of
seman
tic
relatedness:
for
example,
cars
and
gasoline
w
ould
seem
to
b
e
more
closely
related
than,
sa
y
,
cars
and
bicycles,
but
the
latter
pair
are
certainly
more
similar.
Rada
et
al.
(Rada,
Mili,
Bic
knell,
&
Blettner,
		)
suggest
that
the
assessmen
t
of
similarit
y
in
seman
tic
net
w
orks
can
in
fact
b
e
though
t
of
as
in
v
olving
just
taxonomic
(is-a)
links,
to
the
exclusion
of
other
link
t
yp
es;
that
view
will
also
b
e
tak
en
here,
although
admittedly
links
suc
h
as
p
ar
t-of
can
also
b
e
view
ed
as
attributes
that
con
tribute
to
similarit
y
(cf.
Ric
hardson,
Smeaton,
&
Murph
y
,
		;
Sussna,
		).
Although
man
y
measures
of
similarit
y
are
dened
in
the
literature,
they
are
seldom
accompanied
b
y
an
indep
enden
t
c
haracterization
of
the
phenomenon
they
are
measuring,
particularly
when
the
measure
is
prop
osed
in
service
of
a
computational
application
(e.g.,
similarit
y
of
do
cumen
ts
in
information
retriev
al,
similarit
y
of
cases
in
case-based
reasoning).
Rather,
the
w
orth
of
a
similarit
y
measure
is
in
its
utilit
y
for
the
giv
en
task.
In
the
cognitiv
e
domain,
similarit
y
is
treated
as
a
prop
ert
y
c
haracterized
b
y
h
uman
p
erception
and
in
tuition,
in
m
uc
h
the
same
w
a
y
as
notions
lik
e
\plausibili
t
y"
and
\t
ypicalit
y
."
As
suc
h,
the
w
orth
of
a
similarit
y
measure
is
in
its
delit
y
to
h
uman
b
eha
vior,
as
measured
b
y
predictions
of
h
uman
p
erformance
on
exp
erimen
tal
tasks.
The
latter
view
underlies
the
w
ork
in
this
article,
although
the
results
presen
ted
comprise
not
only
direct
comparison
with
h
uman
p
erformance
but
also
practical
application
to
problems
in
natural
language
pro
cessing.
A
natural,
time-honored
w
a
y
to
ev
aluate
seman
tic
similarit
y
in
a
taxonom
y
is
to
measure
the
distance
b
et
w
een
the
no
des
corresp
onding
to
the
items
b
eing
compared
|
the
shorter
c
			
AI
Access
F
oundation
and
Morgan
Kaufmann
Publishers.
All
righ
ts
reserv
ed.

----- Page 2 (native) -----
Resnik
the
path
from
one
no
de
to
another,
the
more
similar
they
are.
Giv
en
m
ultiple
paths,
one
tak
es
the
length
of
the
shortest
one
(Lee,
Kim,
&
Lee,
		;
Rada
&
Bic
knell,
		;
Rada
et
al.,
		).
A
widely
ac
kno
wledged
problem
with
this
approac
h,
ho
w
ev
er,
is
that
it
relies
on
the
notion
that
links
in
the
taxonom
y
represen
t
uniform
distances.
Unfortunately
,
uniform
link
distance
is
dicult
to
dene,
m
uc
h
less
to
con
trol.
In
real
taxonomies,
there
is
wide
v
ariabilit
y
in
the
\distance"
co
v
ered
b
y
a
single
taxonomic
link,
particularly
when
certain
sub-taxonomies
(e.g.,
biological
categories)
are
m
uc
h
denser
than
others.
F
or
example,
in
W
ordNet
(Miller,
		0;
F
ellbaum,
		),
a
widely
used,
broad-co
v
erage
seman
tic
net
w
ork
for
English,
it
is
not
at
all
dicult
to
nd
links
that
co
v
er
an
in
tuitiv
ely
narro
w
distance
(rabbit
ears
is-a
television
antenna)
or
an
in
tuitiv
ely
wide
one
(phytoplankton
is-a
living
thing).
The
same
kinds
of
examples
can
b
e
found
in
the
Collins
COBUILD
Dictionary
(Sinclair,
ed.,
	),
whic
h
iden
ties
sup
erordinate
terms
for
man
y
w
ords
(e.g.,
safety
v
al
ve
is-a
v
al
ve
seems
m
uc
h
narro
w
er
than
knitting
ma
chine
is-a
ma
chine).
In
the
rst
part
of
this
article,
I
describ
e
an
alternativ
e
w
a
y
to
ev
aluate
seman
tic
sim-
ilarit
y
in
a
taxonom
y
,
based
on
the
notion
of
information
con
ten
t.
Lik
e
the
edge-coun
ting
metho
d,
it
is
conceptually
quite
simple.
Ho
w
ev
er,
it
is
not
sensitiv
e
to
the
problem
of
v
arying
link
distances.
In
addition,
b
y
com
bining
a
taxonomic
structure
with
empirical
probabilit
y
estimates,
it
pro
vides
a
w
a
y
of
adapting
a
static
kno
wledge
structure
to
m
ul-
tiple
con
texts.
Section

sets
up
the
probabilistic
framew
ork
and
denes
the
measure
of
seman
tic
similarit
y
in
information-theoretic
terms,
and
Section

presen
ts
an
ev
aluation
of
the
similarit
y
measure
against
h
uman
similarit
y
judgmen
ts,
using
the
simple
edge-coun
ting
metho
d
as
a
baseline.
In
the
second
part
of
the
article,
Sections

and
,
I
describ
e
t
w
o
applications
of
seman
tic
similarit
y
to
problems
of
am
biguit
y
in
natural
language.
The
rst
concerns
a
particular
case
of
syn
tactic
am
biguit
y
that
in
v
olv
es
b
oth
co
ordination
and
nominal
comp
ounds,
eac
h
of
whic
h
is
a
p
ernicious
source
of
structural
am
biguit
y
in
English.
Consider
the
phrase
fo
o
d
hand
ling
and
stor
age
pr
o
c
e
dur
es:
do
es
it
represen
t
a
conjunction
of
fo
o
d
hand
ling
and
stor
age
pr
o
c
e
dur
es,
or
do
es
it
refer
to
the
hand
ling
and
stor
age
of
fo
o
d?
The
second
application
concerns
the
resolution
of
w
ord
sense
am
biguit
y
|
not
for
w
ords
in
running
text,
whic
h
is
a
large
op
en
problem
(though
cf.
Wilks
&
Stev
enson,
		),
but
for
groups
of
related
w
ords
as
are
often
disco
v
ered
b
y
distributional
analysis
of
text
corp
ora
or
found
in
dictionaries
and
thesauri.
Finally
,
Section

discusses
related
w
ork.
.
Similarit
y
and
Information
Con
ten
t
Let
C
b
e
the
set
of
concepts
in
an
is-a
taxonom
y
,
p
ermitting
m
ultiple
inheritance.
In
tuitiv
ely
,
one
k
ey
to
the
similarit
y
of
t
w
o
concepts
is
the
exten
t
to
whic
h
they
share
information,
in-
dicated
in
an
is-a
taxonom
y
b
y
a
highly
sp
ecic
concept
that
subsumes
them
b
oth.
The
edge-coun
ting
metho
d
captures
this
indirectly
,
since
if
the
minimal
path
of
is-a
links
b
e-
t
w
een
t
w
o
no
des
is
long,
that
means
it
is
necessary
to
go
high
in
the
taxonom
y
,
to
more
abstract
concepts,
in
order
to
nd
a
least
upp
er
b
ound.
F
or
example,
in
W
ordNet,
nickel
and
dime
are
b
oth
subsumed
b
y
coin,
whereas
the
most
sp
ecic
sup
erclass
that
nickel
and
credit
card
share
is
medium
of
ex
change
(see
Figure
).
In
a
feature-based
setting
(e.g.,
Tv
ersky
,
	),
this
w
ould
b
e
reected
b
y
explicit
shared
features:
nic
k
els
and
dimes
	

----- Page 3 (native) -----
Inf
orma
tion-Based
Semantic
Similarity
COIN
CASH
MONEY
NICKEL
DIME
MEDIUM OF EXCHANGE
CREDIT CARD
CREDIT
Figure
:
F
ragmen
t
of
the
W
ordNet
taxonom
y
.
Solid
lines
represen
t
is-a
links;
dashed
lines
indicate
that
some
in
terv
ening
no
des
w
ere
omitted
to
sa
v
e
space.
are
b
oth
small,
round,
metallic,
and
so
on.
These
features
are
captured
implicitly
b
y
the
taxonom
y
in
categorizing
nickel
and
dime
as
sub
ordinates
of
coin.
By
asso
ciating
probabilities
with
concepts
in
the
taxonom
y
,
it
is
p
ossible
to
capture
the
same
idea
as
edge-coun
ting,
but
a
v
oiding
the
unreliabili
t
y
of
edge
distances.
Let
the
taxonom
y
b
e
augmen
ted
with
a
function
p
:
C
!
[0;
],
suc
h
that
for
an
y
c

C
,
p(c)
is
the
probabilit
y
of
encoun
tering
an
instance
of
concept
c.
This
implies
that
p
is
monotonically
nondecreasing
as
one
mo
v
es
up
the
taxonom
y:
if
c

is-a
c

,
then
p(c

)

p(c

).
Moreo
v
er,
if
the
taxonom
y
has
a
unique
top
no
de
then
its
probabilit
y
is
.
F
ollo
wing
the
standard
argumen
tation
of
information
theory
(Ross,
	),
the
infor-
mation
c
ontent
of
a
concept
c
can
b
e
quan
tied
as
negativ
e
the
log
lik
eliho
o
d,
 log
p(c).
Notice
that
quan
tifying
information
con
ten
t
in
this
w
a
y
mak
es
in
tuitiv
e
sense
in
this
set-
ting:
as
probabilit
y
increases,
informativ
eness
decreases;
so
the
more
abstract
a
concept,
the
lo
w
er
its
information
con
ten
t.
Moreo
v
er,
if
there
is
a
unique
top
concept,
its
information
con
ten
t
is
0.
This
quan
titativ
e
c
haracterization
of
information
pro
vides
a
new
w
a
y
to
measure
seman-
tic
similarit
y
.
The
more
information
t
w
o
concepts
share,
the
more
similar
they
are,
and
the
information
shared
b
y
t
w
o
concepts
is
indicated
b
y
the
information
con
ten
t
of
the
concepts
that
subsume
them
in
the
taxonom
y
.
F
ormally
,
dene
sim
(c

;
c

)
=
max
c

S
(c

;
c

)
[ log
p(c)]
;
()
where
S
(c

;
c

)
is
the
set
of
concepts
that
subsume
b
oth
c

and
c

.
A
class
that
ac
hiev
es
the
maxim
um
v
alue
in
Equation

will
b
e
termed
a
most
informative
subsumer;
most
often
there
is
a
unique
most
informativ
e
subsumer,
although
this
need
not
b
e
true
in
the
general
case.
T
aking
the
maxim
um
with
resp
ect
to
information
con
ten
t
is
analogous
to
taking
the
rst
in
tersection
in
seman
tic
net
w
ork
mark
er-passing
or
the
shortest
path
with
resp
ect
to
edge
distance
(cf.
Quillian,
	;
Rada
et
al.,
		);
a
generalization
from
taking
the
maxim
um
to
taking
a
w
eigh
ted
a
v
erage
is
in
tro
duced
in
Section
..
Notice
that
although
similarit
y
is
computed
b
y
considering
all
upp
er
b
ounds
for
the
t
w
o
concepts,
the
information
measure
has
the
eect
of
iden
tifying
minimal
upp
er
b
ounds,
since
no
class
is
less
informativ
e
than
its
sup
erordinates.
F
or
example,
in
Figure
,
coin,
cash,
etc.
are
all
mem
b
ers
of
S
(nickel
;
dime
),
but
the
concept
that
is
structurally
the
minimal
	

----- Page 4 (native) -----
Resnik
NURSE2
p=.0001
info=13.17
DOCTOR1
p=.0018
info=9.093
HEALTH_PROFESSIONAL
p=.0022
info=8.844
NURSE1
p=.0001
info=12.94
PROFESSIONAL
p=.0079
info=6.993
LAWYER
p=.0007
info=10.39
ADULT
p=.0208
info=5.584
PERSON
p=.2491
info=2.005
FEMALE_PERSON
p=.0188
info=5.736
GUARDIAN
p=.0058
info=7.434
p=.0027
info=8.522
ACTOR1
INTELLECTUAL
p=.0113
info=6.471
DOCTOR2
p=.0005
info=10.84
Figure
:
Another
fragmen
t
of
the
W
ordNet
taxonom
y
upp
er
b
ound,
coin,
will
also
b
e
the
most
informativ
e.
This
can
mak
e
a
dierence
in
cases
of
m
ultiple
inheritance:
t
w
o
distinct
ancestor
no
des
ma
y
b
oth
b
e
minimal
upp
er
b
ounds,
as
measured
using
distance
in
the
graph,
but
those
t
w
o
no
des
migh
t
ha
v
e
v
ery
dieren
t
v
alues
for
information
con
ten
t.
Also
notice
that
in
is-a
taxonomies
suc
h
as
W
ordNet,
where
there
are
m
ultiple
sub-taxonomies
but
no
unique
top
no
de,
asserting
zero
similarit
y
for
concepts
in
separate
sub-taxonomies
(e.g.,
liber
ty,
a
or
t
a)
is
equiv
alen
t
to
unifying
the
sub-taxonomies
b
y
creating
a
virtual
topmost
concept.
In
practice,
one
often
needs
to
measure
wor
d
similarity
,
rather
than
concept
similarit
y
.
Using
s(w
)
to
represen
t
the
set
of
concepts
in
the
taxonom
y
that
are
senses
of
w
ord
w
,
dene
wsim(w

;
w

)
=
max
c;
c
[
sim
(c

;
c

)]
;
()
where
c

ranges
o
v
er
s(w

)
and
c

ranges
o
v
er
s(w

).
This
is
consisten
t
with
Rada
et
al.'s
(		)
treatmen
t
of
\disjunctiv
e
concepts"
using
edge-coun
ting:
they
dene
the
distance
b
et
w
een
t
w
o
disjunctiv
e
sets
of
concepts
as
the
minim
um
path
length
from
an
y
elemen
t
of
the
rst
set
to
an
y
elemen
t
of
the
second.
Here,
the
w
ord
similarit
y
is
judged
b
y
taking
the
maximal
information
con
ten
t
o
v
er
all
concepts
of
whic
h
b
oth
w
ords
could
b
e
an
in-
stance.
T
o
tak
e
an
example,
consider
ho
w
the
w
ord
similarit
y
wsim(do
ctor,
nurse)
w
ould
b
e
computed,
using
the
taxonomic
information
in
Figure
.
(Note
that
only
noun
senses
are
considered
here.)
By
Equation
,
w
e
m
ust
consider
all
pairs
of
concepts
hc

;
c

i,
where
c


fdoctor;
doctorg
and
c


fnurse;
nurseg,
and
for
eac
h
suc
h
pair
w
e
m
ust
compute
the
seman
tic
similarit
y
sim(c

,c

)
according
to
Equation
.
T
able

illustrates
the
computation.
	

----- Page 5 (native) -----
Inf
orma
tion-Based
Semantic
Similarity
c

(description)
c

(description)
subsumer
sim(c

,c

)
doctor
(medical)
nurse
(medical)
heal
th
pr
ofessional
.
doctor
(medical)
nurse
(nann
y)
person
.00
doctor
(Ph.D.)
nurse
(medical)
person
.00
doctor
(Ph.D.)
nurse
(nann
y)
person
.00
T
able
:
Computation
of
similarit
y
for
do
ctor
and
nurse
As
the
table
sho
ws,
when
all
the
senses
for
do
ctor
are
considered
against
all
the
senses
for
nurse,
the
maxim
um
v
alue
is
.,
via
heal
th
pr
ofessional
as
a
most
informativ
e
subsumer;
this
is,
therefore,
the
v
alue
of
w
ord
similarit
y
for
do
ctor
and
nurse.

.
Ev
aluation
This
section
describ
es
a
simple,
direct
metho
d
for
ev
aluating
seman
tic
similarit
y
,
using
h
uman
judgmen
ts
as
the
basis
for
comparison.
.
Implemen
tation
The
w
ork
rep
orted
here
used
W
ordNet's
taxonom
y
of
concepts
represen
ted
b
y
nouns
(and
comp
ound
nominals)
in
English.

F
requencies
of
concepts
in
the
taxonom
y
w
ere
estimated
using
noun
frequencies
from
the
Bro
wn
Corpus
of
American
English
(F
rancis
&
Ku

cera,
	),
a
large
(,000,000
w
ord)
collection
of
text
across
genres
ranging
from
news
articles
to
science
ction.
Eac
h
noun
that
o
ccurred
in
the
corpus
w
as
coun
ted
as
an
o
ccurrence
of
eac
h
taxonomic
class
con
taining
it.

F
or
example,
in
Figure
,
an
o
ccurrence
of
the
noun
dime
w
ould
b
e
coun
ted
to
w
ard
the
frequency
of
dime,
coin,
cash,
and
so
forth.
F
ormally
,
freq(c)
=
X
nw
ords
(c)
coun
t
(n);
()
where
w
ords
(c)
is
the
set
of
w
ords
subsumed
b
y
concept
c.
Concept
probabilities
w
ere
computed
simply
as
relativ
e
frequency:
^
p(c)
=
freq
(c)
N
;
()
where
N
w
as
the
total
n
um
b
er
of
nouns
observ
ed
(excluding
those
not
subsumed
b
y
an
y
W
ordNet
class,
of
course).
Naturally
the
frequency
estimates
in
Equation

w
ould
b
e
.
The
taxonom
y
in
Figure

is
a
fragmen
t
of
W
ordNet
v
ersion
.,
sho
wing
real
quan
titativ
e
information
computed
using
the
metho
d
describ
ed
b
elo
w.
The
\nann
y"
sense
of
nurse
(n
ursemaid,
a
w
oman
who
is
the
custo
dian
of
c
hildren)
is
primarily
a
British
usage.
The
example
omits
t
w
o
other
senses
of
do
ctor
in
W
ordNet:
a
theologian
in
the
Roman
Catholic
Ch
urc
h,
and
a
game
pla
y
ed
b
y
c
hildren.
W
ordNet
do
es
not
use
no
de
lab
els
lik
e
doctor,
but
I
ha
v
e
created
suc
h
lab
els
here
for
the
sak
e
of
readabilit
y
.
.
Conc
ept
as
used
here
refers
to
what
Miller
et
al.
(		0)
call
a
synset,
essen
tially
a
no
de
in
the
taxonom
y
.
The
exp
erimen
t
rep
orted
in
this
section
used
the
noun
taxonom
y
from
W
ordNet
v
ersion
.,
whic
h
has
appro
ximately
0,000
no
des.
.
Plural
nouns
coun
ted
as
instances
of
their
singular
forms.

----- Page 6 (native) -----
Resnik
impro
v
ed
b
y
taking
in
to
accoun
t
the
in
tended
sense
of
eac
h
noun
in
the
corpus
|
for
example,
an
instance
of
cr
ane
can
b
e
a
bird
or
a
mac
hine,
but
not
b
oth.
Sense-tagged
corp
ora
are
generally
not
a
v
ailable,
ho
w
ev
er,
and
so
the
frequency
estimates
are
done
using
this
w
eak
er
but
more
generally
applicable
tec
hnique.
It
should
b
e
noted
that
the
presen
t
metho
d
of
asso
ciating
probabilities
with
concepts
in
a
taxonom
y
is
not
based
on
the
notion
of
a
single
random
v
ariable
ranging
o
v
er
all
concepts
|
w
ere
that
the
case,
the
\credit"
for
eac
h
noun
o
ccurrence
w
ould
b
e
distributed
o
v
er
all
concepts
for
the
noun,
and
the
coun
ts
normalized
across
the
en
tire
taxonom
y
to
sum
to
.
(That
is
the
approac
h
tak
en
in
Resnik,
		a,
also
see
Resnik,
		b
for
discussion.)
In
assigning
taxonomic
probabilities
for
purp
oses
of
measuring
seman
tic
similarit
y
,
the
presen
t
mo
del
asso
ciates
a
separate,
binomially
distributed
random
v
ariable
with
eac
h
concept.

That
is,
from
the
p
ersp
ectiv
e
of
an
y
giv
en
concept
c,
an
observ
ed
noun
either
is
or
is
not
an
instance
of
that
concept,
with
probabilities
p(c)
and

 p(c),
resp
ectiv
ely
.
Unlik
e
a
mo
del
in
whic
h
there
is
a
single
m
ultinomial
v
ariable
ranging
o
v
er
the
en
tire
set
of
concepts,
this
form
ulation
assigns
probabilit
y

to
the
top
concept
of
the
taxonom
y
,
leading
to
the
desirable
consequence
that
its
information
con
ten
t
is
zero.
.
T
ask
Although
there
is
no
standard
w
a
y
to
ev
aluate
computational
measures
of
seman
tic
similar-
it
y
,
one
reasonable
w
a
y
to
judge
w
ould
seem
to
b
e
agreemen
t
with
h
uman
similarit
y
ratings.
This
can
b
e
assessed
b
y
using
a
computational
similarit
y
measure
to
rate
the
similarit
y
of
a
set
of
w
ord
pairs,
and
lo
oking
at
ho
w
w
ell
its
ratings
correlate
with
h
uman
ratings
of
the
same
pairs.
An
exp
erimen
t
b
y
Miller
and
Charles
(		)
pro
vided
appropriate
h
uman
sub
ject
data
for
the
task.
In
their
study
,

undergraduate
sub
jects
w
ere
giv
en
0
pairs
of
nouns
that
w
ere
c
hosen
to
co
v
er
high,
in
termediate,
and
lo
w
lev
els
of
similarit
y
(as
determined
using
a
previous
study
,
Rub
enstein
&
Go
o
denough,
	),
and
those
sub
jects
w
ere
ask
ed
to
rate
\similarit
y
of
meaning"
for
eac
h
pair
on
a
scale
from
0
(no
similarit
y)
to

(p
erfect
synon
ym
y).
The
a
v
erage
rating
for
eac
h
pair
th
us
represen
ts
a
go
o
d
estimate
of
ho
w
similar
the
t
w
o
w
ords
are,
according
to
h
uman
judgmen
ts.

In
order
to
get
a
baseline
for
comparison,
I
replicated
Miller
and
Charles's
exp
erimen
t,
giving
ten
sub
jects
the
same
0
noun
pairs.
The
sub
jects
w
ere
all
computer
science
graduate
studen
ts
or
p
ostdo
ctoral
researc
hers
at
the
Univ
ersit
y
of
P
ennsylv
ania,
and
the
instructions
w
ere
exactly
the
same
as
used
b
y
Miller
and
Charles,
the
main
dierence
b
eing
that
in
this
replication
the
sub
jects
completed
the
questionnaire
b
y
electronic
mail
(though
they
w
ere
instructed
to
complete
the
whole
task
in
a
single
unin
terrupted
sitting).
Fiv
e
sub
jects
receiv
ed
the
list
of
w
ord
pairs
in
a
random
order,
and
the
other
v
e
receiv
ed
the
list
in
the
rev
erse
order.
The
correlation
b
et
w
een
the
Miller
and
Charles
mean
ratings
and
the
mean
ratings
in
m
y
replication
w
as
.	,
quite
close
to
the
.	
correlation
that
Miller
and
Charles
obtained
b
et
w
een
their
results
and
the
ratings
determined
b
y
the
earlier
study
.
.
This
is
similar
in
spirit
to
the
w
a
y
probabiliti
es
are
used
in
a
Ba
y
esian
net
w
ork.
.
An
anon
ymous
review
er
p
oin
ts
out
that
h
uman
judgmen
ts
on
this
task
ma
y
b
e
inuenced
b
y
protot
ypi-
calit
y
,
e.g.,
the
pair
bir
d/r
obin
w
ould
lik
ely
yield
higher
ratings
than
bir
d/cr
ane.
Issues
of
this
kind
are
briey
touc
hed
on
in
Section
,
but
for
the
most
part
they
are
ignored
here
since
protot
ypicalit
y
,
lik
e
topical
relatedness,
is
not
captured
in
most
is-a
taxonomies.
00

----- Page 7 (native) -----
Inf
orma
tion-Based
Semantic
Similarity
F
or
eac
h
sub
ject
in
m
y
replication,
I
computed
ho
w
w
ell
his
or
her
ratings
correlated
with
the
Miller
and
Charles
ratings.
The
a
v
erage
correlation
o
v
er
the
0
sub
jects
w
as
r
=
0:,
with
a
standard
deviation
of
0.0.

This
v
alue
represen
ts
an
upp
er
b
ound
on
what
one
should
exp
ect
from
a
computational
attempt
to
p
erform
the
same
task.
F
or
purp
oses
of
ev
aluation,
three
computational
similarit
y
measures
w
ere
used.
The
rst
is
the
similarit
y
measuremen
t
using
information
con
ten
t
prop
osed
in
the
previous
sec-
tion.
The
second
is
a
v
arian
t
on
the
edge-coun
ting
metho
d,
con
v
erting
it
from
distance
to
similarit
y
b
y
subtracting
the
path
length
from
the
maxim
um
p
ossible
path
length:
wsim
edge
(w

;
w

)
=
(

max)
 
min
c

;
c

len
(c

;
c

)

()
where
c

ranges
o
v
er
s(w

),
c

ranges
o
v
er
s(w

),
max
is
the
maxim
um
depth
of
the
tax-
onom
y
,
and
len
(c

;
c

)
is
the
length
of
the
shortest
path
from
c

to
c

.
(Recall
that
s(w
)
denotes
the
set
of
concepts
in
the
taxonom
y
that
represen
t
senses
of
w
ord
w
.)
If
all
senses
of
w

and
w

are
in
separate
sub-taxonomies
of
W
ordNet
their
similarit
y
is
tak
en
to
b
e
zero.
Note
that
b
ecause
correlation
is
used
as
the
ev
aluation
metric,
the
con
v
ersion
from
a
distance
to
a
similarit
y
can
b
e
view
ed
as
an
exp
ository
con
v
enience,
and
do
es
not
aect
the
results:
although
the
sign
of
the
correlation
co
ecien
t
c
hanges
from
p
ositiv
e
to
negativ
e,
its
magnitude
turns
out
to
b
e
just
the
same
regardless
of
whether
or
not
the
minim
um
path
length
is
subtracted
from
(

max).
The
third
p
oin
t
of
comparison
is
a
measure
that
simply
uses
the
probabilit
y
of
a
concept,
rather
than
the
information
con
ten
t,
to
dene
seman
tic
similarit
y
of
concepts
sim
p(c)
(c

;
c

)
=
max
c

S
(c

;
c

)
[
 p(c)]
()
and
the
corresp
onding
measure
of
w
ord
similarit
y:
wsim
p(c)
(w

;
w

)
=
max
c

;
c

h
sim
p(c)
(c

;
c

)
i
;
()
where
c

ranges
o
v
er
s(w

)
and
c

ranges
o
v
er
s(w

)
in
Equation
.
The
probabilit
y-based
similarit
y
score
is
included
in
order
to
assess
the
exten
t
to
whic
h
similarit
y
judgmen
ts
migh
t
b
e
sensitiv
e
to
frequency
p
er
se
rather
than
information
con
ten
t.
Again,
the
dierence
b
et
w
een
maximizing

 p(c)
and
minimizing
p(c)
turns
out
not
to
aect
the
magnitude
of
the
correlation.
It
simply
ensures
that
the
v
alue
can
b
e
in
terpreted
as
a
similarit
y
v
alue,
with
high
v
alues
indicating
similar
w
ords.
.
Results
T
able

summarizes
the
exp
erimen
tal
results,
giving
the
correlation
b
et
w
een
the
similarit
y
ratings
and
the
mean
ratings
rep
orted
b
y
Miller
and
Charles.
Note
that,
o
wing
to
a
noun
missing
from
the
W
ordNet
.
taxonom
y
,
it
w
as
only
p
ossible
to
obtain
computational
similarit
y
ratings
for

of
the
0
noun
pairs;
hence
the
prop
er
p
oin
t
of
comparison
for
h
uman
judgmen
ts
is
not
the
correlation
o
v
er
all
0
items
(r
=
:),
but
rather
the
correlation
o
v
er
the

included
pairs
(r
=
:	0).
The
similarit
y
ratings
b
y
item
are
giv
en
in
T
able
.
.
In
ter-sub
ject
correlation
in
the
replication,
estimated
using
lea
ving-one-out
resampling
(W
eiss
&
Ku-
lik
o
wski,
		),
w
as
r
=
:	0;
stdev
=
0:0.
0

----- Page 8 (native) -----
Resnik
Similarit
y
metho
d
Correlation
Human
judgmen
ts
(replication)
r
=
:	0
Information
con
ten
t
r
=
:	
Probabilit
y
r
=
:
Edge-coun
ting
r
=
:
T
able
:
Summary
of
exp
erimen
tal
results.
W
ord
P
air
Miller
and
Charles
Replication
wsim
wsim
edge
wsim
p(c)
means
means
car
automobile
.	
.	
.0
0
0.		
gem
jew
el
.
.
.	
0
.0000
journey
v
o
y
age
.
.
.
	
0.		0
b
o
y
lad
.
.
.0
	
0.		
coast
shore
.0
.
0.0
	
0.			
asylum
madhouse
.
.
.
	
.0000
magician
wizard
.0
.
.
0
0.				
midda
y
no
on
.
.
.	
0
0.			
furnace
sto
v
e
.
.
.

0.	
fo
o
d
fruit
.0
.
.00

0.		
bird
co
c
k
.0
.
	.	
	
0.		
bird
crane
.	
.
	.	

0.		
to
ol
implemen
t
.	
.
.0
	
0.	
brother
monk
.
.
.	

0.
crane
implemen
t
.
0.
.	

0.
lad
brother
.
.
.	

0.	
journey
car
.
0.
0.0000
0
0.0000
monk
oracle
.0
0.
.	

0.
fo
o
d
ro
oster
0.	
.
.00

0.0
coast
hill
0.
0.
.

0.	
forest
gra
v
ey
ard
0.
0.
0.0000
0
0.0000
monk
sla
v
e
0.
0.
.	

0.
coast
forest
0.
0.
0.0000
0
0.0000
lad
wizard
0.
0.
.	

0.
c
hord
smile
0.
0.
.
0
0.0
glass
magician
0.
0.
.00

0.0
no
on
string
0.0
0.0
0.0000
0
0.0000
ro
oster
v
o
y
age
0.0
0.0
0.0000
0
0.0000
T
able
:
Seman
tic
similarit
y
b
y
item.
0

----- Page 9 (native) -----
Inf
orma
tion-Based
Semantic
Similarity
n
n
wsim(n

,n

)
subsumer
tobacco
alcohol
.
dr
ug
tobacco
sugar
.
subst
ance
tobacco
horse
.
nar
cotic
T
able
:
Similarit
y
with
tob
ac
c
o
computed
b
y
maximizing
information
con
ten
t
.
Discussion
The
exp
erimen
tal
results
in
the
previous
section
suggest
that
measuring
seman
tic
similarit
y
using
information
con
ten
t
pro
vides
results
that
are
b
etter
than
the
traditional
metho
d
of
simply
coun
ting
the
n
um
b
er
of
in
terv
ening
is-a
links.
The
measure
is
not
without
its
problems,
ho
w
ev
er.
Lik
e
simple
edge-coun
ting,
the
measure
sometimes
pro
duces
spuriously
high
similarit
y
measures
for
w
ords
on
the
basis
of
inappropriate
w
ord
senses.
F
or
example,
T
able

sho
ws
the
w
ord
similarit
y
for
sev
eral
w
ords
with
tob
ac
c
o.
T
ob
ac
c
o
and
alc
ohol
are
similar,
b
oth
b
eing
drugs,
and
tob
ac
c
o
and
sugar
are
less
similar,
though
not
en
tirely
dissimilar,
since
b
oth
can
b
e
classied
as
substances.
The
problem
arises,
ho
w
ev
er,
in
the
similarit
y
rating
for
tob
ac
c
o
with
horse:
the
w
ord
horse
can
b
e
used
as
a
slang
term
for
her
oin,
and
as
a
result
information-based
similarit
y
is
maximized,
and
path
length
minimized,
when
the
t
w
o
w
ords
are
b
oth
categorized
as
narcotics.
This
is
con
trary
to
in
tuition.
Cases
lik
e
this
are
probably
relativ
ely
rare.
Ho
w
ev
er,
the
example
illustrates
a
more
general
concern:
in
measuring
similarit
y
b
et
w
een
w
ords,
it
is
really
the
relationship
among
w
ord
senses
that
matters,
and
a
similarit
y
measure
should
b
e
able
to
tak
e
this
in
to
accoun
t.
In
the
absence
of
a
reliable
algorithm
for
c
ho
osing
the
appropriate
w
ord
senses,
the
most
straigh
tforw
ard
w
a
y
to
do
so
in
the
information-based
setting
is
to
consider
al
l
concepts
to
whic
h
b
oth
nouns
b
elong
rather
than
taking
just
the
single
maximally
informativ
e
class.
This
suggests
dening
a
measure
of
weighte
d
wor
d
similarity
as
follo
ws:
wsim

(w

;
w

)
=
X
i
(c
i
)[ log
p(c
i
)];
()
where
fc
i
g
is
the
set
of
concepts
dominating
b
oth
w

and
w

in
an
y
sense
of
either
w
ord,
and

is
a
w
eigh
ting
function
o
v
er
concepts
suc
h
that
P
i
(c
i
)
=
.
This
measure
of
similarit
y
tak
es
more
information
in
to
accoun
t
than
the
previous
one:
rather
than
relying
on
the
single
concept
with
maximum
information
con
ten
t,
it
allo
ws
e
ach
class
represen
ting
shared
prop
erties
to
con
tribute
information
con
ten
t
according
to
the
v
alue
of
(c
i
).
In
tuitiv
ely
,
these

v
alues
measure
relev
ance.
F
or
example,
in
computing
wsim

(tob
ac
c
o,horse)
,
the
c
i
w
ould
range
o
v
er
all
concepts
of
whic
h
tob
ac
c
o
and
horse
are
b
oth
instances,
including
nar
cotic,
dr
ug,
ar
tif
a
ct,
life
f
orm,
etc.
In
an
ev
eryda
y
con
text
one
migh
t
exp
ect
lo
w
v
alues
for
(nar
cotic
)
and
(dr
ug),
but
in
the
con
text
of,
sa
y
,
a
newspap
er
article
ab
out
drug
dealers,
the
w
eigh
ts
of
these
concepts
migh
t
b
e
quite
high.
Although
it
is
not
p
ossible
to
include
w
eigh
ted
w
ord
similarit
y
in
the
comparison
of
Section
,
since
the
noun
pairs
are
judged
without
con
text,
Section

pro
vides
further
discussion
and
a
w
eigh
ting
function

designed
for
a
particular
natural
language
pro
cessing
task.
0

----- Page 10 (native) -----
Resnik
.
Using
T
axonomic
Similarit
y
in
Resolving
Syn
tactic
Am
biguit
y
Ha
ving
considered
a
direct
ev
aluation
of
the
information-based
seman
tic
similarit
y
measure,
I
no
w
turn
to
the
application
of
the
measure
in
resolving
syn
tactic
am
biguit
y
.
.
Clues
for
Resolving
Co
ordination
Am
biguit
y
Syn
tactic
am
biguit
y
is
a
p
erv
asiv
e
problem
in
natural
language.
As
Ch
urc
h
and
P
atil
(	)
p
oin
t
out,
the
class
of
\ev
ery
w
a
y
am
biguous"
syn
tactic
constructions
|
those
for
whic
h
the
n
um
b
er
of
analyses
is
the
n
um
b
er
of
binary
trees
o
v
er
the
terminal
elemen
ts
|
includes
suc
h
frequen
t
constructions
as
prep
ositional
phrases,
co
ordination,
and
nominal
comp
ounds.
In
the
last
sev
eral
y
ears,
researc
hers
in
natural
language
ha
v
e
made
a
great
deal
of
progress
in
using
quan
titativ
e
information
from
text
corp
ora
to
pro
vide
the
needed
constrain
ts.
Progress
on
broad-co
v
erage
prep
ositional
phrase
attac
hmen
t
am
biguit
y
has
b
een
particularly
notable,
no
w
that
the
dominan
t
approac
h
has
shifted
from
structural
strategies
to
quan
titativ
e
analysis
of
lexical
relationships
(Whittemore,
F
errara,
&
Brunner,
		0;
Hindle
&
Ro
oth,
		;
Brill
&
Resnik,
		;
Ratnaparkhi
&
Rouk
os,
		;
Li
&
Ab
e,
		;
Collins
&
Bro
oks,
		;
Merlo,
Cro
c
k
er,
&
Berthouzoz,
		).
Noun
comp
ounds
ha
v
e
receiv
ed
comparativ
ely
less
atten
tion
(Koba
y
asi,
T
akunaga,
&
T
anak
a,
		;
Lauer,
		,
		),
as
has
the
problem
of
co
ordination
am
biguit
y
(Agarw
al
&
Boggess,
		;
Kurohashi
&
Nagao,
		).
In
this
section,
I
in
v
estigate
the
role
of
seman
tic
similarit
y
in
resolving
co
ordination
am
biguities
in
v
olving
nominal
comp
ounds.
I
b
egan
with
noun
phrase
co
ordinations
of
the
form
n
and
n
n,
whic
h
admit
t
w
o
structural
analyses,
one
in
whic
h
n
and
n
are
the
t
w
o
noun
phrase
heads
b
eing
conjoined
(a)
and
one
in
whic
h
the
conjoined
heads
are
n
and
n
(b).
()
a.
a
(bank
and
w
arehouse)
guard
b.
a
(p
oliceman)
and
(park
guard)
Iden
tifying
whic
h
t
w
o
head
nouns
are
conjoined
is
necessary
in
order
to
arriv
e
at
a
correct
in
terpretation
of
the
phrase's
con
ten
t.
F
or
example,
analyzing
(b)
according
to
the
struc-
ture
of
(a)
could
lead
a
mac
hine
translation
system
to
pro
duce
a
noun
phrase
describing
someb
o
dy
who
guards
b
oth
p
olicemen
and
parks.
Analyzing
(a)
according
to
the
struc-
ture
of
(b)
could
lead
an
information
retriev
al
system
to
miss
this
phrase
when
lo
oking
for
queries
in
v
olving
the
term
b
ank
guar
d.
Kurohashi
and
Nagao
(		)
p
oin
t
out
that
similarit
y
of
form
and
similarit
y
of
meaning
are
imp
ortan
t
cues
to
conjoinabilit
y
.
In
English,
similarit
y
of
form
is
to
a
great
exten
t
captured
b
y
agreemen
t
in
n
um
b
er
(singular
vs.
plural):
()
a.
sev
eral
business
and
university
groups
b.
sev
eral
businesses
and
univ
ersit
y
gr
oups
Similarit
y
of
form
b
et
w
een
candidate
conjoined
heads
can
th
us
b
e
though
t
of
as
a
Bo
olean
v
ariable:
n
um
b
er
agreemen
t
is
either
satised
b
y
the
candidate
heads
or
it
is
not.
Similarit
y
of
meaning
of
the
conjoined
heads
also
app
ears
to
pla
y
an
imp
ortan
t
role:
()
a.
a
television
and
r
adio
p
ersonalit
y
0

----- Page 11 (native) -----
Inf
orma
tion-Based
Semantic
Similarity
b.
a
psycholo
gist
and
sex
r
ese
ar
cher
Clearly
television
and
r
adio
are
more
similar
than
television
and
p
ersonality;
corresp
ond-
ingly
for
psycholo
gist
and
r
ese
ar
cher.
This
similarit
y
of
meaning
is
captured
w
ell
b
y
seman
tic
similarit
y
in
a
taxonom
y
,
and
th
us
a
second
v
ariable
to
consider
when
ev
aluating
a
co
ordina-
tion
structure
is
seman
tic
similarit
y
as
measured
b
y
o
v
erlap
in
information
con
ten
t
b
et
w
een
the
t
w
o
head
nouns.
In
addition,
for
the
constructions
considered
here,
the
appropriateness
of
noun-noun
mo
dication
is
relev
an
t:
()
a.
mail
and
se
curities
fraud
b.
c
orn
and
p
ean
ut
butter
One
reason
w
e
prefer
to
conjoin
mail
and
se
curities
is
that
mail
fr
aud
is
a
salien
t
comp
ound
nominal
phrase.
On
the
other
hand,
c
orn
butter
is
not
a
familiar
concept;
compare
to
the
c
hange
in
p
erceiv
ed
structure
if
the
phrase
w
ere
c
orn
and
p
e
anut
cr
ops.
In
order
to
measure
the
appropriateness
of
noun-noun
mo
dication,
I
use
a
quan
titativ
e
measure
of
selectional
t
called
sele
ctional
asso
ciation
(Resnik,
		),
whic
h
tak
es
in
to
accoun
t
b
oth
lexical
co-
o
ccurrence
frequencies
and
seman
tic
class
mem
b
ership
in
the
W
ordNet
taxonom
y
.
Briey
,
the
selectional
asso
ciation
of
a
w
ord
w
with
a
W
ordNet
class
c
is
giv
en
b
y
A(w
;
c)
=
p(cjw
)
log
p(cjw
)
p(c)
D(p(C
jw
)
k
p(C
))
(	)
where
D(p

k
p

)
is
the
Kullbac
k-Leib
le
r
distance
(relativ
e
en
trop
y)
b
et
w
een
probabilit
y
distributions
p

and
p

.
In
tuitiv
ely
,
A(w,
c)
is
measuring
the
exten
t
to
whic
h
class
c
is
predicted
b
y
w
ord
w
;
for
example,
A(wo
ol,
clothing)
w
ould
ha
v
e
a
higher
v
alue
than,
sa
y
,
A(wo
ol,
person).
The
selectional
asso
ciation
A(w

;
w

)
of
t
w
o
w
ords
is
dened
as
the
maxim
um
of
A(w

;
c)
tak
en
o
v
er
all
classes
c
to
whic
h
w

b
elongs.
F
or
example,
A(wo
ol,
glove)
w
ould
most
lik
ely
b
e
equal
to
A(wo
ol,
clothing),
as
compared
to,
sa
y
,
A(wo
ol,
spor
ts
equipment)
|
the
latter
v
alue
corresp
onding
to
the
sense
of
glove
as
something
used
in
baseball
or
in
b
o
xing.
(See
Li
&
Ab
e,
		,
for
an
approac
h
in
whic
h
selectional
relationships
are
mo
deled
using
conditional
probabilit
y
.)
A
simple
w
a
y
to
treat
selectional
asso
ciation
as
a
v
ariable
in
resolving
co
ordination
am
biguities
is
to
prefer
analy-
ses
that
include
noun-noun
mo
dications
with
v
ery
strong
anities
(e.g.,
b
ank
as
a
mo
dier
of
guar
d)
and
to
disprefer
v
ery
w
eak
noun-noun
relationships
(e.g.,
c
orn
as
a
mo
dier
of
butter).
Thresholds
dening
\strong"
and
\w
eak"
are
parameters
of
the
algorithm,
dened
b
elo
w.
.
Resolving
Co
ordination
Am
biguit
y:
First
Exp
erimen
t
I
in
v
estigated
the
roles
of
these
sources
of
evidence
b
y
conducting
a
straigh
tforw
ard
dis-
am
biguation
exp
erimen
t
using
naturally
o
ccurring
linguistic
data.
Tw
o
sets
of
00
noun
phrases
of
the
form
[NP
n
and
n
n]
w
ere
extracted
from
the
parsed
Wal
l
Str
e
et
Journal
(WSJ)
corpus,
as
found
in
the
P
enn
T
reebank
(Marcus,
San
torini,
&
Marcinkiewicz,
		).
These
w
ere
disam
biguated
b
y
hand,
with
one
set
used
for
dev
elopmen
t
and
the
other
for
0

----- Page 12 (native) -----
Resnik
Source
of
evidence
Conjoined
Condition
Num
b
er
agreemen
t
n
and
n
n
um
b
er(n)
=
n
um
b
er(n)
and
n
um
b
er(n)
=
n
um
b
er(n)
n
and
n
n
um
b
er(n)
=
n
um
b
er(n)
and
n
um
b
er(n)
=
n
um
b
er(n)
undecided
otherwise
Seman
tic
similarit
y
n
and
n
wsim(n,n)
>
wsim(n,n)
n
and
n
wsim(n,n)
>
wsim(n,n)
undecided
otherwise
Noun-noun
n
and
n
A(n,n)
>

or
A(n,n)
>

mo
dication
n
and
n
A(n,n)
<

or
A(n,n)
<

undecided
otherwise
T
able
:
Rules
for
n
um
b
er
agreemen
t,
seman
tic
similarit
y
,
and
noun-noun
mo
dication
in
resolving
syn
tactic
am
biguit
y
of
noun
phrases
n
and
n
n
testing.

A
set
of
simple
transformations
w
ere
applied
to
all
WSJ
data,
including
the
map-
ping
of
all
prop
er
names
to
the
tok
en
some
one,
the
expansion
of
mon
th
abbreviations,
and
the
reduction
of
all
nouns
to
their
ro
ot
forms.
Num
b
er
agreemen
t
w
as
determined
using
a
simple
analysis
of
suxes
in
com
bination
with
W
ordNet's
lists
of
ro
ot
nouns
and
irregular
plurals.

Seman
tic
similarit
y
w
as
deter-
mined
using
the
information-based
measure
of
Equation
()
|
the
noun
class
probabilities
of
Equation
()
w
ere
estimated
using
a
sample
of
appro
ximately
00,000
noun
o
ccurrences
in
Asso
ciated
Press
newswire
stories.
	
F
or
the
purp
ose
of
determining
seman
tic
similarit
y
,
nouns
not
in
W
ordNet
w
ere
treated
as
instances
of
the
class
hthingi.
Appropriateness
of
noun-noun
mo
dication
w
as
determined
b
y
computing
selectional
asso
ciation
(Equation
	),
using
co-o
ccurrence
frequencies
tak
en
from
a
sample
of
appro
ximately
,000
noun-noun
comp
ounds
extracted
from
the
WSJ
corpus.
(This
sample
did
not
include
the
test
data.)
Both
selection
of
the
mo
dier
for
the
head
and
selection
of
the
head
for
the
mo
dier
w
ere
considered
b
y
the
disam
biguation
algorithm.
T
able

pro
vides
details
of
the
decision
rule
for
eac
h
source
of
evidence
when
used
indep
enden
tly
.
0
In
addition,
I
in
v
estigated
sev
eral
metho
ds
for
com
bining
the
three
sources
of
informa-
tion.
These
included:
(a)
a
simple
form
of
\bac
king
o
"
(sp
ecically
,
giv
en
the
n
um
b
er
agreemen
t,
noun-noun
mo
dication,
and
seman
tic
similarit
y
strategies
in
that
order,
use
the
c
hoice
giv
en
b
y
the
rst
strategy
that
isn't
undecided);
(b)
taking
a
v
ote
among
the
three
strategies
and
c
ho
osing
the
ma
jorit
y;
(c)
classifying
using
the
results
of
a
linear
re-
.
Hand
disam
biguati
on
w
as
necessary
b
ecause
the
P
enn
T
reebank
do
es
not
enco
de
NP-in
ternal
structure.
These
phrases
w
ere
disam
biguated
using
the
full
sen
tence
in
whic
h
they
o
ccurred,
plus
the
previous
and
follo
wing
sen
tence,
as
con
text.
.
The
exp
erimen
ts
in
this
section
used
W
ordNet
v
ersion
..
	.
I
am
grateful
to
Donald
Hindle
for
making
these
data
a
v
ailable.
0.
Thresholds

=
:0
and

=
0:0
w
ere
xed
man
ually
based
on
exp
erience
with
the
dev
elopmen
t
set
b
efore
ev
aluating
the
test
data.
0

----- Page 13 (native) -----
Inf
orma
tion-Based
Semantic
Similarity
Stra
tegy
Co
vera
ge
(%)
A
ccura
cy
(%)
Default
00.0
.0
Num
b
er
agreemen
t
.0
	0.
Noun-noun
mo
dication
.0
	.
Seman
tic
similarit
y
.0
.
Bac
king
o
	.0
.
V
oting
	.0
.
Num
b
er
agreemen
t
+
def
a
ul
t
00.0
.0
Noun-noun
mo
dication
+
def
a
ul
t
00.0
.0
Seman
tic
similarit
y
+
def
a
ul
t
00.0
.0
Bac
king
o
+
def
a
ul
t
00.0
.0
V
oting
+
def
a
ul
t
00.0
.0
Regression
00.0
	.0
ID
T
ree
00.0
0.0
T
able
:
Syn
tactic
disam
biguation
for
items
of
the
form
n
and
n
n
gression;
and
(d)
constructing
a
decision
tree
classier.
The
latter
t
w
o
metho
ds
are
forms
of
sup
ervised
learning;
in
this
exp
erimen
t
the
dev
elopmen
t
set
w
as
used
as
the
training
data.

The
results
are
sho
wn
in
T
able
.
The
dev
elopmen
t
set
con
tained
a
bias
in
fa
v
or
of
conjoining
n
and
n;
therefore
a
\default"
strategy
,
alw
a
ys
c
ho
osing
that
brac
k
eting,
w
as
used
as
a
baseline
for
comparison.
The
default
w
as
also
used
for
resolving
undecided
cases
in
order
to
mak
e
comparisons
of
individual
strategies
at
00%
co
v
erage.
F
or
example,
\Num
b
er
agreemen
t
+
def
a
ul
t"
sho
ws
the
gures
obtained
when
n
um
b
er
agreemen
t
is
used
to
mak
e
the
c
hoice
and
the
default
is
selected
if
that
c
hoice
is
undecided.
Not
surprisingly
,
the
individual
strategies
p
erform
reasonably
w
ell
on
the
instances
they
can
classify
,
but
co
v
erage
is
p
o
or;
the
strategy
based
on
similarit
y
of
form
is
the
most
highly
accurate,
but
arriv
es
at
an
answ
er
only
half
the
time.
Ho
w
ev
er,
the
hea
vy
a
priori
bias
mak
es
up
the
dierence
|
to
suc
h
an
exten
t
that
ev
en
though
the
other
forms
of
evidence
ha
v
e
some
v
alue,
no
com
bination
b
eats
the
n
um
b
er-agreemen
t-plus-default
com
bination.
On
the
p
ositiv
e
side,
this
sho
ws
that
the
am
biguit
y
can
b
e
resolv
ed
reasonably
w
ell
using
a
v
ery
simple
algorithm:
view
ed
in
terms
of
ho
w
man
y
errors
are
made,
n
um
b
er
agreemen
t
mak
es
it
p
ossible
to
cut
the
baseline
%
error
rate
nearly
in
half
to
%
incorrect
analyses
(a
%
reduction).
On
the
negativ
e
side,
the
results
fail
to
mak
e
a
strong
case
that
seman
tic
similarit
y
can
add
something
useful.
Before
taking
up
this
issue,
let
us
assess
the
con
tributions
of
the
individual
strategies
to
the
results
when
evidence
is
com
bined,
b
y
further
analyzing
the
b
eha
vior
of
the
unsup
ervised
evidence
com
bination
strategies.
When
com
bining
evidence
b
y
v
oting,
a
c
hoice
w
as
made
in
	
cases.
The
n
um
b
er
agreemen
t
strategy
agreed
with
the
ma
jorit
y
v
ote
in

cases,
of
whic
h

(.%)
w
ere
correct;
the
noun-noun
mo
dication
strategy
agreed
with
the
ma
jorit
y
in

cases,
of
whic
h
0
(.%)
w
ere
correct;
and
the
seman
tic
similarit
y
strategy
.
What
I
am
calling
\bac
king
o
"
is
related
in
spirit
to
Katz's
w
ell
kno
wn
smo
othing
tec
hnique
(Katz,
	),
but
the
\bac
king
o
"
strategy
used
here
is
not
quan
titativ
e.
I
retain
the
double
quotes
in
order
to
highlight
the
distinction
.
0

----- Page 14 (native) -----
Resnik
agreed
with
the
ma
jorit
y
in

cases,
of
whic
h

(.%)
w
ere
correct.
In
the
\bac
king
o
"
form
of
evidence
com
bination,
n
um
b
er
agreemen
t
mak
es
a
c
hoice
for

cases
and
is
correct
for

(	0.%);
then,
of
those
remaining
undecided,
noun-noun
mo
dication
mak
es
a
c
hoice
for

cases
and
is
correct
for

(.%);
then,
of
those
still
undecided,
seman
tic
similarit
y
mak
es
a
c
hoice
for

cases
of
whic
h

are
correct
(.%);
and
the
remaining

cases
are
undecided.
This
analysis
and
the
ab
o
v
e-baseline
p
erformance
of
the
seman
tic-similarit
y-plus-d
efault
strategy
sho
w
that
seman
tic
similarit
y
do
es
con
tain
information
ab
out
the
correct
answ
er:
it
agrees
with
the
ma
jorit
y
v
ote
a
substan
tial
p
ortion
of
the
time,
and
it
selects
correct
answ
ers
more
often
than
one
w
ould
exp
ect
b
y
default
for
the
cases
it
receiv
es
through
\bac
king
o."
Ho
w
ev
er,
b
ecause
the
default
is
correct
t
w
o
thirds
of
the
time,
and
b
ecause
the
n
um
b
er
agreemen
t
strategy
is
correct
nine
out
of
ten
times
for
the
cases
it
can
decide,
the
p
oten
tial
con
tribution
of
seman
tic
similarit
y
remains
suggestiv
e
rather
than
conclusiv
e.
In
a
second
exp
erimen
t,
therefore,
I
in
v
estigated
a
more
dicult
form
ulation
of
the
problem
in
order
to
obtain
a
b
etter
assessmen
t.
.
Resolving
Co
ordination
Am
biguit
y:
Second
Exp
erimen
t
In
the
second
exp
erimen
t
using
the
same
data
sources,
I
in
v
estigated
a
more
complex
set
of
co
ordinations,
lo
oking
at
noun
phrases
of
the
form
n0
n
and
n
n.
The
syn
tactic
analyses
of
suc
h
phrases
are
c
haracterized
b
y
the
same
top-lev
el
binary
c
hoice
as
the
data
in
the
previous
exp
erimen
t,
either
conjoining
heads
n
and
n
as
in
()
or
conjoining
n
and
n
as
in
().

()
a.
freshman
((business
and
mark
eting)
ma
jor)
b.
(fo
o
d
(handling
and
storage))
pro
cedures
c.
((mail
fraud)
and
brib
ery)
c
harges
()
a.
Clorets
(gum
and
(breath
min
ts))
b.
(bab
y
fo
o
d)
and
(pupp
y
c
ho
w)
F
or
this
exp
erimen
t,
one
set
of
	
items
w
as
extracted
from
the
P
enn
T
reebank
WSJ
data
for
dev
elopmen
t,
and
another
set
of
	
items
w
as
set
aside
for
testing.
The
dev
elopmen
t
set
sho
w
ed
signican
tly
less
bias
than
the
data
in
the
previous
exp
erimen
t,
with
.	%
of
items
conjoining
n
and
n.
The
disam
biguation
strategies
in
this
exp
erimen
t
w
ere
a
more
rened
v
ersion
of
those
used
in
the
previous
exp
erimen
t,
as
illustrated
in
T
able
.
Num
b
er
agreemen
t
w
as
used
just
as
b
efore.
Ho
w
ev
er,
rather
than
emplo
ying
seman
tic
similarit
y
and
noun-noun
mo
dication
as
indep
enden
t
strategies
|
something
not
clearly
w
arran
ted
giv
en
the
lac
kluster
p
erfor-
mance
of
the
mo
dication
strategy
|
the
t
w
o
w
ere
com
bined
in
a
measure
of
w
eigh
ted
seman
tic
similarit
y
as
dened
in
Equation
().
Selectional
asso
ciation
w
as
used
as
the
basis
for
.
In
particular,

;
(c)
w
as
the
greater
of
A(n0,c)
and
A(n,c),
capturing
the
fact
that
when
n
and
n
are
conjoined,
the
com
bined
phrase
p
oten
tially
stands
in
a
head-mo
dier
relationship
with
n0
and
a
mo
dier-head
relationship
with
n
.
Corresp
ondingly
,

;
(c)
w
as
the
greater
of
A(n0,c)
and
A(n,c),
capturing
the
fact
that
the
co
ordination
of
n
.
The
full
-w
a
y
classicatio
n
problem
for
the
structures
in
()
and
()
w
as
not
in
v
estigated.
0

----- Page 15 (native) -----
Inf
orma
tion-Based
Semantic
Similarity
Source
of
evidence
Conjoined
Condition
Num
b
er
agreemen
t
n
and
n
n
um
b
er(n)
=
n
um
b
er(n)
and
n
um
b
er(n)
=
n
um
b
er(n)
n
and
n
n
um
b
er(n)
=
n
um
b
er(n)
and
n
um
b
er(n)
=
n
um
b
er(n)
undecided
otherwise
W
eigh
ted
seman
tic
n
and
n
wsim

;
(n,n)
>
wsim

;
(n,n)
similarit
y
n
and
n
wsim

;
(n,n)
>
wsim

;
(n,n)
undecided
otherwise
T
able
:
Rules
for
n
um
b
er
agreemen
t
and
w
eigh
ted
seman
tic
similarit
y
in
resolving
syn
tac-
tic
am
biguit
y
of
noun
phrases
n0
n
and
n
n
Stra
tegy
Co
vera
ge
(%)
A
ccura
cy
(%)
Default
00.0
.	
Num
b
er
agreemen
t
0.
0.
W
eigh
ted
seman
tic
similarit
y
	.
.
Bac
king
o
.
.
T
able
:
Syn
tactic
disam
biguation
for
items
of
the
form
n0
n
and
n
n
and
n
tak
es
place
in
the
con
text
of
n
mo
difying
n
and
of
n
(or
a
co
ordinated
phrase
con
taining
it)
b
eing
mo
died
b
y
n0.
F
or
example,
consider
an
instance
of
the
am
biguous
phrase:
()
telecomm
unications
pro
ducts
and
services
units.
It
so
happ
ens
that
a
high-information-con
ten
t
connection
exists
b
et
w
een
pr
o
duct
in
its
sense
as
\a
quan
tit
y
obtained
b
y
m
ultiplication"
and
unit
in
its
sense
as
\a
single
undivided
whole."
As
a
result,
although
neither
of
these
senses
is
relev
an
t
for
this
example,
nouns
n
and
n
w
ould
b
e
assigned
a
high
v
alue
for
(un
w
eigh
ted)
seman
tic
similarit
y
and
b
e
c
hosen
incorrectly
as
the
conjoined
heads
for
this
example.
Ho
w
ev
er,
the
un
w
eigh
ted
similarit
y
com-
putation
misses
an
imp
ortan
t
piece
of
con
text:
in
an
y
syn
tactic
analysis
conjoining
pr
o
duct
and
unit
(cf.
examples
a
and
b),
the
w
ord
tele
c
ommunic
ations
is
necessarily
a
mo
dier
of
the
concept
iden
tied
b
y
pr
o
ducts.
But
the
selectional
asso
ciation
b
et
w
een
tele
c
ommu-
nic
ations
and
pr
o
ducts
in
its
\m
ultiplication"
sense
is
w
eak
or
nonexisten
t.
W
eigh
ting
b
y
selection
asso
ciation,
therefore,
pro
vides
a
w
a
y
to
reduce
the
impact
of
the
spurious
senses
on
the
similarit
y
computation.
In
order
to
com
bine
sources
of
evidence,
I
used
\bac
king
o
"
(from
n
um
b
er
agreemen
t
to
w
eigh
ted
seman
tic
similarit
y)
to
com
bine
the
t
w
o
individual
strategies.
As
a
baseline,
results
w
ere
ev
aluated
against
a
simple
default
strategy
of
alw
a
ys
c
ho
osing
the
group
that
w
as
more
common
in
the
dev
elopmen
t
set.
The
results
are
sho
wn
in
T
able
.
In
this
case,
the
default
strategy
dened
using
the
dev
elopmen
t
set
w
as
misleading,
yielding
w
orse
than
c
hance
accuracy
.
F
or
this
reason,
strategy-plus-default
gures
are
not
rep
orted.
Ho
w
ev
er,
ev
en
if
default
c
hoices
w
ere
made
using
the
bias
found
in
the
test
set,
0

----- Page 16 (native) -----
Resnik
accuracy
w
ould
b
e
only
.%.
In
con
trast
to
the
equiv
o
cal
results
in
the
rst
exp
erimen
t,
this
exp
erimen
t
demonstrates
a
clear
con
tribution
of
seman
tic
similarit
y:
b
y
emplo
ying
seman
tic
similarit
y
in
those
cases
where
the
more
accurate
n
um
b
er-agreemen
t
strategy
cannot
apply
,
it
is
p
ossible
to
obtain
equiv
alen
t
or
ev
en
somewhat
b
etter
accuracy
than
n
um
b
er
agreemen
t
alone
while
at
the
same
time
more
than
doubling
the
co
v
erage.
Comparison
with
previous
algorithms
is
unfortunately
not
p
ossible,
since
researc
hers
on
co
ordination
am
biguit
y
ha
v
e
not
established
a
common
data
set
for
ev
aluation
or
ev
en
a
common
c
haracterization
of
the
problem,
in
con
trast
to
the
no
w-standard
(v,
n,
pr
ep,
n)
con
texts
used
in
w
ork
on
prop
ositional
phrase
attac
hmen
t.
With
that
crucial
ca
v
eat,
it
is
nonetheless
in
teresting
to
note
that
the
results
obtained
here
are
broadly
consisten
t
with
Kurohashi
and
Nagao
(		),
who
rep
ort
accuracy
results
in
the
range
of
0-%
at
00%
co
v
erage
when
analyzing
a
broad
range
of
conjunctiv
e
structures
in
Japanese
using
a
com
bination
of
string
matc
hing,
syn
tactic
similarit
y
,
and
thesaurus-based
similarit
y
,
and
with
Agarw
al
and
Boggess
(		),
who
use
syn
tactic
t
yp
es
and
structure,
along
with
partly
domain-dep
enden
t
seman
tic
lab
els,
to
obtain
accuracies
in
a
similar
range
for
iden
tifying
conjuncts
in
English.
.
Using
T
axonomic
Similarit
y
in
W
ord
Sense
Selection
This
section
considers
the
application
of
the
seman
tic
similarit
y
measure
in
resolving
another
form
of
am
biguit
y:
selecting
the
appropriate
sense
of
a
noun
when
it
app
ears
in
the
con
text
of
other
nouns
that
are
related
in
meaning.
.
Asso
ciating
W
ord
Senses
with
Noun
Groupings
Kno
wledge
ab
out
groups
of
related
w
ords
pla
ys
a
role
in
man
y
natural
language
applications.
As
examples,
query
expansion
using
related
w
ords
is
a
w
ell
studied
tec
hnique
in
information
retriev
al
(e.g.,
Harman,
		;
Grefenstette,
		),
clusters
of
similar
w
ords
can
pla
y
a
role
in
smo
othing
sto
c
hastic
language
mo
dels
for
sp
eec
h
recognition
(Bro
wn,
Della
Pietra,
deSouza,
Lai,
&
Mercer,
		),
classes
of
v
erbs
that
share
seman
tic
structure
form
the
basis
for
an
approac
h
to
in
terlingual
mac
hine
translation
(Dorr,
		),
and
clusterings
of
related
w
ords
can
b
e
used
in
c
haracterizing
subgroupings
of
retriev
ed
do
cumen
ts
in
large-
scale
W
eb
searc
hes
(e.g.,
Digital
Equipmen
t
Corp
oration,
		).
There
is
a
wide
b
o
dy
of
researc
h
on
the
use
of
distributional
metho
ds
for
measuring
w
ord
similarit
y
in
order
to
obtain
groups
of
related
w
ords
(e.g.,
Bensc
h
&
Sa
vitc
h,
		;
Brill,
		;
Bro
wn
et
al.,
		;
Grefenstette,
		,
		;
McKeo
wn
&
Hatziv
assiloglou,
		;
P
ereira,
Tish
b
y
,
&
Lee,
		;
Sc
h

utze,
		),
and
thesauri
suc
h
as
W
ordNet
are
another
source
of
w
ord
relationships
(e.g.,
V
o
orhees,
		).
Distributional
tec
hniques
can
sometimes
do
a
go
o
d
job
of
iden
tifying
groups
of
related
w
ords
(see
Resnik,
		b,
for
an
o
v
erview
and
critical
discussion),
but
for
some
tasks
the
relev
an
t
relationships
are
not
among
w
ords,
but
among
w
ord
senses.
F
or
example,
Bro
wn
et
al.
(		)
illustrate
the
notion
of
a
distributionally
deriv
ed,
\seman
tically
stic
ky"
cluster
using
an
automatically
deriv
ed
w
ord
group
con
taining
attorney,
c
ounsel,
trial,
c
ourt,
and
judge.
Although
the
seman
tic
coherence
of
this
cluster
\p
ops
out"
for
a
h
uman
reader,
a
naiv
e
computational
system
has
no
defense
against
w
ord
sense
am
biguit
y:
using
this
cluster
0

----- Page 17 (native) -----
Inf
orma
tion-Based
Semantic
Similarity
for
query
expansion
could
result
in
retrieving
do
cumen
ts
in
v
olving
advice
(one
sense
of
c
ounsel)
and
ro
y
alt
y
(as
one
sense
of
c
ourt).

Resnik
(		a)
in
tro
duces
an
algorithm
that
uses
taxonomically-dened
seman
tic
simi-
larit
y
in
order
to
deriv
e
grouping
relationships
among
w
ord
senses
from
grouping
relation-
ships
among
w
ords.
F
ormally
,
the
problem
can
b
e
stated
as
follo
ws.
Consider
a
set
of
w
ords
W
=
fw

;
:
:
:
;
w
n
g,
with
eac
h
w
ord
w
i
ha
ving
an
asso
ciated
set
S
i
=
fs
i;
;
:
:
:
;
s
i;m
g
of
p
os-
sible
senses.
Assume
that
there
exists
some
set
W
0

S
S
i
,
represen
ting
the
set
of
w
ord
senses
that
an
ideal
h
uman
judge
w
ould
conclude
b
elong
to
the
group
of
senses
corresp
ond-
ing
to
the
w
ord
grouping
W
.
(It
follo
ws
that
W
0
m
ust
con
tain
at
least
one
represen
tativ
e
from
eac
h
S
i
.)
The
goal
is
then
to
dene
a
mem
b
ership
function
'
that
tak
es
s
i;j
,
w
i
,
and
W
as
its
argumen
ts
and
computes
a
v
alue
in
[0;
],
represen
ting
the
condence
with
whic
h
one
can
state
that
sense
s
i;j
b
elongs
in
sense
grouping
W
0
.
Note
that,
in
principle,
nothing
precludes
the
p
ossibilit
y
that
m
ultiple
senses
of
a
w
ord
are
included
in
W
0
.
F
or
example,
consider
again
the
group
attorney
,
counsel,
trial,
court,
judge.
Restricting
atten
tion
to
noun
senses
in
W
ordNet,
ev
ery
w
ord
but
attorney
is
p
olysemous.
T
reating
this
w
ord
group
as
W
,
a
go
o
d
algorithm
for
computing
'
should
assign
a
v
alue
of

to
the
unique
sense
of
attorney,
and
it
should
assign
a
high
v
alue
to
the
sense
of
c
ounsel
as
a
la
wy
er
who
pleads
cases
in
court.
Similarly
,
it
should
assign
high
v
alues
to
the
senses
of
trial
as
legal
pro
ceedings
consisting
of
the
judicial
examination
of
issues
b
y
a
comp
eten
t
tri-
bunal
the
determination
of
a
p
erson's
inno
cence
or
guilt
b
y
due
pro
cess
of
la
w.
It
should
also
assign
high
v
alues
to
the
senses
of
c
ourt
as
an
assem
bly
to
conduct
judicial
business
a
ro
om
in
whic
h
a
la
w
court
sits.
And
it
should
assign
a
high
v
alue
to
the
sense
of
judge
as
a
public
ocial
authorized
to
decide
questions
brough
t
b
efore
a
court
of
justice.
It
should
assign
lo
w
v
alues
of
'
to
the
v
arious
w
ord
senses
of
w
ords
in
this
cluster
that
are
asso
ciated
with
the
group
to
a
lesser
exten
t
or
not
at
all.
These
w
ould
include
the
sense
of
c
ounsel
as
direction
or
advice
as
to
a
decision
or
course
of
action;
similarly
,
a
lo
w
v
alue
of
'
should
b
e
assigned
to
other
senses
of
c
ourt
suc
h
as
.
See
Kro
v
etz
and
Kroft,
		
and
V
o
orhees,
		
for
exp
erimen
tation
and
discussion
of
the
eects
of
w
ord
sense
am
biguit
y
in
information
retriev
al.


----- Page 18 (native) -----
Resnik
Algorithm
(Resnik,
		a).
Giv
en
W
=
fw

;
:
:
:
;
w
n
g,
a
set
of
nouns:
for
i
and
j
=

to
n,
with
i
<
j
f
v
i;j
=
wsim(w
i
,
w
j
)
c
i;j
=
the
most
informativ
e
subsumer
for
w
i
and
w
j
for
k
=

to
n
um
senses(w
i
)
if
c
i;j
is
an
ancestor
of
sense
i;k
incremen
t
supp
ort[i,
k]
b
y
v
i;j
for
k
0
=

to
n
um
senses(w
j
)
if
c
i;j
is
an
ancestor
of
sense
j;k
0
incremen
t
supp
ort[j,
k']
b
y
v
i;j
incremen
t
normalization
[i]
b
y
v
i;j
incremen
t
normalization
[j]
b
y
v
i;j
g
for
i
=

to
n
for
k
=

to
n
um
senses(w
i
)
f
if
(normalization[i
]
>
0.0)
'
i;k
=
supp
ort[i,
k]
/
normalization[i]
else
'
i;k
=

/
n
um
senses(w
i
)
g
Figure
:
Disam
biguation
algorithm
for
noun
groupings
a
y
ard
wholly
or
partly
surrounded
b
y
w
alls
or
buildings.
The
disam
biguation
algorithm
for
noun
groups
is
giv
en
in
Figure
.
In
tuitiv
ely
,
when
t
w
o
p
olysemous
w
ords
are
similar,
their
most
informativ
e
subsumer
pro
vides
information
ab
out
whic
h
sense
of
eac
h
w
ord
is
the
relev
an
t
one.
This
observ
ation
is
similar
in
spirit
to
other
approac
hes
to
w
ord
sense
disam
biguation
based
on
maximizing
relatedness
of
meaning
(e.g.,
Lesk,
	;
Sussna,
		).
The
k
ey
idea
b
ehind
the
algorithm
is
to
consider
the
nouns
in
a
w
ord
group
pairwise.
F
or
eac
h
pair
the
algorithm
go
es
through
all
p
ossible
com
binations
of
the
w
ords'
senses,
and
assigns
\credit"
to
senses
on
the
basis
of
shared
information
con
ten
t,
as
measured
using
the
information
con
ten
t
of
the
most
informativ
e
subsumer.

As
an
example,
W
ordNet
lists
do
ctor
as
meaning
either
a
medical
do
ctor
or
someone
holding
a
Ph.D.,
and
lists
nurse
as
meaning
either
a
health
professional
or
a
nann
y
,
but
when
the
t
w
o
w
ords
are
considered
together,
the
medical
sense
of
eac
h
w
ord
is
ob
vious
to
the
h
uman
reader.
This
eect
nds
its
parallel
in
the
op
eration
of
the
algorithm.
Giv
en
a
taxonom
y
lik
e
that
of
Figure
,
consider
a
case
in
whic
h
the
set
W
of
w
ords
con
tains
w

=
do
ctor,
w

=
nurse,
and
w

=
actor.
In
the
rst
pairwise
comparison,
for
do
ctor
and
nurse,
.
In
Figure
,
the
square
brac
k
et
notation
highligh
ts
the
fact
that
support
is
a
matrix
and
normalizat
io
n
is
an
arra
y
.
Conceptually
v
and
c
are
(triangular)
matrices
also;
ho
w
ev
er,
I
use
subscripts
rather
than
square
brac
k
ets
b
ecause
at
implemen
tation
time
there
is
no
need
to
implemen
t
them
as
suc
h
since
the
v
alues
v
i;j
and
c
i;j
are
used
and
discarded
on
eac
h
pass
through
the
double
lo
op.


----- Page 19 (native) -----
Inf
orma
tion-Based
Semantic
Similarity
the
most
informativ
e
subsumer
is
c
;
=
heal
th
pr
ofessional,
whic
h
has
information
con
ten
t
v
;
=
..
Therefore
the
supp
ort
for
doctor
and
nurse
is
incremen
ted
b
y
..
Neither
doctor
nor
nurse
receiv
es
an
y
incremen
t
in
supp
ort
based
on
this
comparison,
since
neither
has
heal
th
pr
ofessional
as
an
ancestor.
In
the
second
pairwise
comparison,
the
most
informativ
e
subsumer
for
do
ctor
and
actor
is
c
;
=
person,
with
information
con
ten
t
v
;
=
.00,
and
so
there
is
an
incremen
t
b
y
that
amoun
t
to
the
supp
ort
for
doctor,
doctor,
and
a
ctor,
all
of
whic
h
ha
v
e
person
as
an
ancestor.
Similarly
,
in
the
third
pairwise
comparison,
the
most
informativ
e
subsumer
for
nurse
and
actor
is
also
person,
so
nurse,
nurse,
and
a
ctor
all
ha
v
e
their
supp
ort
incremen
ted
b
y
.00.
In
the
end,
therefore,
doctor
has
receiv
ed
supp
ort
:
+
:00
out
of
a
p
ossible
:
+
:00
for
all
the
pairwise
comparisons
in
whic
h
it
participated,
so
for
that
w
ord
sense
'
=
.
In
con
trast,
doctor
receiv
ed
supp
ort
in
the
amoun
t
of
.00
out
of
a
p
ossible
:
+
:00
for
the
comparisons
in
whic
h
it
w
as
in
v
olv
ed,
so
the
v
alue
of
'
for
doctor
is
:00
:+:00
=
0:.
Resnik
(		a)
illustrates
the
algorithm
of
Figure

using
w
ord
groupings
from
a
v
ariet
y
of
sources,
including
sev
eral
of
the
sources
on
distributional
clustering
cited
ab
o
v
e,
and
ev
aluates
the
algorithm
more
rigorously
on
the
task
of
asso
ciating
W
ordNet
senses
with
nouns
in
Roget's
thesaurus,
based
on
their
thesaurus
category
mem
b
ership.
On
a
v
erage,
the
algorithm
ac
hiev
ed
appro
ximately
	%
of
the
p
erformance
of
h
uman
annotators
p
erforming
the
same
task.

In
the
remainder
of
this
section
I
describ
e
a
new
application
of
the
algorithm,
and
ev
aluate
its
p
erformance.
.
Linking
to
W
ordNet
using
a
Bilingual
Dictionary
Multilingual
resources
for
natural
language
pro
cessing
can
b
e
dicult
to
obtain,
although
some
promising
eorts
are
underw
a
y
in
pro
jects
lik
e
EuroW
ordNet
(V
ossen,
		).
F
or
man
y
languages,
ho
w
ev
er,
suc
h
large-scale
resources
are
unlik
ely
to
b
e
a
v
ailable
in
the
near
future,
and
individual
researc
h
eorts
will
ha
v
e
to
con
tin
ue
to
build
from
scratc
h
or
to
adapt
existing
resources
suc
h
as
bilingual
dictionaries
(e.g.,
Kla
v
ans
&
Tzouk
ermann,
		).
In
this
section
I
describ
e
an
application
of
the
algorithm
of
Figure

to
the
English
denitions
in
the
CET
A
Chinese-English
dictionary
(CET
A,
	).
The
ultimate
task,
b
eing
undertak
en
in
the
con
text
of
a
Chinese-English
mac
hine
translation
pro
ject,
will
b
e
to
asso
ciate
Chinese
v
o
cabulary
items
with
no
des
in
W
ordNet,
m
uc
h
in
the
same
w
a
y
that
v
o
cabulary
in
Spanish,
Dutc
h,
and
Italian
are
asso
ciated
with
in
terlingual
taxonom
y
no
des
deriv
ed
from
the
American
W
ordNet,
in
the
EuroW
ordNet
pro
ject;
the
task
is
also
similar
to
attempts
to
relate
dictionaries
and
thesauri
monolingually
(e.g.,
see
Section
.
and
Ji,
Gong,
&
Huang,
		).
The
presen
t
study
in
v
estigates
the
exten
t
to
whic
h
seman
tic
similarit
y
migh
t
b
e
useful
in
partially
automating
the
pro
cess.
.
The
task
w
as
p
erformed
indep
enden
tl
y
b
y
t
w
o
h
uman
judges.
T
reating
Judge

as
the
b
enc
hmark
the
accuracies
ac
hiev
ed
b
y
Judge
,
the
algorithm,
and
random
selection
w
ere
resp
ectiv
ely
.%,
.%,
and
.%;
treating
Judge

as
the
b
enc
hmark
the
accuracies
ac
hiev
ed
b
y
Judge
,
the
algorithm,
and
random
selection
w
ere
resp
ectiv
ely
.%,
0.%,
and
.%.
As
the
relativ
ely
lo
w
accuracies
for
h
uman
judges
demonstrate,
disam
biguation
using
W
ordNet's
ne-grained
senses
is
quite
a
bit
more
dicult
than
disam
biguati
on
to
the
lev
el
of
homographs
(Hearst,
		;
Co
wie,
Guthrie,
&
Guthrie,
		).
Resnik
and
Y
aro
wsky
(		,
			)
discuss
the
implicati
ons
of
W
ordNet's
ne-grainedness
for
ev
aluation
of
w
ord
sense
disam
biguatio
n,
and
consider
alternativ
e
ev
aluation
metho
ds.


----- Page 20 (native) -----
Resnik
F
or
example,
consider
the
follo
wing
dictionary
en
tries:
(a)
:
.
hliti
brother-in-la
w
(h
usband's
elder
brother)
.
hregi
father
.
hregi
uncle
(father's
elder
brother)
.
uncle
(form
of
address
to
an
older
man)
(b)
:
actress,
pla
y
er
of
female
roles.
In
order
to
asso
ciate
Chinese
terms
suc
h
as
these
with
the
W
ordNet
noun
taxonom
y
,
it
is
imp
ortan
t
to
a
v
oid
asso
ciations
with
inappropriate
senses
|
for
example,
the
w
ord
in
en
try
(a),
,
should
clearly
not
b
e
asso
ciated
with
father
in
its
W
ordNet
senses
as
Ch
urc
h
F
ather,
priest,
Go
d-the-F
ather,
or
founding
father.

Although
one
traditional
approac
h
to
using
dictionary
en
tries
has
b
een
to
compute
w
ord
o
v
erlap
with
resp
ect
to
dictionary
denitions
(e.g.,
Lesk,
	),
the
English
glosses
in
the
CET
A
dictionary
are
generally
to
o
short
to
tak
e
adv
an
tage
of
w
ord
o
v
erlap
in
this
fashion.
Ho
w
ev
er,
man
y
of
the
denitions
do
ha
v
e
a
useful
prop
ert
y:
they
p
ossess
m
ultiple
sub-
denitions
that
are
similar
in
meaning,
as
in
the
cases
illustrated
ab
o
v
e.
Although
one
cannot
alw
a
ys
assume
that
this
is
so,
e.g.,
(c)
:
.
case
(i.e.,
upp
er
case
or
lo
w
er
case)
.
dial
(of
a
w
atc
h,
etc.),
insp
ection
of
the
dictionary
conrms
that
when
m
ultiple
denitions
are
presen
t
they
tend
more
to
w
ard
p
olysem
y
than
homon
ym
y
.
Based
on
this
observ
ation,
I
conducted
an
exp
erimen
t
to
assess
the
exten
t
to
whic
h
the
w
ord
sense
disam
biguation
algorithm
of
Figure

can
b
e
used
to
iden
tify
relev
an
t
noun
senses
in
W
ordNet
for
Chinese
w
ords
in
the
CET
A
dictionary
,
using
the
English
denitions
as
the
source
of
similar
nouns
to
disam
biguate.
Nouns
heading
denitional
noun
phrases
w
ere
extracted
automatically
via
simple
heuristic
metho
ds,
for
a
randomly-selected
sample
of
00
dictionary
en
tries
con
taining
m
ultiple
denitions
to
b
e
used
as
a
test
set.
F
or
example,
the
noun
groups
asso
ciated
with
the
denitions
ab
o
v
e
w
ould
b
e
(a')
uncle,
brother-in-la
w,
father
(b')
actress,
pla
y
er.
W
ordNet's
noun
database
w
as
used
to
automatically
iden
tify
comp
ound
nominals
where
p
ossible.
So,
for
example,
a
w
ord
dened
as
\record
pla
y
er"
w
ould
ha
v
e
the
comp
ound
r
e
c
or
d
player
rather
than
player
as
its
head
noun
b
ecause
r
e
c
or
d
player
is
a
comp
ound
noun
kno
wn
to
W
ordNet.

It
should
b
e
noted
that
no
attempt
w
as
made
to
exclude
dictionary
en
tries
lik
e
(c)
when
creating
the
test
set.
Since
in
general
there
is
no
w
a
y
to
automatically
iden
tify
alternativ
e
denitions
distinguished
b
y
synon
ym
y
from
those
distinguished
b
y
homon
ym
y
,
suc
h
en
tries
m
ust
b
e
faced
b
y
an
y
disam
biguation
algorithm
for
this
task.
Tw
o
indep
enden
t
judges
w
ere
recruited
for
assistance
in
annotating
the
test
set,
one
a
nativ
e
Chinese
sp
eak
er,
and
the
second
a
Chinese
language
exp
ert
for
the
United
States
go
v
ernmen
t.
These
judges
indep
enden
tly
annotated
the
00
test
items.
F
or
eac
h
item,
.
Annotations
within
the
dictionary
en
tries
suc
h
as
<lit>
(literary),
<reg>
(regional),
and
the
lik
e
are
ignored
b
y
the
algorithm
describ
ed
in
this
section.
.
W
ordNet
v
ersion
.
w
as
used
for
this
exp
erimen
t.


----- Page 21 (native) -----
Inf
orma
tion-Based
Semantic
Similarity
F
or
eac
h
W
ordNet
denition,
y
ou
will
see

b
o
xes:
,
,
,
,
,
and
is-a.
F
or
eac
h
denition:

if
y
ou
think
the
Chinese
w
ord
c
an
have
that
me
aning,
select
the
n
um
b
er
corresp
onding
to
y
our
condence
in
that
c
hoice,
where

is
lo
w
est
condence
and

is
highest
condence.

If
the
Chinese
w
ord
cannot
ha
v
e
that
meaning,
but
can
ha
v
e
a
mor
e
sp
e
cic
meaning,
select
is-a.
F
or
example,
if
the
Chinese
w
ord
means
\truc
k"
and
the
W
ordNet
denition
is
\automotiv
e
v
ehicle:
self-prop
elled
wheeled
v
ehicle",
y
ou
w
ould
select
this
option.
(That
is,
it
mak
es
sense
to
sa
y
that
this
Chinese
w
ord
describ
es
a
concept
that
IS
A
KIND
OF
a
utomotive
vehicle.)
Then
pic
k
,
,
,
,
or

as
y
our
condence
in
this
decision,
again
with

as
lo
w
est
condence
and

as
highest
condence.

If
neither
of
the
ab
o
v
e
cases
apply
for
this
W
ordNet
denition,
don't
c
hec
k
o
an
ything
for
this
denition.
Figure
:
Instructions
for
h
uman
judges
selecting
senses
asso
ciated
with
Chinese
w
ords
the
judge
w
as
giv
en
the
Chinese
w
ord,
its
full
CET
A
dictionary
denition
(as
in
examples
a{c),
and
a
list
of
all
the
W
ordNet
sense
descriptions
asso
ciated
with
an
y
sense
of
an
y
head
noun
in
the
asso
ciated
noun
group.
F
or
example,
the
list
corresp
onding
to
the
follo
wing
dictionary
denition
(d)
:
urgen
t
message,
urgen
t
dispatc
h
w
ould
con
tain
the
follo
wing
W
ordNet
sense
descriptions,
as
generated
via
the
head
nouns
message
and
disp
atch:

message,
con
ten
t,
sub
ject
matter,
substance:
what
a
comm
unication
that
is
ab
out
something
is
ab
out

dispatc
h,
exp
edition,
exp
editiousness,
fastness:
sub
concept
of
celerit
y
,
quic
k-
ness,
rapidit
y

dispatc
h,
despatc
h,
comm
unique:
an
ocial
rep
ort
(usually
sen
t
in
haste)

message:
a
comm
unication
(usually
brief
)
that
is
written
or
sp
ok
en
or
signaled;
\he
sen
t
a
three-w
ord
message"

dispatc
h,
despatc
h,
shipmen
t:
the
act
of
sending
o
something

dispatc
h,
despatc
h:
the
m
urder
or
execution
of
someone
F
or
eac
h
item,
the
judge
w
as
rst
ask
ed
whether
he
knew
that
Chinese
w
ord
in
that
meaning;
if
the
resp
onse
w
as
negativ
e,
he
w
as
instructed
to
pro
ceed
to
the
next
item.
F
or
items
with
kno
wn
w
ords,
the
judges
w
ere
instructed
as
in
Figure
.
Although
the
use
of
the
is-a
selection
w
as
not
used
in
the
analysis
of
the
results,
it
w
as
imp
ortan
t
to
include
it
b
ecause
it
pro
vided
the
judges
with
a
w
a
y
to
indicate
where
a
Chinese
w
ord
could
b
est
b
e
classied
in
the
W
ordNet
noun
taxonom
y
,
without
ha
ving
to
assert
translational
equiv
alence
b
et
w
een
the
Chinese
concept
and
a
close
W
ordNet
(English)
concept.
So,
for
example,
a
judge
could
classify
the
w
ord
(the
spring
festiv
al,
lunar
new
y
ear,
Chinese
new
y
ear)
as
b
elonging
under
the
W
ordNet
sense
glossed
as
festiv
al:
a
da
y
or
p
erio
d
of
time
set
aside
for
feasting
and
celebration,


----- Page 22 (native) -----
Resnik
the
most
sensible
c
hoice
giv
en
that
\Chinese
New
Y
ear"
do
es
not
app
ear
as
a
W
ordNet
concept.
Annotating
the
is-a
relationship
for
the
set
w
as
also
imp
ortan
t
b
ecause
the
al-
gorithm
b
eing
ev
aluated
w
as
w
orking
on
groups
of
head
nouns,
thereb
y
p
oten
tially
losing
information
p
oin
ting
to
a
more
sp
ecic
concept
reading.
F
or
example,
the
denition
(e)
:
steel
tub
e,
steel
pip
e
w
ould
b
e
giv
en
to
the
algorithm
as
a
group
con
taining
head
nouns
tub
e
and
pip
e.
Once
the
test
set
w
as
annotated,
ev
aluation
w
as
done
according
to
t
w
o
paradigms:
sele
ction
and
ltering.
In
b
oth
paradigms
w
e
assume
that
for
eac
h
en
try
in
the
test
set,
an
annotator
has
correctly
sp
ecied
whic
h
W
ordNet
senses
are
to
b
e
considered
c
orr
e
ct,
and
whic
h
are
inc
orr
e
ct.
An
algorithm
b
eing
tested
against
this
set
m
ust
iden
tify
,
for
eac
h
listed
sense,
whether
that
sense
should
b
e
include
d
for
that
item
or
whether
it
should
b
e
exclude
d.
F
or
example,
the
W
ordNet
sense
corresp
onding
to
\the
m
urder
or
execution
of
someone"
w
ould
b
e
iden
tied
b
y
an
annotator
as
incorrect
for
(d),
and
so
an
algorithm
marking
it
as
\included"
should
b
e
p
enalized.
F
or
the
sele
ction
p
ar
adigm,
the
goal
is
to
iden
tify
W
ordNet
senses
to
include.
W
e
can
therefore
dene
precision
in
that
paradigm
as
P
selection
=
n
um
b
er
of
correctly
included
senses
n
um
b
er
of
included
senses
(0)
and
recall
as
R
selection
=
n
um
b
er
of
correctly
included
senses
n
um
b
er
of
correct
senses
:
()
These
corresp
ond
directly
to
the
use
of
precision
and
recall
in
information
retriev
al.
Preci-
sion
b
egins
with
the
set
of
senses
included
b
y
some
metho
d,
and
computes
the
prop
ortion
of
these
that
are
correct.
Recall
b
egins
with
the
set
of
senses
that
should
ha
v
e
b
een
included,
and
computes
the
prop
ortion
of
these
that
the
metho
d
actually
managed
to
c
ho
ose.
Since
the
n
um
b
er
of
p
oten
tial
W
ordNet
senses
for
an
item
can
b
e
quite
large,
an
equally
v
alid
alternativ
e
to
the
selection
paradigm
is
what
I
will
call
the
ltering
p
ar
adigm,
according
to
whic
h
the
goal
is
to
iden
tify
W
ordNet
senses
to
exclude.
One
can
easily
imagine
this
b
eing
the
more
relev
an
t
paradigm
|
for
example,
in
a
semi-automated
setting
where
one
wishes
to
reduce
the
burden
of
a
user
selecting
among
alternativ
es.
In
the
ltering
paradigm
one
can
dene
ltering
precision
as
P
ltering
=
n
um
b
er
of
correctly
excluded
senses
n
um
b
er
of
excluded
senses
()
and
ltering
recall
as
R
ltering
=
n
um
b
er
of
correctly
excluded
senses
n
um
b
er
of
senses
lab
eled
incorrect
:
()
In
the
ltering
paradigm,
precision
b
egins
with
the
set
of
senses
that
the
metho
d
ltered
out
and
computes
the
prop
ortion
that
w
ere
c
orr
e
ctly
ltered
out.
And
recall
in
ltering
b
egins
with
the
set
of
senses
that
should
ha
v
e
b
een
excluded
(i.e.
the
incorrect
ones)
and
computes
the
prop
ortion
of
these
that
the
metho
d
actually
managed
to
exclude.


----- Page 23 (native) -----
Inf
orma
tion-Based
Semantic
Similarity
Sense
Selection
Sense
Filtering
Precision
(%)
Recall
(%)
Precision
(%)
Recall
(%)
Random
	.
.
.0
.
Algorithm
.	
	.	
	.
	.
Judge

.
.
	.	
	.
T
able
	:
Ev
aluation
using
Judge

as
the
reference
standard,
considering
items
selected
with
condence

and
ab
o
v
e.
Judge

Algorithm
Random
Include
Exclude
Include
Exclude
Include
Exclude
Judge

Include
0





Exclude


		
0


T
able
0:
Agreemen
t
and
disagreemen
t
with
Judge

T
able
	
sho
ws
the
precision/recall
gures
using
the
judgmen
ts
of
Judge
,
the
nativ
e
Chinese
sp
eak
er,
as
a
reference
standard,
considering
only
kno
wn
items
selected
with
con-
dence

and
ab
o
v
e.

The
algorithm
recorded
all
00
items
as
kno
wn,
and
its
condence
v
alues
w
ere
scaled
linearly
from
con
tin
uous
v
alues
in
range
[0,]
to
discrete
v
alues
from

to
.
The
table
sho
ws
the
algorithm's
results
with
its
c
hoice
thresholded
at
condence
,
and
Figure

sho
ws
ho
w
recall
and
precision
v
ary
as
the
condence
threshold
c
hanges.
As
a
lo
w
er
b
ound
for
comparison,
an
algorithm
w
as
implemen
ted
that
considered
eac
h
w
ord
sense
for
eac
h
item,
selecting
that
sense
probabilisticall
y
(with
complete
condence)
in
suc
h
a
w
a
y
as
to
mak
e
the
a
v
erage
n
um
b
er
of
senses
p
er
item
as
close
as
p
ossible
to
the
a
v
erage
n
um
b
er
of
senses
p
er
item
in
the
reference
standard
(.
senses).
Figures
for
the
random
baseline
are
the
a
v
erage
o
v
er
0
runs.
T
able
0
illustrates
the
c
hoices
underlying
those
gures;
for
example,
there
w
ere

senses
that
the
random
pro
cedure
c
hose
to
include
that
w
ere
also
included
b
y
Judge
.
The
fact
that
Judge

has
suc
h
lo
w
precision
and
recall
for
selection
indicates
that
matc
hing
the
c
hoices
of
an
indep
enden
t
judge
is
indeed
a
dicult
task.
This
is
unsurpris-
ing,
giv
en
previous
exp
erience
with
the
problem
of
selecting
among
W
ordNet's
ne-grained
senses
(Resnik,
		a;
Resnik
&
Y
aro
wsky
,
		).
The
results
clearly
sho
w
that
the
algo-
rithm
is
b
etter
than
the
baseline,
but
also
indicate
that
it
is
o
v
ergenerating
senses,
whic
h
h
urts
selection
precision.
In
terms
of
ltering,
when
the
algorithm
c
ho
oses
to
lter
out
a
sense
it
tends
to
do
so
reliably
(ltering
precision).
Ho
w
ev
er,
its
prop
ensit
y
to
w
ard
o
v
ergen-
eration
is
reected
in
its
b
elo
w-baseline
p
erformance
on
ltering
recall;
that
is,
the
algorithm
is
c
ho
osing
to
allo
w
in
senses
that
it
should
b
e
ltering
out.
.
Judge
,
the
nativ
e
sp
eak
er
of
Chinese,
iden
tied

of
the
w
ords
as
kno
wn
to
him;
Judge

iden
tied
	.
This
on-line
dictionary
w
as
constructed
from
a
large
v
ariet
y
of
lexical
resources,
and
includes
a
great
man
y
uncommon
w
ords,
arc
haic
usages,
regionalisms,
and
the
lik
e.


----- Page 24 (native) -----
Resnik
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
Precision
Recall
Filtering: Algorithm
Human
Random
Selection: Algorithm
Human
Random
Figure
:
Precision/recall
curv
es
using
Judge

as
the
reference
standard,
v
arying
the
con-
dence
threshold
This
pattern
of
results
suggests
that
the
b
est
use
of
this
algorithm
at
its
presen
t
lev
el
of
p
erformance
w
ould
b
e
as
a
lter
for
a
lexical
acquisition
pro
cess
with
a
h
uman
in
the
lo
op,
dividing
candidate
W
ordNet
senses
for
dictionary
en
tries
according
to
higher
and
lo
w
er
priorit
y
.
F
or
Chinese-English
dictionary
en
tries
that
serv
e
as
appropriate
input
to
the
algorithm
(of
whic
h
there
are
appro
ximately
000
in
the
CET
A
dictionary),
if
a
W
ordNet
sense
is
not
selected
b
y
the
algorithm
with
a
condence
at
least
equal
to

it
should
b
e
demoted
to
the
lo
w
er
priorit
y
group
in
the
presen
tation
of
alternativ
es,
since
the
algorithm's
c
hoice
to
exclude
a
sense
is
correct
appro
ximately
	%
of
the
time.
Those
senses
that
are
selected
b
y
the
algorithm
are
not
ne
c
essarily
to
b
e
included
|
the
h
uman
judge
is
still
needed
to
mak
e
the
selection,
since
selection
precision
is
lo
w
|
but
the
algorithm
tends
to
err
on
the
side
of
caution,
and
so
correct
senses
will
b
e
found
in
the
higher
priorit
y
group
some
0%
of
the
time.
.
Linking
to
W
ordNet
from
an
English
Dictionary/Thesaurus
The
results
on
W
ordNet
sense
selection
using
a
bilingual
dictionary
demonstrate
that
the
algorithm
of
Figure

do
es
a
go
o
d
job
of
assigning
lo
w
scores
to
W
ordNet
senses
that
should
b
e
ltered
out,
ev
en
if
it
should
probably
not
b
e
trusted
to
mak
e
categorical
decisions.
One
application
prop
osed
as
suitable,
therefore,
w
as
helping
to
iden
tify
whic
h
senses
should
b
e
ltered
out
within
a
semi-automated
pro
cess
of
lexical
acquisition.
Here
I
describ
e
a
closely
related,
real-w
orld
application
for
whic
h
the
algorithm
has
b
een
deplo
y
ed:
adding
p
oin
ters
in
to
W
ordNet
from
an
on-line
dictionary/thesaurus
on
the
W
eb.
The
con
text
of
this
application
is
the
W
ordsm
yth
English
Dictionary-Thesaurus
(WEDT,
http://www.wordsmyth.net/)
,
an
on-line
educational
dictionary
aliated
with
the
AR
TFL
text
database
pro
ject
(http://humanities.uchic
ago.edu/
ARTFL/;
Morrissey
,
		).
It
has
b
een
designed
to
b
e
useful
in
educational
con
texts,
and,
as
part
of
that
design,
it
in
tegrates
a
thesaurus
within
the
structure
of
the
dictionary
.
As
illustrated
in
Figure
,


----- Page 25 (native) -----
Inf
orma
tion-Based
Semantic
Similarity
bar
SYL:
bar

PR
O:
bar
POS:
noun
DEF:
.
a
length
of
solid
material,
usu.
rectangular
or
cylindrical
:
EXA:
a
b
ar
of
so
ap;
EXA:
a
c
andy
b
ar;
EXA:
an
ir
on
b
ar.
SYN:
ro
d
(),
stic
k

(,,)
SIM:
p
ole

,
shaft,
stak
e

,
ingot,
blo
c
k,
rail

,
railing,
cro
wbar,
jimm
y
,
lev
er
DEF:
.
an
ything
that
acts
as
a
restrain
t
or
hindrance.
SYN:
blo
c
k
(0),
hindrance
(),
obstruction
(),
imp
edimen
t
(),
obstacle,
barrier
(,),
stop
()
SIM:
barricade,
blo
c
k
ade,
deterren
t,
h
urdle,
curb,
stum
bling
blo
c
k,
snag,
jam

,
shoal

,
reef

,
sandbar
.
.
.
Figure
:
Example
from
the
W
ordsm
yth
English
Dictionary-Thesaurus
(WEDT)
WEDT
con
tains
traditional
dictionary
information,
suc
h
as
part
of
sp
eec
h,
pron
unciation,
and
denitional
information,
but
in
man
y
cases
also
includes
p
oin
ters
to
synon
yms
(SYN)
or
similar
w
ords
(SIM).
Within
the
on-line
dictionary
,
these
thesaurus
items
are
h
yp
erlinks
|
for
example,
stak
e

is
a
link
to
the
rst
WEDT
en
try
for
stake
|
and
paren
thetical
n
um
b
ers
refer
to
sp
ecic
denitions
within
an
en
try
.
The
thesaurus-lik
e
grouping
of
similar
w
ords
pro
vides
an
opp
ortunit
y
to
exploit
the
algorithm
for
disam
biguating
noun
groupings
b
y
automatically
linking
WEDT
en
tries
to
W
ordNet.
The
v
alue
in
linking
these
t
w
o
resources
comes
from
their
compatabilit
y
,
in
that
b
oth
ha
v
e
prop
erties
of
b
oth
a
thesaurus
and
a
dictionary
,
as
w
ell
as
from
their
complemen-
tarit
y:
b
ey
ond
b
eing
an
alternativ
e
source
of
denitional
information
and
lists
of
synon
yms,
W
ordNet
pro
vides
ordering
of
w
ord
senses
b
y
frequency
,
estimates
of
w
ord
familiarit
y
,
p
ar
t-
of
relationships,
and
of
course
the
o
v
erall
taxonomic
organization
illustrated
in
Figures

and
.
Figure

sho
ws
ho
w
taxonomic
information
is
presen
ted
using
the
W
ordNet
W
eb
serv
er
(http://www.cogsci.prin
ceton.ed
u/cgi-b
in/webw
n/).
In
a
collab
oration
with
WEDT
and
AR
TFL,
I
ha
v
e
tak
en
the
noun
en
tries
from
the
WEDT
dictionary
and,
for
eac
h
grouping
of
similar
w
ords,
added
a
set
of
exp
erimen
tal
h
yp
erlinks
to
W
ordNet
en
tries
on
the
W
ordNet
W
eb
serv
er.
Figure

sho
ws
ho
w
the
exp
er-
imen
tal
W
ordNet
links
(XWN)
lo
ok
to
the
WEDT
user.
Links
to
W
ordNet
senses,
suc
h
as
p
ole

,
app
ear
together
with
the
condence
lev
el
assigned
b
y
the
sense
disam
biguation
al-
gorithm;
senses
with
condence
less
than
a
threshold
are
not
presen
ted.
	
When
an
XWN
h
yp
erlink
is
selected
b
y
the
user,
W
ordNet
taxonomic
information
for
the
selected
sense
app
ears
in
a
parallel
bro
wser
windo
w,
as
in
Figure
.
F
rom
this
windo
w,
the
user
has
an
en
try
p
oin
t
in
to
the
other
capabilities
of
the
W
ordNet
w
eb
serv
er.
F
or
example,
one
migh
t
c
ho
ose
to
lo
ok
at
all
the
W
ordNet
senses
for
p
ole
as
	.
The
curren
t
threshold,
0.,
w
as
c
hosen
man
ually
.
It
ma
y
b
e
sub-optimal
but
I
ha
v
e
found
that
it
w
orks
w
ell
in
practice.


----- Page 26 (native) -----
Resnik
Sense

pole
(a
long
(usually
round)
rod
of
wood
or
metal
or
plastic)
=>
rod
(a
long
thin
implement
made
of
metal
or
wood)
=>
implement
(a
piece
of
equipment
or
tool
used
to
effect
an
end)
=>
instrumen
ta
lit
y,
instrument
at
ion
(an
artifact
(or
system
of
artifacts)
that
is
instrumen
ta
l
in
accomplishi
ng
some
end)
=>
artifact,
artefact
(a
man-made
object)
=>
object,
physical
object
(a
physical
(tangible
and
visible)
entity;
``it
was
full
of
rackets,
balls
and
other
objects'')
=>
entity,
something
(anythin
g
having
existence
(living
or
nonliving
))
Figure
:
W
ordNet
en
try
(h
yp
ern
yms)
for
p
ole

bar
SYL:
bar

PR
O:
bar
POS:
noun
DEF:
.
a
length
of
solid
material,
usu.
rectangular
or
cylindrica
l:
EXA:
a
b
ar
of
so
ap;
EXA:
a
c
andy
b
ar;
EXA:
an
ir
on
b
ar.
SYN:
ro
d
(),
stic
k

(,,)
SIM:
p
ole

,
shaft,
stak
e

,
ingot,
blo
c
k,
rail

,
railing,
cro
wbar,
jimm
y
,
lev
er
XWN:
p
ole

(0.)
ingot

(.00)
blo
c
k

(0.)
rail

(0.	)
railing

(.00)
cro
wbar

(.00)
jimm
y

(.00)
lev
er

(0.)
lev
er(0.)
lev
er(0.)
DEF:
.
an
ything
that
acts
as
a
restrain
t
or
hindrance.
SYN:
blo
c
k
(0),
hindrance
(),
obstruction
(),
imp
edimen
t
(),
obstacle,
barrier
(,),
stop
()
SIM:
barricade,
blo
c
k
ade,
deterren
t,
h
urdle,
curb,
stum
bling
blo
c
k,
snag,
jam

,
shoal

,
reef

,
sandbar
XWN:
barricade

(.00)
barricade(.00)
blo
c
k
ade

(0.)
blo
c
k
ade

(0.)
deterren
t

(.00)
h
urdle

(0.0)
h
urdle

(0.)
curb

(0.)
curb

(0.)
curb

(0.	)
curb

(0.)
stum
bling
blo
c
k

(.00)
snag

(.00)
jam

(0.)
shoal

(0.)
shoal(0.	)
reef

(.00)
sandbar

(.00)
.
.
.
Figure
:
Example
from
WEDT
with
exp
erimen
tal
W
ordNet
links
0

----- Page 27 (native) -----
Inf
orma
tion-Based
Semantic
Similarity
.
p
ole
{
(a
long
(usually
round)
ro
d
of
w
o
o
d
or
metal
or
plastic)
.
P
ole
{
(a
nativ
e
or
inhabitan
t
of
P
oland)
.
p
ole
{
(one
of
t
w
o
div
ergen
t
or
m
utually
exclusiv
e
opinions;
\they
are
at
opp
osite
p
oles"
or
\they
are
p
oles
apart")
.
p
erc
h,
ro
d,
p
ole
{
((British)
a
linear
measure
of
.
feet)
.
p
erc
h,
ro
d,
p
ole
{
(a
square
ro
d
of
land)
.
p
ole,
celestial
p
ole
{
(one
of
t
w
o
p
oin
ts
of
in
tersection
of
the
Earth's
axis
and
the
celestial
sphere)
.
p
ole
{
(one
of
t
w
o
an
tip
o
dal
p
oin
ts
where
the
Earth's
axis
of
rotation
in
tersects
the
Earth's
surface)
.
terminal,
p
ole
{
(a
p
oin
t
on
an
electrical
device
(suc
h
as
a
battery)
at
whic
h
electric
curren
t
en
ters
or
lea
v
es)
	.
p
ole
{
(a
long
b
erglass
implemen
t
used
for
p
ole
v
aulting)
0.
p
ole,
magnetic
p
ole
{
(one
of
the
t
w
o
ends
of
a
magnet
where
the
magnetism
seems
to
b
e
concen
trated)
Figure
	:
List
of
W
ordNet
senses
for
p
ole
a
noun,
displa
y
ed
as
in
Figure
	.
Notice
that
if
a
user
of
WEDT
had
simply
gone
directly
to
the
W
ordNet
serv
er
to
lo
ok
up
p
ole,
the
full
list
of
0
senses
w
ould
ha
v
e
app
eared
with
no
indication
of
whic
h
are
most
p
oten
tially
related
to
the
WEDT
dictionary
en
try
under
consideration.
In
con
trast,
the
WEDT
h
yp
erlinks,
in
tro
duced
via
the
sense
selection
algorithm,
lter
out
the
ma
jorit
y
of
the
irrelev
an
t
senses
and
pro
vide
the
user
a
measure
of
condence
in
selecting
among
those
that
remain.
Although
no
formal
ev
aluation
of
the
WEDT/W
ordNet
connection
has
b
een
attempted,
the
results
of
the
bilingual
dictionary
exp
erimen
t
suggest
that
this
application
of
w
ord
sense
disam
biguation
|
ltering
out
the
least
relev
an
t
senses,
and
then
lea
ving
the
user
in
the
lo
op
|
is
a
task
for
whic
h
the
sense
disam
biguation
algorithm
is
w
ell
suited.
This
is
supp
orted
b
y
user
feedbac
k
on
the
XWN
feature
of
WEDT,
whic
h
has
b
een
fa
v
orable
(Rob
ert
P
arks,
p
ersonal
comm
unication).
The
site
has
b
een
gro
wing
in
p
opularit
y
,
with
a
curren
t
estimate
of
000-00
hits
p
er
da
y
.
.
Related
W
ork
There
is
an
extensiv
e
literature
on
measuring
similarit
y
in
general,
and
on
w
ord
similarit
y
in
particular;
for
a
classic
pap
er
see
Tv
ersky
(	).
Recen
t
w
ork
in
information
retriev
al
and
computational
linguistics
has
emphasized
a
distributional
approac
h,
in
whic
h
w
ords
are
represen
ted
as
v
ectors
in
a
space
of
features
and
similarit
y
measures
are
dened
in
terms
of
those
v
ectors;
see
Resnik
(		b)
for
discussion,
and
Lee
(		)
for
a
go
o
d
recen
t
example.
Common
to
the
traditional
and
the
distributional
approac
hes
is
the
idea
that
w
ord
or
concept
represen
tations
include
explicit
features,
whether
those
features
are
sp
ecied
in
a
kno
wledge-based
fashion
(e.g.,
do
g
migh
t
ha
v
e
features
lik
e
mammal,
lo
y
al)
or
dened
in
terms
of
distributional
con
text
(e.g.,
do
g
migh
t
ha
v
e
features
lik
e
\observ
ed
within

w
ords
of
how
l).
This
represen
tational
assumption
con
trasts
with
the
assumptions
em
b
o
died
in
a
taxonomic
represen
tation,
where
most
often
the
is-a
relation
stands
b
et
w
een
non-
decomp
osed
concepts.
The
t
w
o
are
not
inconsisten
t,
of
course,
since
concepts
in
a
taxonom
y


----- Page 28 (native) -----
Resnik
sometimes
c
an
b
e
decomp
osed
in
to
explicit
features,
and
the
is-a
relation,
as
it
is
usually
in
terpreted,
implies
inheritance
of
features
whether
they
are
explicit
or
implicit.
In
that
resp
ect,
the
traditional
approac
h
of
coun
ting
edges
can
b
e
view
ed
as
a
particularly
simple
appro
ximation
to
a
similarit
y
measure
based
on
coun
ting
feature
dierences,
under
the
assumption
that
an
edge
exists
to
indicate
a
dierence
of
at
least
one
feature.
Information-theoretic
concepts
and
tec
hniques
ha
v
e,
in
recen
t
y
ears,
emerged
from
the
sp
eec
h
recognition
comm
unit
y
to
nd
wide
application
in
natural
language
pro
cessing;
e.g.,
see
Ch
urc
h
and
Mercer
(		).
The
information
of
an
ev
en
t
is
a
fundamen
tal
notion
in
sto
c
hastic
language
mo
deling
for
sp
eec
h
recognition,
where
the
con
tribution
of
a
correct
w
ord
prediction
based
on
its
conditional
probabilit
y
,
p(w
ordjcon
text
),
is
measured
as
the
information
con
v
ey
ed
b
y
that
prediction,
 log
p(w
ordjcon
text
).
This
forms
the
basis
for
standard
measures
of
language
mo
del
p
erformance,
suc
h
as
cross
en
trop
y
.
F
requency
of
shared
and
unshared
features
has
also
long
b
een
a
factor
in
computing
similarit
y
o
v
er
v
ec-
tor
represen
tations.
The
in
v
erse
do
cumen
t
frequency
(idf
)
for
term
w
eigh
ting
in
information
retriev
al
mak
es
use
of
logarithmic
scaling,
and
serv
es
to
iden
tify
terms
that
do
not
discrim-
inate
w
ell
among
dieren
t
do
cumen
ts,
a
concept
v
ery
similar
in
spirit
to
the
idea
that
suc
h
terms
ha
v
e
lo
w
information
con
ten
t
(Salton,
		).
Although
the
coun
ting
of
edges
in
is-a
taxonomies
seems
to
b
e
something
man
y
p
eople
ha
v
e
tried,
there
seem
to
b
e
few
published
descriptions
of
attempts
to
directly
ev
aluate
the
eectiv
eness
of
this
metho
d.
A
n
um
b
er
of
researc
hers
ha
v
e
attempted
to
mak
e
use
of
conceptual
distance
in
information
retriev
al.
F
or
example,
Rada
et
al.
(		,
		)
and
Lee
et
al.
(		)
rep
ort
exp
erimen
ts
using
conceptual
distance,
implemen
ted
using
the
edge-
coun
ting
metric,
as
the
basis
for
ranking
do
cumen
ts
b
y
their
similarit
y
to
a
query
.
Sussna
(		)
uses
seman
tic
relatedness
measured
with
W
ordNet
in
w
ord
sense
disam
biguation,
dening
a
measure
of
distance
that
w
eigh
ts
dieren
t
t
yp
es
of
links
and
also
explicitly
tak
es
depth
in
the
taxonom
y
in
to
accoun
t.
F
ollo
wing
the
original
prop
osal
to
measure
seman
tic
similarit
y
in
a
taxonom
y
using
information
con
ten
t
(Resnik,
		b,
		a),
a
n
um
b
er
of
related
prop
osals
ha
v
e
b
een
ex-
plored.
Leaco
c
k
and
Cho
doro
w
(		)
dene
a
measure
resem
bling
information
con
ten
t,
but
using
the
normalized
path
length
b
et
w
een
the
t
w
o
concepts
b
eing
compared
rather
than
the
probabilit
y
of
a
subsuming
concept.
Sp
ecically
,
they
dene
wsim
ndist
(w

;
w

)
=
 log


min
c

;
c

len
(c

;
c

)
(

max)


:
()
(The
notation
ab
o
v
e
is
the
same
as
for
Equation
().)
In
addition
to
this
denition,
they
also
include
sev
eral
sp
ecial
cases,
most
notably
to
a
v
oid
innite
similarit
y
when
c

and
c

are
exact
synon
yms
and
th
us
ha
v
e
a
path
length
of
0.
Leaco
c
k
and
Cho
doro
w
ha
v
e
exp
erimen
ted
with
this
measure
and
the
information
con
ten
t
measure
describ
ed
here
in
the
con
text
of
w
ord
sense
disam
biguation,
and
found
that
they
yield
roughly
similar
results.
Implemen
ting
their
metho
d
and
testing
it
on
the
task
rep
orted
in
Section
,
I
found
that
it
actually
outp
erformed
the
information-based
measure
sligh
tly
on
that
data
set;
ho
w
ev
er,
in
a
follo
w-up
exp
erimen
t
using
a
dieren
t
and
larger
set
of
noun
pairs
(00
items),
the
information-based
measure
p
erformed
signican
tly
b
etter
(T
able
).
Analyzing
the
dierences
b
et
w
een
the
t
w
o
studies
is
illuminating.
In
the
follo
w-up
ex-
p
erimen
t,
I
used
netnews
arc
hiv
es
to
gather
highly
frequen
t
nouns
within
related
topic
areas


----- Page 29 (native) -----
Inf
orma
tion-Based
Semantic
Similarity
Similarit
y
metho
d
Correlation
Information
con
ten
t
r
=
:	
Leaco
c
k
and
Cho
doro
w
r
=
:0
Edge-coun
ting
r
=
:0
T
able
:
Summary
of
exp
erimen
tal
results
in
follo
w-up
study
.
(to
ensure
that
similar
noun
pairs
o
ccurred)
and
then
selected
noun
pairings
at
random
(in
order
to
a
v
oid
biasing
the
follo
w-up
study
in
fa
v
or
of
either
algorithm).
There
is,
therefore,
a
predominance
of
lo
w-similarit
y
noun
pairs
in
the
test
data.
Lo
oking
at
the
distribution
of
ratings
for
the
noun
pairs,
as
giv
en
b
y
the
t
w
o
measures,
it
is
eviden
t
that
the
Leaco
c
k
and
Cho
doro
w
measure
is
o
v
erestimating
seman
tic
similarit
y
for
man
y
of
the
predominan
tly
non-similar
pairs.
This
stands
to
reason
since
the
measure
is
iden
tical
whenev
er
the
edge
distance
is
iden
tical,
regardless
of
whether
the
pair
is
high
or
lo
w
in
the
taxonom
y
(e.g.,
the
distance
b
et
w
een
plant
and
animal
is
the
same
as
the
distance
b
et
w
een
white
o
ak
and
r
e
d
o
ak).
In
con
trast,
the
information-based
measure
is
sensitiv
e
to
the
dierence,
and
b
etter
at
a
v
oiding
spuriously
high
similarit
y
v
alues
for
non-similar
pairs.
On
a
related
note,
the
edge-coun
ting
measure
used
in
the
follo
w-up
study
w
as
a
v
arian
t
that
computes
path
length
through
a
virtual
top
no
de,
rather
than
asserting
zero
similarit
y
b
et
w
een
w
ords
with
no
path
connecting
them
in
the
existing
W
ordNet
taxonom
y
,
as
w
as
done
previously
.
Using
the
data
set
in
the
follo
w-up
study
,
the
information-based
measure,
at
r
=
:	,
do
es
signican
tly
b
etter
than
either
of
the
edge-coun
ting
v
arian
ts
(r
=
:0
and
r
=
:);
but
going
bac
k
to
the
original
Miller
and
Charles
data,
the
virtual-top-no
de
v
arian
t
do
es
signican
tly
b
etter
than
the
assert-zero
edge
distance
measure,
with
its
correlation
of
r
=
:
approac
hing
that
of
the
measure
based
on
information
con
ten
t.
This
comparison
b
et
w
een
the
follo
w-up
study
and
the
original
Miller
and
Charles
data
illustrates
quite
clearly
ho
w
the
utilit
y
of
a
similarit
y
measure
can
dep
end
up
on
the
distribution
of
items
giv
en
b
y
the
task.
Lin
(		,
		)
has
recen
tly
prop
osed
an
alternativ
e
information-theoretic
similarit
y
measure,
deriv
ed
from
a
set
of
basic
assumptions
ab
out
similarit
y
in
a
st
yle
reminiscen
t
of
the
w
a
y
in
whic
h
en
trop
y/information
itself
has
a
formal
denition
deriv
able
from
a
set
of
basic
prop
erties
(Khinc
hin,
	).
F
ormally
,
Lin
denes
similarit
y
in
a
taxonom
y
as:
sim
Lin
(c

;
c

)
=


log
p(
T
i
C
i
)
log
p(c

)
+
log
p(c

)
()
where
the
C
i
are
the
\maximally
sp
ecic
sup
erclasses"
of
b
oth
c

and
c

.
Although
the
p
ossibilit
y
of
m
ultiple
inheritance
mak
es
the
in
tersection
T
i
C
i
necessary
in
principle,
m
ul-
tiple
inheritance
is
in
fact
so
rare
in
W
ordNet
that
in
practice
one
computes
Equation
()
separately
for
eac
h
common
ancestor
C
i
,
using
p(C
i
)
in
the
n
umerator,
and
then
tak
es
the
maxim
um
(Dek
ang
Lin,
p.c.).
Other
than
the
m
ultiplicativ
e
constan
t
of
,
therefore,
Lin's
metho
d
for
determining
similarit
y
in
a
taxonom
y
is
essen
tially
the
information-based
similarit
y
measure
of
Equation
,
but
normalize
d
b
y
the
com
bined
information
con
ten
t
of
the
t
w
o
concepts
assuming
their
indep
endence
.
Put
another
w
a
y
,
Lin's
measure
is
taking


----- Page 30 (native) -----
Resnik
Similarit
y
metho
d
Correlation
Information
con
ten
t
r
=
:	
sim
Wu&Palmer
r
=
:0
sim
Lin
r
=
:	
T
able
:
Summary
of
Lin's
results
comparing
alternativ
e
similarit
y
measures
in
to
accoun
t
not
only
commonalities
but
dierences
b
et
w
een
the
items
b
eing
compared,
expressing
b
oth
in
information-theoretic
terms.
Lin's
measure
is
theoretically
w
ell
motiv
ated
and
elegan
tly
deriv
ed.
Moreo
v
er,
Lin
p
oin
ts
out
that
his
measure
will
b
y
denition
yield
the
same
v
alue
for
sim
Lin
(x;
x)
regardless
of
the
iden
tit
y
of
x
|
unlik
e
information
con
ten
t,
whic
h
has
b
een
criticized
on
the
grounds
that
the
v
alue
of
self-similarit
y
dep
ends
on
ho
w
sp
ecic
a
concept
x
is,
and
that
t
w
o
non-
iden
tical
items
x
and
y
can
b
e
rated
more
similar
to
eac
h
other
than
a
third
item
z
is
to
itself
(Ric
hardson
et
al.,
		).
F
rom
a
cognitiv
e
p
ersp
ectiv
e,
ho
w
ev
er,
similarit
y
comparisons
in
v
olving
self-similarit
y
(\Robins
are
similar
to
robins"),
as
w
ell
as
sub
class
relationships
(\Robins
are
similar
to
birds"),
ha
v
e
themselv
es
b
een
criticized
b
y
psyc
hologists
as
anoma-
lous
(Medin,
Goldstone,
&
Gen
tner,
		).
Moreo
v
er,
exp
erimen
tal
evidence
with
h
uman
judgmen
ts
suggests
that
not
all
iden
tical
ob
jects
are
judged
equally
similar,
consisten
t
with
the
information-con
ten
t
measure
prop
osed
here
but
con
trary
to
Lin's
measure.
F
or
exam-
ple,
ob
jects
that
are
iden
tical
and
complex,
suc
h
as
t
wins,
can
seem
more
similar
to
eac
h
other
than
ob
jects
that
are
iden
tical
and
simple,
suc
h
as
t
w
o
instances
of
a
simple
geo-
metric
shap
e
(Goldstone,
			;
Tv
ersky
,
	).
It
w
ould
app
ear,
therefore,
that
insofar
as
delit
y
to
h
uman
judgmen
ts
is
relev
an
t,
further
exp
erimen
tation
is
needed
to
ev
aluate
the
comp
eting
predictions
of
alternativ
e
similarit
y
measures.
W
u
and
P
almer
(		)
prop
ose
a
similarit
y
measure
that
is
based
on
edge
distances,
but
related
to
Lin's
measure
in
the
w
a
y
it
tak
es
in
to
accoun
t
the
most
sp
ecic
no
de
dominating
c

and
c

,
c
haracterizing
their
commonalities,
while
normalizing
in
a
w
a
y
that
accoun
ts
for
their
dierences.
Revising
W
u
and
P
almer's
notation
sligh
tly
,
their
measure
is:
sim
Wu&Palmer
(c

;
c

)
=


d(c

)
d(c

)
+
d(c

)
()
where
c

is
the
maximally
sp
ecic
sup
erclass
of
c

and
c

,
d
(c

)
is
its
depth,
i.e.
distance
from
the
ro
ot
of
the
taxonom
y
,
and
d(c

)
and
d
(c

)
are
the
depths
of
c

and
c

on
the
path
through
c

.
Lin
(		)
rep
eats
the
exp
erimen
t
of
Section

for
the
information
con
ten
t
measure,
sim
Lin
,
and
sim
Wu&Palmer
,
rep
orting
the
results
that
app
ear
in
T
able
.
Lin
uses
a
sense-
tagged
corpus
to
estimate
frequencies,
and
smo
othed
probabilities
rather
than
simple
rel-
ativ
e
frequency
.
His
results
sho
w
a
somewhat
higher
correlation
for
sim
Lin
than
the
other
measures.
F
urther
exp
erimen
tation
is
needed
in
order
to
assess
the
alternativ
e
measures,
particularly
with
resp
ect
to
their
comp
eting
predictions
and
the
v
ariabilit
y
of
p
erformance
across
data
sets.
What
seems
clear,
ho
w
ev
er,
is
that
all
these
measures
p
erform
b
etter
than
the
traditional
edge-coun
ting
measure.


----- Page 31 (native) -----
Inf
orma
tion-Based
Semantic
Similarity
.
Conclusions
This
article
has
presen
ted
a
measure
of
seman
tic
similarit
y
in
an
is-a
taxonom
y
,
based
on
the
notion
of
information
con
ten
t.
Exp
erimen
tal
ev
aluation
w
as
p
erformed
using
a
large,
indep
enden
tly
constructed
corpus,
an
indep
enden
tly
constructed
taxonom
y
,
and
previously
existing
and
new
h
uman
sub
ject
data,
and
the
results
suggest
that
the
measure
p
erforms
encouragingly
w
ell
and
can
b
e
signican
tly
b
etter
than
the
traditional
edge-coun
ting
ap-
proac
h.
Seman
tic
similarit
y
,
as
measured
using
information
con
ten
t,
w
as
sho
wn
to
b
e
useful
in
resolving
cases
of
t
w
o
p
erv
asiv
e
kinds
of
linguistic
am
biguit
y
.
In
resolving
co
ordination
am
biguit
y
,
the
measure
w
as
emplo
y
ed
to
capture
the
in
tuition
that
similarit
y
of
meaning
is
one
indicator
that
t
w
o
w
ords
are
b
eing
conjoined;
suggestiv
e
results
of
a
rst
exp
erimen
t
w
ere
b
olstered
b
y
unequiv
o
cal
results
in
a
second
study
,
demonstrating
signican
t
impro
v
e-
men
ts
o
v
er
a
disam
biguation
strategy
based
only
on
syn
tactic
agreemen
t.
In
resolving
w
ord
sense
am
biguit
y
,
the
seman
tic
similarit
y
measure
w
as
used
to
assign
condence
v
alues
to
w
ord
senses
of
nouns
within
thesaurus-lik
e
groupings.
A
formal
ev
aluation
pro
vided
evi-
dence
that
the
tec
hnique
can
pro
duce
useful
results
but
is
b
etter
suited
for
semi-automated
sense
ltering
than
categorical
sense
selection.
Application
of
the
tec
hnique
to
a
dictio-
nary/thesaurus
on
the
W
orld
Wide
W
eb
pro
vides
a
demonstration
of
the
metho
d
in
action
in
a
real-w
orld
setting.
Ac
kno
wledgemen
ts
Sections
-
of
this
article
comprise
a
revised
and
extended
v
ersion
of
Resnik
(		).
Section

describ
es
previously
presen
ted
algorithms
and
data
(Resnik,
		b,
		a),
ex-
tended
b
y
further
discussion
and
analysis.
Section

summarizes
an
algorithm
describ
ed
in
Resnik
(		a),
and
then
extends
previous
results
b
y
presen
ting
new
applications
of
the
algorithm,
with
Section
.
con
taining
a
formal
ev
aluation
in
a
new
setting
and
Section
.
giving
a
real-w
orld
illustration
where
the
approac
h
has
b
een
put
in
to
practice.
Section

adds
a
substan
tial
discussion
of
related
w
ork
b
y
other
authors
that
has
tak
en
place
since
the
information-based
similarit
y
measure
w
as
originally
prop
osed.
P
arts
of
this
researc
h
w
ere
done
at
the
Univ
ersit
y
of
P
ennsylv
ania
with
the
partial
supp
ort
of
an
IBM
Graduate
F
ello
wship
and
gran
ts
AR
O
D
AAL
0-	-C-00,
D
ARP
A
N000-	0-J-,
NSF
IRI
	0-	,
and
Ben
F
ranklin
	S.0C-;
parts
of
this
researc
h
w
ere
also
done
at
Sun
Microsystems
Lab
oratories
in
Chelmsford,
Massac
h
usetts;
and
parts
of
this
w
ork
w
ere
supp
orted
at
the
Univ
ersit
y
of
Maryland
b
y
Departmen
t
of
Defense
con
tract
MD
A	0	C0,
D
ARP
A/ITO
Con
tract
N00-	-C-0,
Arm
y
Researc
h
Lab
oratory
con
tract
D
AAL0-	-C-00
through
Battelle,
and
a
researc
h
gran
t
from
Sun
Microsystems
Lab
oratories.
The
author
gratefully
ac
kno
wledges
the
commen
ts
of
three
anon
ymous
JAIR
review
ers
and
helpful
discussions
with
John
Ko
v
arik,
Claudia
Leaco
c
k,
Dek
ang
Lin,
Johanna
Mo
ore,
Mari
Broman
Olsen,
and
Jin
T
ong,
as
w
ell
as
commen
ts
and
criticism
receiv
ed
during
v
arious
presen
tations
of
this
w
ork.
References
Agarw
al,
R.,
&
Boggess,
L.
(		).
A
simple
but
useful
approac
h
to
conjunct
iden
tica-


----- Page 32 (native) -----
Resnik
tion.
In
Pr
o
c
e
e
dings
of
the
0th
A
nnual
Me
eting
of
the
Asso
ciation
for
Computational
Linguistics,
pp.
{.
Asso
ciation
for
Computational
Linguistics.
Bensc
h,
P
.
A.,
&
Sa
vitc
h,
W.
J.
(		).
An
o
ccurrence-based
mo
del
of
w
ord
categorization.
Presen
ted
at
rd
Meeting
on
Mathematics
of
Language
(MOL).
Brill,
E.
(		).
Disco
v
ering
the
lexical
features
of
a
language.
In
Pr
o
c
e
e
dings
of
the
	th
A
nnual
Me
eting
of
the
Asso
ciation
for
Computational
Linguistics,
Berkeley,
CA.
Brill,
E.,
&
Resnik,
P
.
(		).
A
rule-based
approac
h
to
prep
ositional
phrase
attac
hmen
t
dis-
am
biguation.
In
Pr
o
c
e
e
dings
of
the
th
International
Confer
enc
e
on
Computational
Linguistics
(COLING-	).
Bro
wn,
P
.
F.,
Della
Pietra,
V.
J.,
deSouza,
P
.
V.,
Lai,
J.
C.,
&
Mercer,
R.
L.
(		).
Class-based
n-gram
mo
dels
of
natural
language.
Computational
Linguistics,

(),
{0.
CET
A
(	).
Chinese
Dictionaries:
an
Extensive
Biblio
gr
aphy
of
Dictionaries
in
Chinese
and
Other
L
anguages.
Chinese-English
T
ranslation
Assistance
Group,
Green
w
o
o
d
Publishing.
Ch
urc
h,
K.
W.,
&
Mercer,
R.
(		).
In
tro
duction
to
the
sp
ecial
issue
on
computational
linguistics
using
large
corp
ora.
Computational
Linguistics,
	
(),
{.
Ch
urc
h,
K.
W.,
&
P
atil,
R.
(	).
Coping
with
syn
tactic
am
biguit
y
or
ho
w
to
put
the
blo
c
k
in
the
b
o
x
on
the
table.
A
meric
an
Journal
of
Computational
Linguistics,

(-),
	{	.
Collins,
A.,
&
Loftus,
E.
(	).
A
spreading
activ
ation
theory
of
seman
tic
pro
cessing.
Psycholo
gic
al
R
eview,
,
0{.
Collins,
M.,
&
Bro
oks,
J.
(		).
Prep
ositional
phrase
attac
hmen
t
through
a
bac
k
ed-o
mo
del.
In
Thir
d
Workshop
on
V
ery
L
ar
ge
Corp
or
a.
Asso
ciation
for
Computational
Linguistics.
cmp-lg/	00.
Co
wie,
J.,
Guthrie,
J.,
&
Guthrie,
L.
(		).
Lexical
disam
biguation
using
sim
ulated
anneal-
ing.
In
Pr
o
c
e
e
dings
of
the
th
International
Confer
enc
e
on
Computational
Linguistics
(COLING-	),
pp.
	{
Nan
tes,
F
rance.
Digital
Equipmen
t
Corp
oration
(		).
AltaVista
w
eb
page:
Rene,
or
co
w	?..
http://altavista.digita
l.com/av
/conten
t/about
_our_tec
hnology
_cow	.h
tm.
Dorr,
B.
J.
(		).
Large-Scale
Dictionary
Construction
for
F
oreign
Language
T
utoring
and
In
terlingual
Mac
hine
T
ranslation.
Machine
T
r
anslation,

(),
{.
F
ellbaum,
C.
(Ed.).
(		).
Wor
dNet:
A
n
Ele
ctr
onic
L
exic
al
Datab
ase.
MIT
Press.
F
rancis,
W.
N.,
&
Ku

cera,
H.
(	).
F
r
e
quency
A
nalysis
of
English
Usage:
L
exic
on
and
Gr
ammar.
Hough
ton
Miin,
Boston.


----- Page 33 (native) -----
Inf
orma
tion-Based
Semantic
Similarity
Goldstone,
R.
L.
(			).
Similarit
y
.
In
MIT
Encyclop
e
dia
of
the
Co
gnitive
Scienc
es.
MIT
Press,
Cam
bridge,
MA.
Grefenstette,
G.
(		).
Use
of
syn
tactic
con
text
to
pro
duce
term
asso
ciation
lists
for
text
retriev
al.
In
Pr
o
c
e
e
dings
of
the
Fifte
enth
A
nnual
International
A
CM
SIGIR
Confer-
enc
e
on
R
ese
ar
ch
and
Development
in
Information
R
etrieval,
pp.
	{	.
Grefenstette,
G.
(		).
Explor
ations
in
A
utomatic
Thesaurus
Disc
overy.
Klu
w
er,
Boston.
Harman,
D.
(		).
Relev
ance
feedbac
k
revisited.
In
Pr
o
c
e
e
dings
of
the
Fifte
enth
A
nnual
International
A
CM
SIGIR
Confer
enc
e
on
R
ese
ar
ch
and
Development
in
Information
R
etrieval,
pp.
{0.
Hearst,
M.
(		).
Noun
homograph
disam
biguation
using
lo
cal
con
text
in
large
corp
ora.
In
Pr
o
c
e
e
dings
of
the
th
A
nnual
Confer
enc
e
of
the
University
of
Waterlo
o
Centr
e
for
the
New
OED
and
T
ext
R
ese
ar
ch
Oxford.
Hindle,
D.,
&
Ro
oth,
M.
(		).
Structural
am
biguit
y
and
lexical
relations.
Computational
Linguistics,
	
(),
0{0.
Ji,
D.,
Gong,
J.,
&
Huang,
C.
(		).
Com
bining
a
Chinese
thesaurus
with
a
Chinese
dictionary
.
In
COLING-A
CL
'	,
pp.
00{0.
Univ
ersit

e
de
Mon
treal.
Katz,
S.
M.
(	).
Estimation
of
probabilities
from
sparse
data
for
the
language
mo
del
comp
onen
t
of
a
sp
eec
h
recognizer.
IEEE
T
r
ansactions
on
A
c
oustics,
Sp
e
e
ch
and
Signal
Pr
o
c
essing,
ASSP-
(),
00{0.
Khinc
hin,
A.
I.
(	).
Mathematic
al
F
oundations
of
Information
The
ory.
New
Y
ork:
Do
v
er
Publications.
T
ranslated
b
y
R.
A.
Silv
erman
and
M.
D.
F
riedman.
Kla
v
ans,
J.
L.,
&
Tzouk
ermann,
E.
(		).
Dictionaries
and
Corp
ora:
Com
bining
Corpus
and
Mac
hine-Readable
Dictionary
Data
for
Building
Bilingual
Lexicons.
Machine
T
r
anslation,
0,
{.
Koba
y
asi,
Y.,
T
akunaga,
T.,
&
T
anak
a,
H.
(		).
Analysis
of
Japanese
comp
ound
nouns
using
collo
cational
information.
In
Pr
o
c
e
e
dings
of
the
th
International
Confer
enc
e
on
Computational
Linguistics
(COLING-	).
Kro
v
etz,
R.,
&
Croft,
W.
B.
(		).
Lexical
am
biguit
y
and
information
retriev
al.
A
CM
T
r
ansactions
on
Information
Systems,
0
(),
{.
Kurohashi,
S.,
&
Nagao,
M.
(		).
Dynamic
programming
metho
d
for
analyzing
conjunc-
tiv
e
structures
in
Japanese.
In
Pr
o
c
e
e
dings
of
the
th
International
Confer
enc
e
on
Computational
Linguistics
(COLING-	)
Nan
tes,
F
rance.
Lauer,
M.
(		).
Conceptual
asso
ciation
for
comp
ound
noun
analysis.
In
Pr
o
c
e
e
dings
of
the
nd
A
nnual
Me
eting
of
the
Asso
ciation
for
Computational
Linguistics
Las
Cruces,
New
Mexico.
Studen
t
Session.
Lauer,
M.
(		).
Designing
Statistic
al
L
anguage
L
e
arners:
Exp
eriments
on
Noun
Com-
p
ounds.
Ph.D.
thesis,
Macquarie
Univ
ersit
y
,
Sydney
,
Australia.


----- Page 34 (native) -----
Resnik
Leaco
c
k,
C.,
&
Cho
doro
w,
M.
(		).
Filling
in
a
sparse
training
space
for
w
ord
sense
iden
tication.
ms.
Lee,
J.
H.,
Kim,
M.
H.,
&
Lee,
Y.
J.
(		).
Information
retriev
al
based
on
conceptual
distance
in
IS-A
hierarc
hies.
Journal
of
Do
cumentation,
	
(),
{0.
Lee,
L.
(		).
Similarit
y-based
approac
hes
to
natural
language
pro
cessing.
T
ec
h.
rep.
TR--	,
Harv
ard
Univ
ersit
y
.
Do
ctoral
dissertation.
cmp-lg/	00.
Lesk,
M.
(	).
Automatic
sense
disam
biguation
using
mac
hine
readable
dictionaries:
ho
w
to
tell
a
pine
cone
from
an
ice
cream
cone.
In
Pr
o
c
e
e
dings
of
the
	
SIGDOC
Confer
enc
e,
pp.
{.
Li,
H.,
&
Ab
e,
N.
(		).
Generalizing
case
frames
using
a
thesaurus
and
the
MDL
principle.
In
Pr
o
c
e
e
dings
of
the
International
Confer
enc
e
on
R
e
c
ent
A
dvanc
es
in
NLP
V
elingrad,
Bulgaria.
Lin,
D.
(		).
Using
syn
tactic
dep
endency
as
lo
cal
con
text
to
resolv
e
w
ord
sense
am
bigu-
it
y
.
In
Pr
o
c
e
e
dings
of
the
th
A
nnual
Me
eting
of
the
Asso
ciation
for
Computational
Linguistics
and
th
Confer
enc
e
of
the
Eur
op
e
an
Chapter
of
the
Asso
ciation
for
Com-
putational
Linguistics
Madrid,
Spain.
Lin,
D.
(		).
An
information-theoretic
denition
of
similarit
y
.
In
Pr
o
c
e
e
dings
of
the
Fifte
enth
International
Confer
enc
e
on
Machine
L
e
arning
(ICML-	)
Madison,
Wis-
consin.
Marcus,
M.
P
.,
San
torini,
B.,
&
Marcinkiewicz,
M.
(		).
Building
a
large
annotated
corpus
of
English:
the
Penn
Treebank.
Computational
Linguistics,
	,
{0.
McKeo
wn,
K.,
&
Hatziv
assiloglou,
V.
(		).
Augmen
ting
lexicons
automatically:
Cluster-
ing
seman
tically
related
adjectiv
es.
In
Bates,
M.
(Ed.),
ARP
A
Workshop
on
Human
L
anguage
T
e
chnolo
gy.
Morgan
Kaufmann.
Medin,
D.,
Goldstone,
R.,
&
Gen
tner,
D.
(		).
Resp
ects
for
similarit
y
.
Psycholo
gic
al
R
eview,
00
(),
{.
Merlo,
P
.,
Cro
c
k
er,
M.,
&
Berthouzoz,
C.
(		).
A
ttac
hing
m
ultiple
prep
ositional
phrases:
Generalized
bac
k
ed-o
estimation.
In
Pr
o
c
e
e
dings
of
the
Se
c
ond
Confer
enc
e
on
Em-
piric
al
Metho
ds
in
Natur
al
L
anguage
Pr
o
c
essing
(EMNLP-).
cmp-lg/	000.
Miller,
G.
(		0).
W
ordNet:
An
on-line
lexical
database.
International
Journal
of
L
exic
o
g-
r
aphy,

().
(Sp
ecial
Issue).
Miller,
G.
A.,
&
Charles,
W.
G.
(		).
Con
textual
correlates
of
seman
tic
similarit
y
.
L
an-
guage
and
Co
gnitive
Pr
o
c
esses,

(),
{.
Morrissey
,
R.
(		).
T
exts
and
con
texts:
The
AR
TFL
database
in
F
renc
h
studies.
Pr
ofession
	,
{.
http://humanities.uchicago
.edu/hom
es/publ
ication
s/romoar
t.html.


----- Page 35 (native) -----
Inf
orma
tion-Based
Semantic
Similarity
P
ereira,
F.,
Tish
b
y
,
N.,
&
Lee,
L.
(		).
Distributional
clustering
of
English
w
ords.
In
Pr
o-
c
e
e
dings
of
the
st
A
nnual
Me
eting
of
the
Asso
ciation
for
Computational
Linguistics
(A
CL-	)
Morristo
wn,
New
Jersey
.
Asso
ciation
for
Computational
Linguistics.
Quillian,
M.
R.
(	).
Seman
tic
memory
.
In
Minsky
,
M.
(Ed.),
Semantic
Information
Pr
o
c
essing.
MIT
Press,
Cam
bridge,
MA.
Rada,
R.,
&
Bic
knell,
E.
(		).
Ranking
do
cumen
ts
with
a
thesaurus.
JASIS,
0
(),
0{0.
Rada,
R.,
Mili,
H.,
Bic
knell,
E.,
&
Blettner,
M.
(		).
Dev
elopmen
t
and
application
of
a
metric
on
seman
tic
nets.
IEEE
T
r
ansaction
on
Systems,
Man,
and
Cyb
ernetics,
	
(),
{0.
Ratnaparkhi,
A.,
&
Rouk
os,
S.
(		).
A
maxim
um
en
trop
y
mo
del
for
prep
ositional
phrase
attac
hmen
t.
In
Pr
o
c
e
ddings
of
the
ARP
A
Workshop
on
Human
L
anguage
T
e
chnolo
gy
Plainsb
oro,
NJ.
Resnik,
P
.
(		a).
Sele
ction
and
Information:
A
Class-Base
d
Appr
o
ach
to
L
exic
al
R
e-
lationships.
Ph.D.
thesis,
Univ
ersit
y
of
P
ennsylv
ania.
(ftp://ftp.cis.upenn.e
du/pub/
ircs/tr/
	-.p
s.Z).
Resnik,
P
.
(		b).
Seman
tic
classes
and
syn
tactic
am
biguit
y
.
In
Pr
o
c
e
e
dings
of
the
		
ARP
A
Human
L
anguage
T
e
chnolo
gy
Workshop.
Morgan
Kaufmann.
Resnik,
P
.
(		).
Using
information
con
ten
t
to
ev
aluate
seman
tic
similarit
y
in
a
taxonom
y
.
In
Pr
o
c
e
e
dings
of
the
th
International
Joint
Confer
enc
e
on
A
rticial
Intel
ligenc
e
(IJCAI-	).
(cmp-lg/	00).
Resnik,
P
.
(		).
Selectional
constrain
ts:
An
information-theoretic
mo
del
and
its
compu-
tational
realization.
Co
gnition,
,
{	.
Resnik,
P
.
(		a).
Disam
biguating
noun
groupings
with
resp
ect
to
W
ordnet
senses.
In
Armstrong,
S.,
Ch
urc
h,
K.,
Isab
elle,
P
.,
Tzouk
ermann,
E.,
&
Y
aro
wsky
,
D.
(Eds.),
Natur
al
L
anguage
Pr
o
c
essing
Using
V
ery
L
ar
ge
Corp
or
a.
Klu
w
er.
Resnik,
P
.
(		b).
W
ordNet
and
class-based
probabilities.
In
F
ellbaum,
C.
(Ed.),
Wor
dNet:
A
n
Ele
ctr
onic
L
exic
al
Datab
ase.
MIT
Press.
Resnik,
P
.,
&
Y
aro
wsky
,
D.
(		).
A
p
ersp
ectiv
e
on
w
ord
sense
disam
biguation
metho
ds
and
their
ev
aluation.
In
ANLP
Workshop
on
T
agging
T
ext
with
L
exic
al
Semantics
W
ashington,
D.C.
Resnik,
P
.,
&
Y
aro
wsky
,
D.
(			).
Distinguishing
systems
and
distinguishing
senses:
New
ev
aluation
metho
ds
for
w
ord
sense
disam
biguation.
Natur
al
L
anguage
Engine
ering.
(to
app
ear).
Ric
hardson,
R.,
Smeaton,
A.
F.,
&
Murph
y
,
J.
(		).
Using
W
ordNet
as
a
kno
wl-
edge
base
for
measuring
seman
tic
similarit
y
b
et
w
een
w
ords.
W
orking
pap
er
CA-
	,
Dublin
Cit
y
Univ
ersit
y
,
Sc
ho
ol
of
Computer
Applications,
Dublin,
Ireland.
ftp://ftp.compapp.dcu.i
e/pub/w-
papers/
		/CA
	.ps.
Z.


----- Page 36 (native) -----
Resnik
Ross,
S.
(	).
A
First
Course
in
Pr
ob
ability.
Macmillan.
Rub
enstein,
H.,
&
Go
o
denough,
J.
(	).
Con
textual
correlates
of
synon
ym
y
.
CA
CM,

(0),
{.
Salton,
G.
(		).
A
utomatic
T
ext
Pr
o
c
essing.
Addison-W
esley
.
Sc
h

utze,
H.
(		).
W
ord
space.
In
Hanson,
S.
J.,
Co
w
an,
J.
D.,
&
Giles,
C.
L.
(Eds.),
A
d-
vanc
es
in
Neur
al
Information
Pr
o
c
essing
Systems
,
pp.
	{	0.
Morgan
Kaufmann
Publishers,
San
Mateo
CA.
Sinclair
(ed.),
J.
(	).
Col
lins
COBUILD
English
L
anguage
Dictionary.
Collins:
London.
Sussna,
M.
(		).
W
ord
sense
disam
biguation
for
free-text
indexing
using
a
massiv
e
seman-
tic
net
w
ork.
In
Pr
o
c
e
e
dings
of
the
Se
c
ond
International
Confer
enc
e
on
Information
and
Know
le
dge
Management
(CIKM-	)
Arlington,
Virginia.
Tv
ersky
,
A.
(	).
F
eatures
of
similarit
y
.
Psycholo
gic
al
R
eview,
,
{.
V
o
orhees,
E.
M.
(		).
Using
WordNet
to
disam
biguate
w
ord
senses
for
text
retriev
al.
In
Korfhage,
R.,
Rasm
ussen,
E.,
&
Willett,
P
.
(Eds.),
Pr
o
c
e
e
dings
of
the
Sixte
enth
A
nnual
International
A
CM
SIGIR
Confer
enc
e
on
R
ese
ar
ch
and
Development
in
Information
R
etrieval,
pp.
{0.
V
o
orhees,
E.
M.
(		).
Query
expansion
using
lexical-seman
tic
relations.
In
th
Inter-
national
Confer
enc
e
on
R
ese
ar
ch
and
Development
in
Information
R
etrieval
(SIGIR
'	)
Dublin,
Ireland.
V
ossen,
P
.
(		).
Sp
ecial
issue
on
EuroW
ordNet.
Computers
and
the
Humanities,

(/).
W
eiss,
S.
M.,
&
Kulik
o
wski,
C.
A.
(		).
Computer
systems
that
le
arn:
classic
ation
and
pr
e
diction
metho
ds
fr
om
statistics,
neur
al
nets,
machine
le
arning,
and
exp
ert
systems.
Morgan
Kaufmann,
San
Mateo,
CA.
Whittemore,
G.,
F
errara,
K.,
&
Brunner,
H.
(		0).
Empirical
study
of
predictiv
e
p
o
w
ers
of
simple
attac
hmen
t
sc
hemes
for
p
ost-mo
dier
prep
ositional
phrases.
In
Pr
o
c
e
e
dings
of
the
th
A
nnual
Me
eting
of
the
Asso
ciation
for
Computational
Linguistics,
pp.
{0.
Pittsburgh,
P
ennsylv
ania.
Wilks,
Y.,
&
Stev
enson,
M.
(		).
The
grammar
of
sense:
Is
w
ord-sense
tagging
m
uc
h
more
than
part-of-sp
eec
h
tagging?..
T
ec
hnical
Rep
ort
CS-	-0,
cmp-lg/	00.
W
u,
Z.,
&
P
almer,
M.
(		).
V
erb
Seman
tics
and
Lexical
Selection.
In
Pr
o
c
e
e
dings
of
the
nd
A
nnual
Me
eting
of
the
Asso
ciation
for
Computational
Linguistics
Las
Cruces,
New
Mexico.
0